{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:00:59.120138: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 10ms/step - loss: 20268.8594 - val_loss: 25913.8711\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 19855.0898 - val_loss: 25143.0859\n",
      "Epoch 3/100\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 15029.8652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:00:59.642464: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 9ms/step - loss: 18941.7285 - val_loss: 23658.8672\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 17311.5371 - val_loss: 21264.8848\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 15062.5137 - val_loss: 18133.4883\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 12289.6172 - val_loss: 14453.0615\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 9246.6396 - val_loss: 10591.3037\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6179.8857 - val_loss: 6900.5918\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3470.8701 - val_loss: 3659.4490\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1418.1006 - val_loss: 1397.3478\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 423.3874 - val_loss: 518.9141\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 228.6872 - val_loss: 410.4455\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 181.3399 - val_loss: 378.8031\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 144.9355 - val_loss: 319.6953\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 123.3742 - val_loss: 276.9713\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 109.9066 - val_loss: 235.0499\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 91.7909 - val_loss: 219.4716\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 81.2260 - val_loss: 186.6572\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 70.8156 - val_loss: 176.3140\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 62.8428 - val_loss: 154.7523\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 55.4579 - val_loss: 141.5781\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 50.3994 - val_loss: 123.1806\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 47.2757 - val_loss: 123.6416\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 40.3845 - val_loss: 103.6669\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.1848 - val_loss: 95.9783\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 35.6433 - val_loss: 90.4822\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.0030 - val_loss: 83.2726\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9955 - val_loss: 73.6692\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 26.5821 - val_loss: 77.0531\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 24.8485 - val_loss: 67.6185\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 24.0841 - val_loss: 68.8437\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 20.6912 - val_loss: 62.2291\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 21.5615 - val_loss: 57.5145\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 18.7088 - val_loss: 54.6749\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 16.2332 - val_loss: 51.9221\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 15.3477 - val_loss: 50.1123\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 14.0571 - val_loss: 45.0134\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 13.4424 - val_loss: 43.1435\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 13.2850 - val_loss: 40.0477\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 11.8545 - val_loss: 37.6012\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 10.3664 - val_loss: 39.2101\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.6456 - val_loss: 34.1746\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.1138 - val_loss: 32.2445\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.3789 - val_loss: 30.3586\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.8792 - val_loss: 33.8069\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.3754 - val_loss: 27.3138\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.5150 - val_loss: 23.3082\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.5736 - val_loss: 22.8979\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.4151 - val_loss: 21.8015\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.4788 - val_loss: 20.9744\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.8821 - val_loss: 21.5090\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.6716 - val_loss: 20.7537\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.6380 - val_loss: 20.8604\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.2936 - val_loss: 21.2083\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8480 - val_loss: 22.4699\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.0773 - val_loss: 21.6839\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6609 - val_loss: 21.0710\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.0208 - val_loss: 20.9487\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8209 - val_loss: 21.1102\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8340 - val_loss: 21.1543\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4741 - val_loss: 17.8191\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4841 - val_loss: 17.7002\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5121 - val_loss: 19.4327\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4213 - val_loss: 17.9885\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4172 - val_loss: 19.1738\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2770 - val_loss: 20.3511\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5359 - val_loss: 19.4435\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8028 - val_loss: 23.9805\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.1458 - val_loss: 20.2072\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2421 - val_loss: 18.9501\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1957 - val_loss: 19.4128\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5371 - val_loss: 19.0235\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3312 - val_loss: 18.1160\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3388 - val_loss: 17.7031\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9841 - val_loss: 18.9258\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3304 - val_loss: 19.9384\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.1708 - val_loss: 18.3534\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9199 - val_loss: 19.0366\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3690 - val_loss: 19.7102\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2051 - val_loss: 18.8285\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5089 - val_loss: 20.2040\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3451 - val_loss: 18.2254\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4299 - val_loss: 19.9081\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8946 - val_loss: 18.3986\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5723 - val_loss: 20.1921\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7528 - val_loss: 19.3693\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1887 - val_loss: 17.9597\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8010 - val_loss: 19.7064\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1684 - val_loss: 18.4244\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9483 - val_loss: 19.1852\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9953 - val_loss: 19.7699\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3101 - val_loss: 18.2308\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8492 - val_loss: 19.6683\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3684 - val_loss: 18.5234\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1239 - val_loss: 18.5173\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1913 - val_loss: 19.1956\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3032 - val_loss: 18.6129\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2251 - val_loss: 17.4964\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5367 - val_loss: 18.3418\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6860 - val_loss: 17.8614\n",
      "Train MSE: 0.694, Test MSE: 17.861\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mlp with unscaled data for the regression problem\n",
    "from sklearn.datasets    import make_regression\n",
    "from keras.layers        import Dense\n",
    "from keras.models        import Sequential\n",
    "from tensorflow.keras.optimizers    import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the regression dataset.\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "\n",
    "plt.hist(y)\n",
    "plt.title(\"Unscaled Input\")\n",
    "plt.show()\n",
    "\n",
    "# Split into train and test.\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# Define the model.\n",
    "model = Sequential()\n",
    "model.add(Dense(25,input_dim=20, activation='relu',kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9, clipnorm=1.0))\n",
    "\n",
    "# Fit the model.\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=1)\n",
    "\n",
    "# Evaluate the model.\n",
    "train_mse = model.evaluate(trainX, trainy, verbose=0)\n",
    "test_mse  = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train MSE: %.3f, Test MSE: %.3f' % (train_mse, test_mse))\n",
    "\n",
    "# Plot losses during training.\n",
    "plt.title('Losses')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:26:03.501279: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 14ms/step - loss: 20290.6250 - val_loss: 26025.0195\n",
      "Epoch 2/100\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 21082.0254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:26:03.843047: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 8ms/step - loss: 20041.0605 - val_loss: 25602.6484\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 19585.6660 - val_loss: 24946.9180\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 18912.6738 - val_loss: 23922.4336\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 17887.5977 - val_loss: 22450.7246\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 16427.2363 - val_loss: 20467.8105\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 14644.0781 - val_loss: 18140.6074\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 12577.1309 - val_loss: 15443.7871\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 10359.9365 - val_loss: 12535.4648\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8019.7769 - val_loss: 9588.1660\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5791.4702 - val_loss: 6913.4224\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3907.8770 - val_loss: 4594.8730\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2276.6343 - val_loss: 2667.2112\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1117.1266 - val_loss: 1377.2200\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 523.2423 - val_loss: 703.0640\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 249.6161 - val_loss: 503.8933\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 188.1534 - val_loss: 421.0437\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 158.1360 - val_loss: 361.7327\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 132.3316 - val_loss: 317.5278\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 114.9668 - val_loss: 291.8608\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 103.2599 - val_loss: 258.9489\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 95.2092 - val_loss: 249.4954\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 89.3960 - val_loss: 222.5627\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 82.3928 - val_loss: 209.1085\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 72.2387 - val_loss: 197.8126\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 68.6577 - val_loss: 187.2745\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 65.2178 - val_loss: 174.9581\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 60.8473 - val_loss: 166.3853\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 59.7149 - val_loss: 162.2331\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 54.3313 - val_loss: 144.4365\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.1637 - val_loss: 148.0219\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 49.4012 - val_loss: 131.8725\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 44.2138 - val_loss: 127.4211\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 42.6686 - val_loss: 115.8088\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 39.2654 - val_loss: 113.3679\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 37.5649 - val_loss: 106.8517\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 34.8171 - val_loss: 115.0781\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 33.5029 - val_loss: 98.1821\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.5921 - val_loss: 108.2610\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.5603 - val_loss: 100.2627\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.1894 - val_loss: 102.4337\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 30.1320 - val_loss: 95.1130\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.4254 - val_loss: 99.5223\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 25.8606 - val_loss: 88.6701\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 24.5951 - val_loss: 85.4558\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 22.8605 - val_loss: 74.4368\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 20.8333 - val_loss: 75.3563\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 18.4561 - val_loss: 75.7125\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 19.0276 - val_loss: 65.9285\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 16.6154 - val_loss: 71.6384\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 16.1646 - val_loss: 59.7058\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14.9429 - val_loss: 60.9644\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 14.5569 - val_loss: 62.4138\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 12.1732 - val_loss: 54.1549\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 12.3416 - val_loss: 53.1954\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10.4204 - val_loss: 48.0849\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.9514 - val_loss: 47.4121\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.1450 - val_loss: 42.9184\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.7607 - val_loss: 43.5589\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.7590 - val_loss: 46.7235\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.5626 - val_loss: 44.3674\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.6870 - val_loss: 41.6135\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.2341 - val_loss: 38.7529\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.6326 - val_loss: 41.2618\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.7373 - val_loss: 38.9021\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.3350 - val_loss: 39.0293\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.6422 - val_loss: 37.9224\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.3942 - val_loss: 35.7268\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.5917 - val_loss: 35.2402\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.2415 - val_loss: 34.4724\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.6570 - val_loss: 32.2320\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.2874 - val_loss: 30.9039\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.7952 - val_loss: 28.4546\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.3314 - val_loss: 27.5473\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.1186 - val_loss: 27.2889\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9099 - val_loss: 27.6712\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.5207 - val_loss: 28.9308\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9584 - val_loss: 26.4605\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8905 - val_loss: 26.8931\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8497 - val_loss: 25.6162\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.0693 - val_loss: 24.6149\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2780 - val_loss: 26.8239\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.0007 - val_loss: 24.5674\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1692 - val_loss: 25.2991\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2421 - val_loss: 27.1023\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.3097 - val_loss: 23.7570\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.1753 - val_loss: 24.6190\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0731 - val_loss: 24.5401\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9903 - val_loss: 23.3146\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.5239 - val_loss: 24.0404\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.0255 - val_loss: 23.5178\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8259 - val_loss: 23.4499\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1971 - val_loss: 23.0460\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.8514 - val_loss: 21.6558\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9923 - val_loss: 23.0813\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2113 - val_loss: 23.4055\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2383 - val_loss: 22.9531\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9806 - val_loss: 22.1077\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1152 - val_loss: 23.7906\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.3428 - val_loss: 23.7016\n",
      "Train MSE: 0.811, Test MSE: 23.702\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 20858.1934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:26:14.567671: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 20294.5723 - val_loss: 26016.8125\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 20031.3691 - val_loss: 25585.8477\n",
      "Epoch 3/100\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 24623.1465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:26:14.799450: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 7ms/step - loss: 19555.7324 - val_loss: 24846.2891\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 18764.1816 - val_loss: 23690.0273\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 17650.5801 - val_loss: 22157.7598\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 16190.1885 - val_loss: 20216.0273\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14482.0352 - val_loss: 17813.4629\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 12398.1309 - val_loss: 15129.1953\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10092.5195 - val_loss: 12289.6816\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7861.7617 - val_loss: 9545.2080\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5751.4409 - val_loss: 6829.1016\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3724.6914 - val_loss: 4408.7563\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2110.8044 - val_loss: 2488.9519\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1011.8845 - val_loss: 1210.6688\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 465.7481 - val_loss: 640.0551\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 235.2842 - val_loss: 450.0251\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 172.3678 - val_loss: 397.6396\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 148.0220 - val_loss: 349.1397\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 128.7739 - val_loss: 308.2542\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 113.7832 - val_loss: 290.5172\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 102.4567 - val_loss: 252.3891\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 92.2717 - val_loss: 236.7833\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 85.9321 - val_loss: 217.7851\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 77.7025 - val_loss: 201.4521\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 73.3050 - val_loss: 181.9616\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 66.3757 - val_loss: 173.3216\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 61.9130 - val_loss: 166.9462\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 58.1281 - val_loss: 151.5358\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 52.4655 - val_loss: 140.6859\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.1305 - val_loss: 137.7634\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 46.4533 - val_loss: 123.2907\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 42.3897 - val_loss: 124.6213\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 40.2725 - val_loss: 113.5001\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 35.9689 - val_loss: 101.8765\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.7569 - val_loss: 100.1158\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9133 - val_loss: 91.6008\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 26.6348 - val_loss: 77.4813\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 24.7587 - val_loss: 76.6169\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 23.3121 - val_loss: 75.6766\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 21.1947 - val_loss: 76.7977\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 20.1693 - val_loss: 62.9581\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 18.4278 - val_loss: 60.4017\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 17.0713 - val_loss: 53.3045\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 15.6392 - val_loss: 54.4068\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 14.7586 - val_loss: 58.1425\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 13.2647 - val_loss: 55.7322\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 12.8573 - val_loss: 45.7544\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 13.0417 - val_loss: 45.9894\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 10.4312 - val_loss: 43.1666\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11.2251 - val_loss: 45.8434\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 10.2514 - val_loss: 43.5911\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.6970 - val_loss: 47.4853\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.5735 - val_loss: 43.6897\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 8.1836 - val_loss: 43.2304\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.4588 - val_loss: 42.1461\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.7996 - val_loss: 37.6128\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.2591 - val_loss: 35.8783\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.9410 - val_loss: 34.9564\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5.6452 - val_loss: 36.0021\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.6791 - val_loss: 35.5453\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.5194 - val_loss: 34.2254\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.2650 - val_loss: 31.5931\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.6183 - val_loss: 31.1346\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.4417 - val_loss: 31.8404\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.8620 - val_loss: 27.3647\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.3109 - val_loss: 26.0221\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.6984 - val_loss: 26.5282\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.5102 - val_loss: 27.1340\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.1908 - val_loss: 26.9676\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.8320 - val_loss: 25.9043\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2277 - val_loss: 21.7596\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3999 - val_loss: 22.7049\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0333 - val_loss: 21.3646\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9534 - val_loss: 20.9277\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5047 - val_loss: 21.9781\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5687 - val_loss: 20.3924\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.6713 - val_loss: 20.5976\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9740 - val_loss: 20.5838\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8961 - val_loss: 19.7205\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.2347 - val_loss: 20.8613\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2484 - val_loss: 20.3640\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9025 - val_loss: 19.6619\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9478 - val_loss: 19.3500\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7570 - val_loss: 19.6289\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1439 - val_loss: 20.2907\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9067 - val_loss: 19.9673\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6237 - val_loss: 20.0797\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6414 - val_loss: 20.3541\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.4952 - val_loss: 19.4900\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8195 - val_loss: 19.0669\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.7962 - val_loss: 17.8874\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5389 - val_loss: 17.5943\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.5129 - val_loss: 17.2141\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6918 - val_loss: 19.8079\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.7442 - val_loss: 18.0377\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.7885 - val_loss: 17.5546\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.5295 - val_loss: 19.3556\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.9532 - val_loss: 17.5576\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6913 - val_loss: 16.5445\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8266 - val_loss: 17.6494\n",
      "Train MSE: 0.809, Test MSE: 17.649\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAoNElEQVR4nO3de5hcdZ3n8fe3qq9JujvpS5K+JOncIFcMEGIQFBCRBB3B8TJREXaXmbguzuB1hXFU2GfZwdkdVHaFeVBYUUeQBRVGQbmLjBhoMELIhXRISDoJSScknQ6kO91V3/3jnO5UOtWX9O1UV31ez1NPVf3O+Z36/gKpT875nTrH3B0REZFY1AWIiEhmUCCIiAigQBARkZACQUREAAWCiIiEFAgiIgIoEEREJKRAEAmZ2TYze1/UdYhERYEgIiKAAkGkT2ZWaGbfMbNd4eM7ZlYYLqs0s1+Z2UEze9PMfm9msXDZV81sp5m1mtkmM7swbI+Z2bVmtsXM9pvZvWZWHi4rMrOfhO0Hzex5M5sS3egl1ygQRPr2NWA5sAR4B7AM+Idw2ZeAJqAKmAL8PeBmdirwOeAsdy8BLga2hX3+DrgMOA+oAQ4A3wuXXQmUAdOACuA/A0dGamAiPSkQRPr2KeC/ufted28GbgA+HS7rAKqBGe7e4e6/9+DiYAmgEFhgZvnuvs3dt4R9PgN8zd2b3L0duB74qJnlhdurAOa4e8LdX3D3Q6M2Usl5CgSRvtUAr6e8fz1sA/ifQCPwiJm9ZmbXArh7I/B5gi/7vWZ2j5l19ZkB/CI8JHQQ2EAQIFOAHwO/Be4JD0/9k5nlj+TgRFIpEET6tovgS7zL9LANd2919y+5+yzgL4Avds0VuPtP3f3csK8D3wr77wBWuvvElEeRu+8M9zJucPcFwLuADwJXjMooRVAgiPSUH07uFplZEXA38A9mVmVmlcA3gJ8AmNkHzWyOmRlwiOBf+gkzO9XM3htOPrcRzAMkwu3/C3Cjmc0It1FlZpeGry8ws8VmFg+315HST2TEKRBEjvcQwRd416MIaABeAl4GXgT+e7juXOAx4DDwLHCruz9FMH9wE7APeAOYTDDhDPBd4EGCw0ytwB+Bd4bLpgL3EYTBBuB3hOEjMhpMN8gRERHQHoKIiIQUCCIiAigQREQkpEAQEREA8qIuYLAqKyu9vr4+6jJERMaUF154YZ+7V6VbNmYDob6+noaGhqjLEBEZU8zs9d6W6ZCRiIgACgQREQkpEEREBBjDcwgiIoPR0dFBU1MTbW1tUZcyooqKiqirqyM/f+AXzFUgiEhOaWpqoqSkhPr6eoLrEmYfd2f//v00NTUxc+bMAffTISMRySltbW1UVFRkbRgAmBkVFRUnvRekQBCRnJPNYdBlMGPMvUDYvwUeux6SyagrERHJKLkXCBt/Dc98G357HejS3yIyyg4ePMitt9560v0uueQSDh48OPwFpci9QHjX38Ly/wJr/gWeuinqakQkx/QWCIlE3zfHe+ihh5g4ceIIVRXIvbOMzOD9N0LbIfjdTVBUCmdfHXVVIpIjrr32WrZs2cKSJUvIz89nwoQJVFdXs3btWtavX89ll13Gjh07aGtr45prrmH16tXAscv1HD58mJUrV3Luuefyhz/8gdraWh544AGKi4uHXFvuBQJALAYfugWOtsJv/x7qlsG0s6KuSkRG2Q3/9grrdx0a1m0uqCnlm3+xsNflN910E+vWrWPt2rU89dRTfOADH2DdunXdp4feeeedlJeXc+TIEc466yw+8pGPUFFRcdw2Nm/ezN133833v/99Pv7xj3P//fdz+eWXD7n23Dtk1CUWh0u/B+Mnw6Nf13yCiERi2bJlx/1W4JZbbuEd73gHy5cvZ8eOHWzevPmEPjNnzmTJkiUAnHnmmWzbtm1Yaul3D8HMpgE/IrgBeBK43d2/a2bXA38DNIer/r27PxT2uQ64CkgAf+fuvw3bzwR+CBQT3Mz8Gnd3MysMP+NMYD/wV+4+PCPsS2EJnH8t/PqLsOkhmPeBEf9IEckcff1LfrSMHz+++/VTTz3FY489xrPPPsu4ceM4//zz0/6WoLCwsPt1PB7nyJEjw1LLQPYQOoEvuft8YDlwtZktCJd9292XhI+uMFgArAIWAiuAW80sHq5/G7AamBs+VoTtVwEH3H0O8G3gW0Mf2gCdcQVUzIVHvwmJzlH7WBHJTSUlJbS2tqZd1tLSwqRJkxg3bhwbN27kj3/846jW1m8guPtud38xfN0KbABq++hyKXCPu7e7+1agEVhmZtVAqbs/6+5OsEdwWUqfu8LX9wEX2mj9ciSeD++7HvZvhj/9aFQ+UkRyV0VFBeeccw6LFi3iK1/5ynHLVqxYQWdnJ6eddhpf//rXWb58+ajWdlKTymZWD5wOrAHOAT5nZlcADQR7EQcIwiI11prCto7wdc92wucdAO7eaWYtQAWwr8fnrybYw2D69OknU3rf5n0App8NT/4jnPZXUDC+/z4iIoP005/+NG17YWEhDz/8cNplXfMElZWVrFu3rrv9y1/+8rDVNeBJZTObANwPfN7dDxEc/pkNLAF2A//ctWqa7t5He199jm9wv93dl7r70qqqtHeAGxwzeO8/wFt7YcOvhm+7IiJjyIACwczyCcLgX9395wDuvsfdE+6eBL4PLAtXbwKmpXSvA3aF7XVp2o/rY2Z5QBnw5mAGNGgzzoGy6fDy/xvVjxURyRT9BkJ4LP8OYIO735zSXp2y2oeBrn2YB4FVZlZoZjMJJo+fc/fdQKuZLQ+3eQXwQEqfK8PXHwWeCOcZRo8ZLP4IbHkC3trX//oiIllmIHsI5wCfBt5rZmvDxyXAP5nZy2b2EnAB8AUAd38FuBdYD/wGuNrdu36T/VngBwQTzVuAroNldwAVZtYIfBG4dlhGd7IWfRQ8Aet/GcnHi4hEqd9JZXd/hvTH+B/qo8+NwI1p2huARWna24CP9VfLiJuyEKrmw8v3wVl/HXU1IiKjKnd/qZxO12Gj7c/CwR1RVyMiMqoUCD0t+mjwvO7+aOsQkaw02MtfA3znO9/h7bffHuaKjlEg9FQ+E2qXBoeNRESGWSYHQm5e7bQ/iz8Gv/kqNG+CqlOjrkZEskjq5a8vuugiJk+ezL333kt7ezsf/vCHueGGG3jrrbf4+Mc/TlNTE4lEgq9//evs2bOHXbt2ccEFF1BZWcmTTz457LUpENKZ/8EgEDY/qkAQyWYPXwtvvDy825y6GFb2fvOt1MtfP/LII9x3330899xzuDsf+tCHePrpp2lubqampoZf//rXQHCNo7KyMm6++WaefPJJKisrh7fmkA4ZpVNWBxVzYOvvoq5ERLLYI488wiOPPMLpp5/OGWecwcaNG9m8eTOLFy/mscce46tf/Sq///3vKSsrG5V6tIfQm1nnw9q7ofMo5BVEXY2IjIQ+/iU/Gtyd6667js985jMnLHvhhRd46KGHuO6663j/+9/PN77xjRGvR3sIvZl5HnS8BTtfiLoSEckiqZe/vvjii7nzzjs5fPgwADt37mTv3r3s2rWLcePGcfnll/PlL3+ZF1988YS+I0F7CL2Z+W7A4LWnYMbZUVcjIlki9fLXK1eu5JOf/CRnnx18x0yYMIGf/OQnNDY28pWvfIVYLEZ+fj633XYbAKtXr2blypVUV1ePyKSyjfYlg4bL0qVLvaGhYWQ/5PYLIF4AV/12ZD9HREbNhg0bmD9/ftRljIp0YzWzF9x9abr1dcioL7POg50N0D5yu2giIplCgdCXWedDshNe/0PUlYiIjDgFQl+mvRPihfCaTj8VySZj9VD5yRjMGBUIfckvhunLg4llEckKRUVF7N+/P6tDwd3Zv38/RUVFJ9VPZxn1Z9b58PgNcHgvTJgcdTUiMkR1dXU0NTXR3NwcdSkjqqioiLq6uv5XTKFA6M+s8+BxYNvvYdFHoq5GRIYoPz+fmTNnRl1GRtIho/5MPS2YR9j5YtSViIiMKAVCf+L5UH2aAkFEsp4CYSBqz4TdayHRGXUlIiIjRoEwEDVnQMfbsG9T1JWIiIwYBcJA1J4RPOuwkYhkMQXCQJTPhsIyXflURLKaAmEgYjGoWQK7tIcgItlLgTBQtWfCnlegoy3qSkRERoQCYaBqzwgudDfc918VEckQCoSBqgknlnXYSESylAJhoEprYMJUTSyLSNZSIAyUWXDYSKeeikiWyrlA6Ewk2XtokBPDtWfA/s3Q1jK8RYmIZIB+A8HMppnZk2a2wcxeMbNrwvZyM3vUzDaHz5NS+lxnZo1mtsnMLk5pP9PMXg6X3WJmFrYXmtnPwvY1ZlY/AmMF4I5ntnLhzb/jnue2n/z10LvnEf40/IWJiERsIHsIncCX3H0+sBy42swWANcCj7v7XIILRF8LEC5bBSwEVgC3mlk83NZtwGpgbvhYEbZfBRxw9znAt4FvDcPY0rp44VQWVJdy7c9f5lM/WMP2/W8PvHPN6cHz7j+PTHEiIhHqNxDcfbe7vxi+bgU2ALXApcBd4Wp3AZeFry8F7nH3dnffCjQCy8ysGih192c9+Kf5j3r06drWfcCFXXsPw62+cjx3/81y/seHF/NSUwsrvvs0f95xcGCdx5UHE8t7N45EaSIikTqpOYTwUM7pwBpgirvvhiA0gK7bidUCO1K6NYVtteHrnu3H9XH3TqAFqEjz+avNrMHMGoZyt6NYzPjkO6fzyBfeQ/n4Av76Rw3sOnhkYJ0nz4PmDYP+bBGRTDXgQDCzCcD9wOfd/VBfq6Zp8z7a++pzfIP77e6+1N2XVlVV9Vdyv2omFnPnfziLtqMJ/tMPn+dw+wAub101H5o3QTI55M8XEckkAwoEM8snCIN/dfefh817wsNAhM97w/YmYFpK9zpgV9hel6b9uD5mlgeUAW+e7GAG45QpJXzvU2ewee9h/vanL5JI9jPRPHlecCnslu2jUZ6IyKgZyFlGBtwBbHD3m1MWPQhcGb6+EnggpX1VeObQTILJ4+fCw0qtZrY83OYVPfp0beujwBN+0qcADd57Tqnim3+xgCc3NfPLP+3se+Wq+cGz5hFEJMsMZA/hHODTwHvNbG34uAS4CbjIzDYDF4XvcfdXgHuB9cBvgKvdPRFu67PADwgmmrcAD4ftdwAVZtYIfJHwjKXR9OnlM1hYU8p3H99MR6KPw0GT5wXPmkcQkSyT198K7v4M6Y/xA1zYS58bgRvTtDcAi9K0twEf66+WkWRmfPGiU7jqrgbuf6GJVcump1+xqAxKa2GvAkFEskvO/VK5L++dN5kl0ybyv59opL0z0fuKVfMUCCKSdRQIKbr2EnYePMK9z+/ofcXJ82Hfq5DsIzRERMYYBUIP755byVn1k/g/TzbS1tHLF37VPOhsgwPbRrU2EZGRpEDowcz4wvtOYc+hdn710u70K00OzzRq1plGIpI9FAhpnD27gunl4/jFn5rSr1B1avCseQQRySIKhDTMjMtOr+UPW/azuyXNJS0KS6BsmvYQRCSrKBB68eHTa3GHB9buSr9C1Tz9OE1EsooCoRczK8dz+vSJ/OLFnenvmzB5HuzbBIkBXP9IRGQMUCD04S9Pr2XTnlY27G49ceHkBZA4Cge2jn5hIiIjQIHQhw+eVkN+3NJPLleFl7DQxLKIZAkFQh8mjS/g/FMn88DaXSdeBbXrTCNNLItIllAg9OMvT69lb2s7f9iy7/gFBeOhtA72N0ZTmIjIMFMg9OOCeZMpzIvx5MY0d2irnAP7No9+USIiI0CB0I+i/DjLZpbz9OY0gVAxF/ZvgdG7dYOIyIhRIAzAeadU0bj38In3Xa6YA+0t8Nbg7+8sIpIpFAgD8O65wf2bn361xxd/5ZzgWfMIIpIFFAgDcMqUCUwtLTrxsFFFGAiaRxCRLKBAGAAz491zK3lm8z46U2+vWTYN4oWwX4EgImOfAmGA3nNKFYfaOvlzU8uxxlgcymcFE8siImOcAmGAzp1TiVkv8wg6ZCQiWUCBMECTxhdwWt3E9PMIB7bqInciMuYpEE7CeXMr+fOOg7S83XGssWIuJDvh4OvRFSYiMgwUCCfhPadUkXR4pjHlMhYVOvVURLKDAuEkLJk2kXEFcZ7buv9YY+Xc4FnzCCIyxikQTkJePMYZ0yfx3LYDxxrHlUNxuU49FZExT4FwkpbWT2LjG4doOZI6jzBHp56KyJinQDhJy+rLcYcXt6fsJVTO1SEjERnzFAgnacn0ieTFjOe3vnmssWI2HH4D2tPcalNEZIxQIJykcQV5LKwtoyF1HqEinFjWmUYiMob1GwhmdqeZ7TWzdSlt15vZTjNbGz4uSVl2nZk1mtkmM7s4pf1MM3s5XHaLmVnYXmhmPwvb15hZ/TCPcdgtq5/E2qaDtHcmgobuU081jyAiY9dA9hB+CKxI0/5td18SPh4CMLMFwCpgYdjnVjOLh+vfBqwG5oaPrm1eBRxw9znAt4FvDXIso+as+nKOdiZ5qeu6RuWzANM8goiMaf0Ggrs/DbzZ33qhS4F73L3d3bcCjcAyM6sGSt39WXd34EfAZSl97gpf3wdc2LX3kKmW1pcD8Py28I8lvwgmToM3tYcgImPXUOYQPmdmL4WHlCaFbbXAjpR1msK22vB1z/bj+rh7J9ACVKT7QDNbbWYNZtbQ3BzdXcrKxxcwZ/KE4yeWddVTERnjBhsItwGzgSXAbuCfw/Z0/7L3Ptr76nNio/vt7r7U3ZdWVVWdVMHD7az6chpeP0AiGZZaPhvefC3SmkREhmJQgeDue9w94e5J4PvAsnBREzAtZdU6YFfYXpem/bg+ZpYHlDHwQ1SROat+Eq1tnby6JzzVtHwWtB2EtzO+dBGRtAYVCOGcQJcPA11nID0IrArPHJpJMHn8nLvvBlrNbHk4P3AF8EBKnyvD1x8FngjnGTLaWT3nESpmB8/aSxCRMSqvvxXM7G7gfKDSzJqAbwLnm9kSgkM724DPALj7K2Z2L7Ae6ASudvfw3Ew+S3DGUjHwcPgAuAP4sZk1EuwZrBqGcY24uknFVE4o7HGmEcE8Qt3S6AoTERmkfgPB3T+RpvmOPta/EbgxTXsDsChNexvwsf7qyDRmxqLaUtbtDANhUj1g2kMQkTFLv1QegoU1pTTuPUxbRwLyCqFsmgJBRMYsBcIQLKopozPpKRPLM/VbBBEZsxQIQ7CotgyAdTsPBQ0VOvVURMYuBcIQ1E0qprQoj3W7UiaWjxzQqaciMiYpEIbAzFhYU8Yru8I9hPKuU0+3RleUiMggKRCGaFFtKRt2H6IjkTx26qnmEURkDFIgDNGi2jKOdibZ0nxYp56KyJimQBiihTWlALyy81Bw1dOyOl3kTkTGJAXCEM2snEBxfvz4iWXtIYjIGKRAGKJ4zFhQUxrsIUAYCNpDEJGxR4EwDBbVlLJ+9yGSSQ9+i6BTT0VkDFIgDIOFNWUcbu/k9TffTjnTSKeeisjYokAYBgtrg4nldTtbUn6LoHkEERlbFAjDYO7kEgrisWBiufvUU80jiMjYokAYBgV5MWZPnsCmN1p16qmIjFkKhGEyb2pJEAigM41EZExSIAyTU6eWsLuljZa3O6BiDuxvhMy/E6iISDcFwjA5dWoJAJv2tAaB0NaiU09FZExRIAyTeV2B8MahIBAg2EsQERkjFAjDZGppESVFeWx8ozX4cRooEERkTFEgDBMzOzaxPHEGxPIUCCIypigQhtGpU0vYtKcVj8WD3yPoTCMRGUMUCMPo1KmltLZ1srulLTzTSIEgImOHAmEYHZtYbj0WCMlkxFWJiAyMAmEYnTIlCITuieXOI9C6K+KqREQGRoEwjMqK86kpKwpOPe26yJ0OG4nIGKFAGGanTi0J9xD0WwQRGVsUCMPslKklbGk+TMf4KZA/TnsIIjJmKBCG2bypJXQknK37jwSHjbSHICJjRL+BYGZ3mtleM1uX0lZuZo+a2ebweVLKsuvMrNHMNpnZxSntZ5rZy+GyW8zMwvZCM/tZ2L7GzOqHeYyj6tQpwc1yuieW9VsEERkjBrKH8ENgRY+2a4HH3X0u8Hj4HjNbAKwCFoZ9bjWzeNjnNmA1MDd8dG3zKuCAu88Bvg18a7CDyQSzJ48nHrPwmkaz4cA2SHREXZaISL/6DQR3fxroednOS4G7wtd3AZeltN/j7u3uvhVoBJaZWTVQ6u7PursDP+rRp2tb9wEXdu09jEWFeXFmV41n4+5wYjnZCQe3R12WiEi/BjuHMMXddwOEz5PD9lpgR8p6TWFbbfi6Z/txfdy9E2gBKtJ9qJmtNrMGM2tobm4eZOkjb97UUp1pJCJjznBPKqf7l7330d5XnxMb3W9396XuvrSqqmqQJY68edUl7Dx4hEPjZwQNOtNIRMaAwQbCnvAwEOHz3rC9CZiWsl4dsCtsr0vTflwfM8sDyjjxENWYMr86nFhuyYeiidpDEJExYbCB8CBwZfj6SuCBlPZV4ZlDMwkmj58LDyu1mtnycH7gih59urb1UeCJcJ5hzJo/NQiEDbvDm+Xs3xxxRSIi/cvrbwUzuxs4H6g0sybgm8BNwL1mdhWwHfgYgLu/Ymb3AuuBTuBqd0+Em/oswRlLxcDD4QPgDuDHZtZIsGewalhGFqEppYVMGpfPxq67p217JuqSRET61W8guPsnell0YS/r3wjcmKa9AViUpr2NMFCyRXCznFLW726FxXPgpXvg6NtQMC7q0kREeqVfKo+Q+dWlvPpGK4ny8EyjN1+LtiARkX4oEEbIvOoSjnQk2B2vCRo0sSwiGU6BMEIWhGcavdJWGTRoYllEMpwCYYTMmTyBeMxY19wJpbX6LYKIZDwFwggpyo8zq3I8G3aHF7nTISMRyXAKhBE0r7o05bcICgQRyWwKhBE0P7yERVvpTDhyAN4e0z/AFpEsp0AYQV2/WN4eC6/jp70EEclgCoQRNK+6BIBX2sIL8SkQRCSDKRBG0NTSIiaOy6ehpQRiebBPp56KSOZSIIwgM2P+1FLWvfE2TJqpPQQRyWgKhBG2sKaUjbsPkSyfrd8iiEhGUyCMsIW1pbR3Jjk4bga8uQWSyahLEhFJS4EwwhbWlAHwOlOhsw0O7Yy4IhGR9BQII2xW5XgK82K8fCS87bTmEUQkQykQRlhePMa86lKebZkYNCgQRCRDKRBGwcKaUv59Tx5eMEGBICIZS4EwChbWlHKoLUFH2Uz9FkFEMpYCYRR0TSzvK5quQBCRjKVAGAXzppYQjxmv2TRo2Q7th6MuSUTkBAqEUVCUH2d21Xj+dKQ6aGjeFG1BIiJpKBBGycKaMn53sDx407wx2mJERNJQIIyShTWlvNg6CY8XQvOGqMsRETmBAmGULKwpI0mMt0pmwV7tIYhI5lEgjJIFNcHNcnYVzNAhIxHJSAqEUVJWnM+08mI2JmqhZQe0t0ZdkojIcRQIo2hhdRlrDod3T2t+NdpiRER6UCCMosV1Zfz7oa5A0MSyiGQWBcIoWlRbxnafQiJeCHsVCCKSWYYUCGa2zcxeNrO1ZtYQtpWb2aNmtjl8npSy/nVm1mhmm8zs4pT2M8PtNJrZLWZmQ6krUy2uDc40OlBcr4llEck4w7GHcIG7L3H3peH7a4HH3X0u8Hj4HjNbAKwCFgIrgFvNLB72uQ1YDcwNHyuGoa6MUz6+gNqJxcElLPRrZRHJMCNxyOhS4K7w9V3AZSnt97h7u7tvBRqBZWZWDZS6+7Pu7sCPUvpkncW1Zfy5bYrONBKRjDPUQHDgETN7wcxWh21T3H03QPgc3iqMWmBHSt+msK02fN2z/QRmttrMGsysobm5eYilR2NxXRnPvTUleKO9BBHJIEMNhHPc/QxgJXC1mb2nj3XTzQt4H+0nNrrf7u5L3X1pVVXVyVebARbVlvGq1wVvNLEsIhlkSIHg7rvC573AL4BlwJ7wMBDh895w9SZgWkr3OmBX2F6Xpj0rLa4tY4dPpjNWqIllEckogw4EMxtvZiVdr4H3A+uAB4Erw9WuBB4IXz8IrDKzQjObSTB5/Fx4WKnVzJaHZxddkdIn65SPL6B64nh2509XIIhIRskbQt8pwC/CM0TzgJ+6+2/M7HngXjO7CtgOfAzA3V8xs3uB9UAncLW7J8JtfRb4IVAMPBw+stai2lLWv17LtD2vRF2KiEi3QQeCu78GvCNN+37gwl763AjcmKa9AVg02FrGmsW1ZTy7cToXdz4Fh3ZBaU3UJYmI6JfKUVhUW8afk7ODNztfjLYYEZGQAiECi2vLWO8zSFoe7Hwh6nJERAAFQiQqJhRSUVZKU8EsBYKIZAwFQkQW15XxYmIW7PoTJJNRlyMiokCIyln15TxzZAa0H4L9jVGXIyKiQIjK8lkVrO2eWNZhIxGJngIhIvOrS9lXOJ222DgFgohkBAVCROIxY+nMKtYzW4EgIhlBgRCh5bPKWXO0Hn/jZehsj7ocEclxCoQIdc0jWLID3lgXdTkikuMUCBGaX13KawWnBm902EhEIqZAiFA8Zsyon8s+m6RAEJHIKRAidvacSl7snEXHjoaoSxGRHKdAiNjyWeWsSc4n/0AjHNgWdTkiksMUCBGbP7WUZ/OXB282/CraYkQkpykQIhaLGbWz5rPZ6vGNCgQRiY4CIQNcOG8yvzp6Jmz/Ixze238HEZERoEDIAJecVs2TtgzDYdNDUZcjIjlKgZABSovymbFgGTuYQnL9v0VdjojkKAVChvjLM+t4uHMpbP0dtB2KuhwRyUEKhAzx7jmVrCl8F7FkB2x+JOpyRCQHKRAyRF48xswl59PsZbSvezDqckQkBykQMshHlk7n0cSZxBofgUO7oy5HRHKMAiGDzK8u5YnyvyKZSOK//KzutSwio0qBkGHOO3s5N3Rcjr32JKy5LepyRCSHKBAyzCffOYPt9R/n8eSZJB+9XvdJEJFRo0DIMPGYcfOqJfxj/tUc8PEk770Stq+JuiwRyQEKhAw0uaSI61edx9+2/xeOtDTDne+HO1cGF787uAOSiahLFJEslBd1AZLeuXMrWXP+pSx9YjbXTPoj/3Hfv1H4s08FC2P5MHEalIWPidOgZCqUVMOEKVBYAgUToGB88DCLdjAiMiZkTCCY2Qrgu0Ac+IG73xRxSZH74kWncOrUEv7xoUn884FzWT3jDd45sYVp1kxl5xsUvbWTvH2PY61vAJ5+I/HCICQmTIaiUsgfB/nFwXN3aIwL28cFrwsmBI/8oiB84gUQz4dYHGJ5wfv8YsgrhnjG/C8kIkNk7r18kYxmEWZx4FXgIqAJeB74hLuv763P0qVLvaEhN+4y1taR4I5ntnLXH7axt7X9hOUT8pJMLzjMtPwWauMtlMbbKYm1M8HamcQhJiYPUJZ4k2I/QoG3U5BsoyB5hILEEQqSbw+ptqTl4fECkrECPJ4PFgeLgcVIxgvxvGI8rxAAwzHAY/mQV4jHC4LAyiuAvEIs7Gsxg1geFsuHvHwsXggFxVh+cRBQFmzNAAv3fsyse/tYDPKKgkCLF3bXg8WCUIvnB8HW/f++gyeDQ3GeDPeoLFg/XhA88goIP5jwA49t08P+Hp4mbLFje2Vd28SP+7M5ca/NjrXHUtbDUupJ6dPb39vU2rtq7E33GOI9PiO1tv6+H+zE7ZgdX5/2UDOKmb3g7kvTLcuUf94tAxrd/TUAM7sHuBToNRBySVF+nKsvmMPVF8yh5UgHrzUf5vX9b9NypIPWtg4OtXXyVnsnbx9NsKO9k7aORPhI0t6Z4GgiydHO5HHPiaTTkXCMJIV0UEw742in2NqZQBvjrI0ijpJPgnw6ySNBnCR5Frwv4ijFtFNsR8nv6KSADvLpJIYTw4lbgkI6KOIohQQhFn5dk08bhbafAoJ+BXRSYB3ESQZf8iSJk+z+7ELriPBPX4ZLkuODIZYSNsljcT5s0m3P+gi4rvV7W8d71Hhsrb5rN5LdY/XurVuPz/M0MXxsHe/eVmDDkq+x5LLP9/qZg5UpgVAL7Eh53wS8s+dKZrYaWA0wffr00aksw5QV53P69EmcPn3SsGwvkXQ6k0k6E05HGBQJd5JJ6Ewmw+UetIePpDtJp/t16jIHku64O+6QdHgrGbxPhOsC4bJgO8muz0x5712v3Ukmk8QSR7FEGyQT3X+l3JPBP867XxtJjJgniCXbyUu2E092gCeCf7B6AvNO4t5JLJkgiEPAIWmx8K9tuHVPYu7EvZO4HyWePBrukwScYLknE2CGW+zYX2nv3jIJ4sE2PfjrHSOJeTJlO2De9dc/gYV9LdyrCJYd+xrBwe1Y39QNHfvq8HA7x+oIth/2Cf/MupZbOFazlM+B7vF618PDHYDurSWPG28sfO7+jHBPwbq30KOOlHddn9Tza9VTX4SfbXiwZrjn4X7C2t1/pqSu37VWmj2W1PVPqMS6/qw8dYXubfe1F2U4SeIntPUMHe8amYF5V4sftzR1RFVTFvT6mUORKYGQLl5P+FN299uB2yE4ZDTSReWCeMyIx+IUZsr/CSISmUw57bQJmJbyvg7YFVEtIiI5KVMC4XlgrpnNNLMCYBWgS36KiIyijDhQ4O6dZvY54LcEp53e6e6vRFyWiEhOyYhAAHD3hwDdUFhEJCKZcshIREQipkAQERFAgSAiIiEFgoiIABlyLaPBMLNm4PVBdq8E9g1jOWNFLo47F8cMuTnuXBwznPy4Z7h7VboFYzYQhsLMGnq7uFM2y8Vx5+KYITfHnYtjhuEdtw4ZiYgIoEAQEZFQrgbC7VEXEJFcHHcujhlyc9y5OGYYxnHn5ByCiIicKFf3EEREpAcFgoiIADkYCGa2wsw2mVmjmV0bdT0jwcymmdmTZrbBzF4xs2vC9nIze9TMNofPw3PbtQxiZnEz+5OZ/Sp8nwtjnmhm95nZxvC/+dnZPm4z+0L4//Y6M7vbzIqyccxmdqeZ7TWzdSltvY7TzK4Lv9s2mdnFJ/t5ORUIZhYHvgesBBYAnzCzkbkXXbQ6gS+5+3xgOXB1OM5rgcfdfS7wePg+21wDbEh5nwtj/i7wG3efB7yDYPxZO24zqwX+Dljq7osILpm/iuwc8w+BFT3a0o4z/Du+ClgY9rk1/M4bsJwKBGAZ0Ojur7n7UeAe4NKIaxp27r7b3V8MX7cSfEHUEoz1rnC1u4DLIilwhJhZHfAB4Acpzdk+5lLgPcAdAO5+1N0PkuXjJrh0f7GZ5QHjCO6wmHVjdvengTd7NPc2zkuBe9y93d23Ao0E33kDlmuBUAvsSHnfFLZlLTOrB04H1gBT3H03BKEBTI6wtJHwHeC/Qsqd5bN/zLOAZuD/hofKfmBm48nicbv7TuB/AduB3UCLuz9CFo+5h97GOeTvt1wLBEvTlrXn3ZrZBOB+4PPufijqekaSmX0Q2OvuL0RdyyjLA84AbnP304G3yI5DJb0Kj5lfCswEaoDxZnZ5tFVlhCF/v+VaIDQB01Le1xHsamYdM8snCIN/dfefh817zKw6XF4N7I2qvhFwDvAhM9tGcCjwvWb2E7J7zBD8P93k7mvC9/cRBEQ2j/t9wFZ3b3b3DuDnwLvI7jGn6m2cQ/5+y7VAeB6Ya2YzzayAYALmwYhrGnZmZgTHlDe4+80pix4ErgxfXwk8MNq1jRR3v87d69y9nuC/6xPufjlZPGYAd38D2GFmp4ZNFwLrye5xbweWm9m48P/1CwnmybJ5zKl6G+eDwCozKzSzmcBc4LmT2rK759QDuAR4FdgCfC3qekZojOcS7Cq+BKwNH5cAFQRnJWwOn8ujrnWExn8+8KvwddaPGVgCNIT/vX8JTMr2cQM3ABuBdcCPgcJsHDNwN8E8SQfBHsBVfY0T+Fr43bYJWHmyn6dLV4iICJB7h4xERKQXCgQREQEUCCIiElIgiIgIoEAQEZGQAkFERAAFgoiIhP4/baJlrGxg2EEAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 20285.5039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:26:25.667606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-08 00:26:25.853754: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 10ms/step - loss: 20289.9727 - val_loss: 26013.7734\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 20012.6602 - val_loss: 25571.4590\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 19524.6191 - val_loss: 24819.0527\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 18712.0391 - val_loss: 23614.3535\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 17567.2812 - val_loss: 21953.2559\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 15982.5449 - val_loss: 19777.3555\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 14050.2275 - val_loss: 17183.0645\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11841.2363 - val_loss: 14330.5283\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9454.4219 - val_loss: 11365.5098\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7189.4624 - val_loss: 8404.4355\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4909.6445 - val_loss: 5769.4033\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3102.7261 - val_loss: 3538.8059\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1667.4481 - val_loss: 1843.0405\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 734.0845 - val_loss: 833.7196\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 300.7619 - val_loss: 429.1744\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 170.0502 - val_loss: 344.7356\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 144.1386 - val_loss: 317.0736\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 123.3776 - val_loss: 270.1184\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 110.2291 - val_loss: 257.1534\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 97.6594 - val_loss: 228.3368\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 89.7112 - val_loss: 228.6082\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 82.9172 - val_loss: 187.0519\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 76.1011 - val_loss: 191.7344\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 70.3206 - val_loss: 166.1785\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 66.6938 - val_loss: 172.1353\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 61.9880 - val_loss: 152.4619\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 58.4641 - val_loss: 158.7869\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 56.2939 - val_loss: 157.6916\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 49.8776 - val_loss: 137.9046\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.7614 - val_loss: 127.8941\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 45.1169 - val_loss: 124.1580\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 42.1537 - val_loss: 108.7399\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 39.6308 - val_loss: 112.4091\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.9921 - val_loss: 100.8604\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.6822 - val_loss: 102.1441\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 32.2023 - val_loss: 93.2836\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 29.7010 - val_loss: 88.3981\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.9376 - val_loss: 85.8420\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 24.5870 - val_loss: 78.9450\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 23.4336 - val_loss: 67.6560\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 20.2399 - val_loss: 61.2909\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 18.9080 - val_loss: 59.7927\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 17.2301 - val_loss: 62.8476\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 16.3878 - val_loss: 51.2265\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14.2522 - val_loss: 52.0093\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 13.9135 - val_loss: 54.4498\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 13.0398 - val_loss: 49.8320\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 11.0961 - val_loss: 42.5188\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.9669 - val_loss: 42.0201\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.9693 - val_loss: 40.4450\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.0348 - val_loss: 36.2500\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.3037 - val_loss: 36.6598\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.8533 - val_loss: 32.1808\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.9593 - val_loss: 31.2950\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.2695 - val_loss: 30.0077\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.5556 - val_loss: 33.8944\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.2731 - val_loss: 31.0959\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.4637 - val_loss: 28.5282\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.8012 - val_loss: 26.7746\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.1698 - val_loss: 27.9019\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.5600 - val_loss: 27.3749\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.9457 - val_loss: 26.9538\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.9346 - val_loss: 24.7386\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.7572 - val_loss: 24.1645\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2330 - val_loss: 24.4700\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2529 - val_loss: 24.5349\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2120 - val_loss: 21.8727\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.3361 - val_loss: 20.6907\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4505 - val_loss: 20.4802\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8801 - val_loss: 18.0126\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8165 - val_loss: 17.8153\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9083 - val_loss: 18.2894\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9752 - val_loss: 19.4153\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9635 - val_loss: 18.4795\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8089 - val_loss: 18.8222\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7992 - val_loss: 18.9168\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9691 - val_loss: 17.3057\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7019 - val_loss: 18.1110\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5472 - val_loss: 17.2185\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7356 - val_loss: 17.6966\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8806 - val_loss: 16.9671\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7541 - val_loss: 17.1068\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0664 - val_loss: 16.8647\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5576 - val_loss: 15.8867\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8266 - val_loss: 15.8710\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4995 - val_loss: 17.2135\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4119 - val_loss: 15.9938\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3949 - val_loss: 15.9626\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5463 - val_loss: 17.4659\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5536 - val_loss: 16.8950\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0544 - val_loss: 17.7842\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4092 - val_loss: 16.7665\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5333 - val_loss: 16.2140\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7489 - val_loss: 16.2910\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0004 - val_loss: 17.5862\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9425 - val_loss: 17.0166\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9198 - val_loss: 17.1430\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7820 - val_loss: 16.8308\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9731 - val_loss: 16.7833\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.8383 - val_loss: 16.9709\n",
      "Train MSE: 1.371, Test MSE: 16.971\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 19355.1875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:26:36.041281: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 12ms/step - loss: 20294.7285 - val_loss: 26017.6797\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 20029.8613 - val_loss: 25603.0254\n",
      "Epoch 3/100\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 16665.7891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:26:36.255556: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 7ms/step - loss: 19566.8652 - val_loss: 24876.5938\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 18777.8848 - val_loss: 23703.0273\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 17657.3574 - val_loss: 22036.4746\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 16073.4238 - val_loss: 19973.1543\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14193.0869 - val_loss: 17490.0391\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 12075.4160 - val_loss: 14680.3008\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9736.9727 - val_loss: 11781.6797\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7508.0972 - val_loss: 8822.1895\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5180.0493 - val_loss: 6039.6543\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3173.0933 - val_loss: 3737.6072\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1695.8279 - val_loss: 1969.4761\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 741.1320 - val_loss: 882.7914\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 317.9315 - val_loss: 465.4739\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 186.7217 - val_loss: 396.2631\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 168.5471 - val_loss: 384.6563\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 144.3546 - val_loss: 320.4218\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 126.5744 - val_loss: 297.7281\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 107.4709 - val_loss: 261.4363\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 99.4055 - val_loss: 240.0021\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 88.4482 - val_loss: 223.4709\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 89.8868 - val_loss: 229.4477\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 79.5052 - val_loss: 208.8909\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 76.2081 - val_loss: 194.9816\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 65.6953 - val_loss: 179.3160\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 60.6684 - val_loss: 163.1813\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 56.1644 - val_loss: 168.2117\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.9446 - val_loss: 147.3174\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 47.0308 - val_loss: 135.1088\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 44.4316 - val_loss: 133.2447\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 41.3675 - val_loss: 110.6832\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.6181 - val_loss: 114.6017\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 33.5784 - val_loss: 104.5005\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 31.8727 - val_loss: 92.3737\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.9942 - val_loss: 84.5166\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 25.1528 - val_loss: 82.6741\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 25.1701 - val_loss: 79.9169\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 24.3297 - val_loss: 71.6288\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 19.9606 - val_loss: 75.8833\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 19.9903 - val_loss: 64.7095\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 17.6049 - val_loss: 57.3692\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 16.9953 - val_loss: 64.7543\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 15.3000 - val_loss: 57.5777\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 14.0015 - val_loss: 58.1555\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 12.3971 - val_loss: 55.3027\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11.9647 - val_loss: 51.7042\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11.2949 - val_loss: 51.5351\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10.5711 - val_loss: 47.8713\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.8576 - val_loss: 46.0233\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.4148 - val_loss: 41.3665\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7.0231 - val_loss: 41.6469\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.0560 - val_loss: 39.9765\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.3936 - val_loss: 38.2592\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 6.2450 - val_loss: 34.9347\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4.1860 - val_loss: 34.6487\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.8756 - val_loss: 33.9509\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.3749 - val_loss: 29.8485\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.9009 - val_loss: 27.2267\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.5898 - val_loss: 25.5379\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.6671 - val_loss: 24.4706\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.3455 - val_loss: 26.1441\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.5093 - val_loss: 25.2628\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.9411 - val_loss: 23.5723\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8146 - val_loss: 23.0307\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5850 - val_loss: 20.6309\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5057 - val_loss: 20.9144\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6136 - val_loss: 22.2420\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3490 - val_loss: 22.4331\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1658 - val_loss: 19.3661\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.0214 - val_loss: 19.4514\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.1506 - val_loss: 21.0446\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6739 - val_loss: 23.5342\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.1168 - val_loss: 18.2362\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1682 - val_loss: 19.6175\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9721 - val_loss: 19.2979\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3363 - val_loss: 19.4180\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9632 - val_loss: 17.4432\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8441 - val_loss: 16.9044\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6718 - val_loss: 17.6294\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9474 - val_loss: 21.4084\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.1017 - val_loss: 20.2862\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.1189 - val_loss: 19.1548\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5286 - val_loss: 17.7568\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6709 - val_loss: 17.8438\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6514 - val_loss: 16.8331\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4895 - val_loss: 17.5884\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9919 - val_loss: 17.2896\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1843 - val_loss: 17.4957\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0367 - val_loss: 16.9236\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6223 - val_loss: 18.1925\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6698 - val_loss: 17.6711\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4943 - val_loss: 17.8306\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5437 - val_loss: 18.6494\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5479 - val_loss: 19.1188\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6787 - val_loss: 16.9536\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5696 - val_loss: 18.7280\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5003 - val_loss: 19.2362\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4956 - val_loss: 19.6140\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9023 - val_loss: 17.9829\n",
      "Train MSE: 0.339, Test MSE: 17.983\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/16 [===================>..........] - ETA: 0s - loss: 20734.9102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:26:46.518609: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step - loss: 20292.2871 - val_loss: 25999.4375\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 20023.4492 - val_loss: 25553.8359\n",
      "Epoch 3/100\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 24135.8164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:26:46.731680: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 8ms/step - loss: 19529.8457 - val_loss: 24798.6738\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 18733.2832 - val_loss: 23599.8359\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 17512.5566 - val_loss: 21901.8438\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 15927.6201 - val_loss: 19727.0586\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 14104.0205 - val_loss: 17122.7461\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 11775.1006 - val_loss: 14319.4150\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 9522.2715 - val_loss: 11370.6777\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7189.2651 - val_loss: 8509.4248\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 5078.6050 - val_loss: 5863.0596\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3232.2842 - val_loss: 3605.7810\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1720.3252 - val_loss: 1887.5918\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 793.6503 - val_loss: 902.9294\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 356.1198 - val_loss: 489.6277\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 184.8970 - val_loss: 393.8529\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 152.4180 - val_loss: 349.7784\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 134.2459 - val_loss: 324.7263\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 114.9367 - val_loss: 271.4437\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 99.5799 - val_loss: 247.3776\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 91.7463 - val_loss: 231.5415\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 82.8752 - val_loss: 223.1564\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 78.2127 - val_loss: 215.8114\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 75.3077 - val_loss: 186.0124\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 64.8510 - val_loss: 177.5162\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 60.0291 - val_loss: 167.8077\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 55.0812 - val_loss: 156.2580\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 50.8374 - val_loss: 142.0221\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 46.5204 - val_loss: 138.9913\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 44.2392 - val_loss: 123.8887\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 40.5417 - val_loss: 125.7752\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 38.0610 - val_loss: 114.0064\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.4295 - val_loss: 105.0239\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.7866 - val_loss: 97.0795\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 28.2895 - val_loss: 92.2115\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.4176 - val_loss: 83.9121\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 25.2215 - val_loss: 80.2341\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 23.3098 - val_loss: 74.5112\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 20.1630 - val_loss: 73.3243\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 18.4366 - val_loss: 64.3841\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 17.9057 - val_loss: 63.1060\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 16.5314 - val_loss: 59.5780\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 15.1929 - val_loss: 57.5935\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 13.9710 - val_loss: 56.5303\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 12.4756 - val_loss: 53.3345\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10.7292 - val_loss: 49.3665\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.5880 - val_loss: 46.3067\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.8885 - val_loss: 43.5246\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.5535 - val_loss: 39.6238\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.6833 - val_loss: 37.4390\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.1802 - val_loss: 37.0489\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.5373 - val_loss: 34.7186\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.6614 - val_loss: 33.5531\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.8993 - val_loss: 33.6749\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.0446 - val_loss: 31.7612\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.7834 - val_loss: 30.6324\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.4938 - val_loss: 30.4589\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.1462 - val_loss: 28.9772\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.6661 - val_loss: 27.1222\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.2773 - val_loss: 27.6578\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.4774 - val_loss: 29.4977\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.1285 - val_loss: 24.6448\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.1626 - val_loss: 24.9570\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.5362 - val_loss: 23.8418\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5731 - val_loss: 22.9286\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.6440 - val_loss: 23.0714\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1634 - val_loss: 21.3391\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2794 - val_loss: 20.7816\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8904 - val_loss: 20.3961\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1277 - val_loss: 20.1325\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7151 - val_loss: 20.2363\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7261 - val_loss: 20.4743\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9844 - val_loss: 18.2743\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8305 - val_loss: 19.6126\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7509 - val_loss: 19.0980\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3037 - val_loss: 19.5340\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1097 - val_loss: 18.6807\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2231 - val_loss: 20.2658\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1466 - val_loss: 18.9232\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6380 - val_loss: 19.7251\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7247 - val_loss: 20.2594\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0659 - val_loss: 23.0433\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3658 - val_loss: 18.9986\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5142 - val_loss: 17.5658\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5249 - val_loss: 18.2255\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5018 - val_loss: 17.3632\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4689 - val_loss: 18.6442\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5576 - val_loss: 18.4641\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8712 - val_loss: 17.3072\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0294 - val_loss: 17.2609\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7498 - val_loss: 16.7261\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9638 - val_loss: 16.7632\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0229 - val_loss: 16.7386\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4969 - val_loss: 17.5060\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4335 - val_loss: 17.5441\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4451 - val_loss: 18.4474\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4427 - val_loss: 17.1246\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5251 - val_loss: 18.3088\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7548 - val_loss: 18.2927\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.8674 - val_loss: 17.8703\n",
      "Train MSE: 0.509, Test MSE: 17.870\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnnUlEQVR4nO3deZScdZ3v8fe3qnpJOr130t1JZ19JWBKIGMDroIAk6Ahcl4kOwjmXM3EcHHGuMsIoKnMu5+DcO4LODHhQuaIoyEG9oIKyK0oEEkTIRjayNNk6K52lt6rv/eN5Oql0qpd0d/XTXfV5nVOnqn7P86v6/kKoT57f76mnzN0RERGJRV2AiIgMDwoEEREBFAgiIhJSIIiICKBAEBGRkAJBREQABYKIiIQUCCIhM9tiZpdGXYdIVBQIIiICKBBEemRmRWZ2l5ntCG93mVlRuK3GzH5lZgfNbL+ZvWBmsXDbl8zsbTNrNrM3zeySsD1mZjeb2SYz22dmD5tZVbit2MweCNsPmtkrZlYb3egl3ygQRHr2ZWARMB84Bzgf+Eq47QtAIzAWqAX+BXAzmw18FniXu5cClwNbwj6fA64C/goYDxwA/ivcdh1QDkwEqoG/B45la2AiXSkQRHr2t8C/uvsed28CbgM+FW5rB+qBye7e7u4veHBxsCRQBMw1swJ33+Lum8I+nwa+7O6N7t4KfB34qJklwterBma4e9LdV7r7O0M2Usl7CgSRno0HtqY93xq2AfxvYCPwpJltNrObAdx9I/B5gg/7PWb2kJl19pkM/CKcEjoIrCUIkFrgR8BvgYfC6al/M7OCbA5OJJ0CQaRnOwg+xDtNCttw92Z3/4K7TwP+GvifnWsF7v4Td39P2NeBb4T9twNL3L0i7Vbs7m+HRxm3uftc4ELgQ8C1QzJKERQIIl0VhIu7xWZWDDwIfMXMxppZDfBV4AEAM/uQmc0wMwPeIfiXftLMZpvZ+8PF5xaCdYBk+PrfAW43s8nha4w1syvDx+8zs7PMLB6+XntaP5GsUyCInOxxgg/wzlsxsAJ4HXgDeBX4X+G+M4GngcPAcuBud3+eYP3gDmAvsAsYR7DgDPAt4DGCaaZm4E/Au8NtdcAjBGGwFvgdYfiIDAXTD+SIiAjoCEFEREIKBBERARQIIiISUiCIiAgAiagL6K+amhqfMmVK1GWIiIwoK1eu3OvuYzNtG7GBMGXKFFasWBF1GSIiI4qZbe1um6aMREQEUCCIiEhIgSAiIsAIXkMQEemP9vZ2GhsbaWlpibqUrCouLqahoYGCgr5fMFeBICJ5pbGxkdLSUqZMmUJwXcLc4+7s27ePxsZGpk6d2ud+mjISkbzS0tJCdXV1zoYBgJlRXV192kdBCgQRyTu5HAad+jPG/AuEfZvg6a+DrvIqInKS/AuEdb+GP9wJT38t6kpEJA8dPHiQu++++7T7XXHFFRw8eHDwC0qTf4Fw4T/Cu/4O/vgtePE/o65GRPJMd4GQTPb843iPP/44FRUVWaoqkH9nGZnBkm/AkSZ48stQMhbO+ZuoqxKRPHHzzTezadMm5s+fT0FBAWPGjKG+vp7XXnuNNWvWcNVVV7F9+3ZaWlq48cYbWbZsGXDicj2HDx9myZIlvOc97+HFF19kwoQJPProo4waNWrAteVfIADE4vDf74Vj++HRf4Dx82Hs7KirEpEhdtsvV7NmxzuD+ppzx5fxtb+e1+32O+64g1WrVvHaa6/x/PPP88EPfpBVq1YdPz30vvvuo6qqimPHjvGud72Lj3zkI1RXV5/0Ghs2bODBBx/ku9/9Lh//+Mf52c9+xjXXXDPg2vNvyqhTogg++gNIjIJn/jXqakQkT51//vknfVfg29/+Nueccw6LFi1i+/btbNiw4ZQ+U6dOZf78+QCcd955bNmyZVBq6fUIwcwmAj8k+AHwFHCvu3/LzL4O/B3QFO76L+7+eNjnFuB6IAl8zt1/G7afB/wAGEXwY+Y3urubWVH4HucB+4C/cffBGWFPSqrhos/Bc7fD9pdh4vlZf0sRGT56+pf8UCkpKTn++Pnnn+fpp59m+fLljB49mosvvjjjdwmKioqOP47H4xw7dmxQaunLEUIH8AV3PwNYBNxgZnPDbXe6+/zw1hkGc4GlwDxgMXC3mcXD/e8BlgEzw9visP164IC7zwDuBL4x8KH10aJ/gJJxOhVVRIZEaWkpzc3NGbcdOnSIyspKRo8ezbp16/jTn/40pLX1GgjuvtPdXw0fNwNrgQk9dLkSeMjdW939LWAjcL6Z1QNl7r7c3Z3giOCqtD73h48fAS6xofrmSNEY+Kt/hq1/hA1PDclbikj+qq6u5qKLLuLMM8/kpptuOmnb4sWL6ejo4Oyzz+bWW29l0aJFQ1rbaS0qm9kUYAHwEnAR8FkzuxZYQXAUcYAgLNJjrTFsaw8fd20nvN8O4O4dZnYIqAb2dnn/ZQRHGEyaNOl0Su/ZudfB8v+EZ26DGZdCLH+XVkQk+37yk59kbC8qKuKJJ57IuK1znaCmpoZVq1Ydb//iF784aHX1+ZPPzMYAPwM+7+7vEEz/TAfmAzuBf+/cNUN376G9pz4nN7jf6+4L3X3h2LEZfwGufxKF8L4vw+5VsPnZwXtdEZERpE+BYGYFBGHwY3f/OYC773b3pLungO8CnSuyjcDEtO4NwI6wvSFD+0l9zCwBlAP7+zOgfjvjw1BYCqt/MaRvKyIyXPQaCOFc/veBte7+zbT2+rTdrgY6j2EeA5aaWZGZTSVYPH7Z3XcCzWa2KHzNa4FH0/pcFz7+KPBsuM4wdAqKYc4VsPZX0NE2pG8tIjIc9GUN4SLgU8AbZvZa2PYvwCfMbD7B1M4W4NMA7r7azB4G1hCcoXSDu3d+J/sznDjt9InwBkHg/MjMNhIcGSwdyKD6bd7V8PpP4a3fwczLIilBRCQqvQaCu/+BzHP8j/fQ53bg9gztK4AzM7S3AB/rrZasm/5+KCqHVT9XIIhI3tHpNOkSRTDng8EVUTtao65GRGRIKRC6mnc1tB6CTc9FXYmI5KD+Xv4a4K677uLo0aODXNEJCoSupl0MxRWw+udRVyIiOWg4B0J+Xu20J4lCOONDsPpRaG8Jzj4SERkk6Ze/vuyyyxg3bhwPP/wwra2tXH311dx2220cOXKEj3/84zQ2NpJMJrn11lvZvXs3O3bs4H3vex81NTU899zgz2IoEDKZezX8+QHY8oIWl0Vy2RM3w643Bvc1686CJXd0uzn98tdPPvkkjzzyCC+//DLuzoc//GF+//vf09TUxPjx4/n1r38NBNc4Ki8v55vf/CbPPfccNTU1g1tzSFNGmUy+EGKJ4PpGIiJZ8uSTT/Lkk0+yYMECzj33XNatW8eGDRs466yzePrpp/nSl77ECy+8QHl5+ZDUoyOETApHQ/182Lo86kpEJJt6+Jf8UHB3brnlFj796U+fsm3lypU8/vjj3HLLLXzgAx/gq1/9atbr0RFCdyZfADteDdYRREQGSfrlry+//HLuu+8+Dh8+DMDbb7/Nnj172LFjB6NHj+aaa67hi1/8Iq+++uopfbNBRwjdmXQhvPgf8PZKmHJR1NWISI5Iv/z1kiVL+OQnP8kFF1wAwJgxY3jggQfYuHEjN910E7FYjIKCAu655x4Ali1bxpIlS6ivr8/KorIN9SWDBsvChQt9xYoV2XuDo/vh36bC+78C772p9/1FZERYu3YtZ5xxRtRlDIlMYzWzle6+MNP+mjLqzugqGHuG1hFEJG8oEHoy+YLgt5ZTyd73FREZ4RQIPZl0IbQ1D/55yiISqZE6VX46+jNGBUJPJgcLPWzTtJFIriguLmbfvn05HQruzr59+yguPr0rLegso56UN0D5JNj6Iiz6TNTViMggaGhooLGxkaampqhLyari4mIaGhp63zGNAqE3ky+ATc+CO1imn4UQkZGkoKCAqVOnRl3GsKQpo95MugCONMG+TVFXIiKSVQqE3kwK1xEaX462DhGRLFMg9KZmJiRG6UwjEcl5CoTexOJQO1eBICI5T4HQF3VnBYGQw6epiYgoEPqi9kxoOQjvvB11JSIiWaNA6Iu6s4N7TRuJSA5TIPRF7dzgXoEgIjlMgdAXRaVQNU2BICI5TYHQV50LyyIiOUqB0Fe1Z8GBt6DlnagrERHJCgVCX9WdFdzvWRNtHSIiWZJ3gdDakWRT0+HT79gZCJo2EpEc1WsgmNlEM3vOzNaa2WozuzFsrzKzp8xsQ3hfmdbnFjPbaGZvmtnlae3nmdkb4bZvmwWXDzWzIjP7adj+kplNycJYAfjO85tZ8q0X+M7vNtGRTPW9Y9l4GFWpQBCRnNWXI4QO4AvufgawCLjBzOYCNwPPuPtM4JnwOeG2pcA8YDFwt5nFw9e6B1gGzAxvi8P264ED7j4DuBP4xiCMLaNPvnsS7589jjueWMdHvrOcDbub+9bRTAvLIpLTeg0Ed9/p7q+Gj5uBtcAE4Erg/nC3+4GrwsdXAg+5e6u7vwVsBM43s3qgzN2Xe/BTRT/s0qfztR4BLuk8ehhsY0uLuOeac/mPTyxg274jfOg//sDKrQf61rn2rGANIdmRjdJERCJ1WmsI4VTOAuAloNbdd0IQGsC4cLcJwPa0bo1h24Twcdf2k/q4ewdwCKjO8P7LzGyFma0YyK8dmRl/fc54fvtP76W2rJhP/2glOw8d671j3VnQ0QL79dsIIpJ7+hwIZjYG+BnweXfv6dzLTP+y9x7ae+pzcoP7ve6+0N0Xjh07treSezWutJjvXbeQY20dLPvhSlrakz130MKyiOSwPgWCmRUQhMGP3f3nYfPucBqI8H5P2N4ITEzr3gDsCNsbMrSf1MfMEkA5sP90B9Mfs2pL+dbSBazacYh/fuT1nn94u2YWWBya1g1FaSIiQ6ovZxkZ8H1grbt/M23TY8B14ePrgEfT2peGZw5NJVg8fjmcVmo2s0Xha17bpU/na30UeNZ7/GQeXJfOreULl83isb/s4Lerd3e/Y6IQKqfA3vVDVZqIyJDpyxHCRcCngPeb2Wvh7QrgDuAyM9sAXBY+x91XAw8Da4DfADe4e+dczGeA7xEsNG8Cngjbvw9Um9lG4H8SnrE0lP7+r6YzraaEu55eTyrV01HCTNi7YegKExEZIonednD3P5B5jh/gkm763A7cnqF9BXBmhvYW4GO91ZJNiXiMGy+dyY0PvcZvVu/iirPqM+9YMxM2PQepZPBraiIiOSLvvqnckw+dPZ4Z48Zw51PrSXZ3lFAzC5KtcHDb0BYnIpJlCoQ08Zjx+UtnsmHPYX79xs7MO9XMCu41bSQiOUaB0MUVZ9Yzu7aUu57u5iihemZwv0+BICK5RYHQRSxm3HjpTDY3HeHZdXtO3aGkGkZV6UwjEck5CoQMLptbS8XoAn79+o7MO9TM0pSRiOQcBUIGBfEYH5hby9Nr92T+9nLNDB0hiEjOUSB044qz6jnc2sELG/aeurFmFhxpgmN9vCieiMgIoEDoxkUzaigfVcATmc42On6m0cahLUpEJIsUCN3onDZ6as1uWju6TBsdDwRNG4lI7lAg9OCKs+tpbu3gD12njSomQ6xAp56KSE5RIPTgouk1lBUnTv2SWjwBVdN0ppGI5BQFQg8KEzEum1vXzbTRTE0ZiUhOUSD04oNn19Hc0sGLm/advKFmFuzfDMn2aAoTERlkCoReXDi9hsJEjD92XUeomQmpDjiwNZrCREQGmQKhF8UFcc6dVJH5CAE0bSQiOUOB0AcXTq9h7a53OHi07URj9YzgXoEgIjlCgdAHF0yvxh3+tDntZ55HVcDoGti/KbK6REQGkwKhD85pqGBUQZw/be4ybVQ9HfZtjqYoEZFBpkDog8JEjIVTKnlxU5eF5arpOkIQkZyhQOijC6ZXs373YfYebj3RWD0NmndC25HoChMRGSQKhD66YFo1wMnTRlXTg/v9mjYSkZFPgdBHZ00oZ0xRguXpp59Wh4GwT9NGIjLyKRD6KBGP8a4plScHQtW04F7rCCKSAxQIp+HC6TVs3nuE3e+0BA1FpTCmVmcaiUhOUCCchgumB+sIJx8l6EwjEckNCoTTcEZ9GWOKEqzcmvbTmdXTtIYgIjlBgXAa4jHjnInlvLotLRCqpsORPdDaHF1hIiKDQIFwmhZMrGTdrmaOtnUEDdU69VREcoMC4TSdO7mCZMr5y/ZDQUPnmUaaNhKREa7XQDCz+8xsj5mtSmv7upm9bWavhbcr0rbdYmYbzexNM7s8rf08M3sj3PZtM7OwvcjMfhq2v2RmUwZ5jINqwcRKAP68PZw20qmnIpIj+nKE8ANgcYb2O919fnh7HMDM5gJLgXlhn7vNLB7ufw+wDJgZ3jpf83rggLvPAO4EvtHPsQyJypJCptWU8OrWg0FDYQmU1uvUUxEZ8XoNBHf/PbC/t/1CVwIPuXuru78FbATON7N6oMzdl7u7Az8Erkrrc3/4+BHgks6jh+FqwaRK/rztAMFQ0KmnIpITBrKG8Fkzez2cUqoM2yYA29P2aQzbJoSPu7af1MfdO4BDQHWmNzSzZWa2wsxWNDU1DaD0gVkwqYJ9R9rYtv9o0KBTT0UkB/Q3EO4BpgPzgZ3Av4ftmf5l7z2099Tn1Eb3e919obsvHDt27GkVPJjOnRTk3/HTT6umw9G90HIosppERAaqX4Hg7rvdPenuKeC7wPnhpkZgYtquDcCOsL0hQ/tJfcwsAZTT9ymqSMyuK6WkMM6ftx0MGnSROxHJAf0KhHBNoNPVQOcZSI8BS8Mzh6YSLB6/7O47gWYzWxSuD1wLPJrW57rw8UeBZ/345PzwFHxBreLkIwTQdxFEZERL9LaDmT0IXAzUmFkj8DXgYjObTzC1swX4NIC7rzazh4E1QAdwg7snw5f6DMEZS6OAJ8IbwPeBH5nZRoIjg6WDMK6sO3dSJff8bhNH2zoYXTU1aNQRgoiMYL0Ggrt/IkPz93vY/3bg9gztK4AzM7S3AB/rrY7hZsGk4AtqrzceYtG0aiibAAfeirosEZF+0zeV+2lBuLB8fB2hcqqmjERkRFMg9FNVSSHjy4t5c9c7YcMU2K8jBBEZuRQIAzCrrpR1u8KrnFZNC696ejjaokRE+kmBMACz60rZ3HSE9mQqmDICOLAl0ppERPpLgTAAs2tLaUum2LL3CHSeaaSFZREZoRQIAzC7rhSAN3c3nzhC0DqCiIxQCoQBmD52DPGYsX5XM4yqgFGVOkIQkRFLgTAAxQVxplSPPrGwrFNPRWQEUyAM0Oy6Utbv7jzTaKqmjERkxFIgDNCs2lK27j8a/MZy5VQ41AjJ9qjLEhE5bQqEAZpTV4o7bNxzODhC8CQc3BZ1WSIip02BMECzasMzjXY1n/h9ZS0si8gIpEAYoMnVJRQlYkEg6NRTERnBFAgDFI8ZM2vHBN9FKK2DxCgFgoiMSAqEQTC7tiw4QjCDyimaMhKREUmBMAhm141hT3MrB4606dRTERmxFAiDoHNheX3nJSwObIHh/SugIiKnUCAMgjl1ZUB4TaOqqdBxDJp3RVyViMjpUSAMgtqyIspHFQSXsKjUVU9FZGRSIAwCM2N2XWn4XQSdeioiI5MCYZCcEQZCqqwBLKaL3InIiKNAGCRz6ss43NrB281JKJ+oKSMRGXEUCINkTvhjOWt3vhNcwkJHCCIywigQBsms2lLMCBaWq6bBvs069VRERhQFwiApKUowuWo063aFRwith+DYgajLEhHpMwXCIJpTV8a6nc1QPT1o0LSRiIwgCoRBNKe+lLf2HaGldHLQoEAQkRFEgTCI5tSV4Q7rW6sAUyCIyIiiQBhEZ9SHZxrtbYPyBgWCiIwovQaCmd1nZnvMbFVaW5WZPWVmG8L7yrRtt5jZRjN708wuT2s/z8zeCLd928wsbC8ys5+G7S+Z2ZRBHuOQmVg5mtGFcdbuDL+xvG9T1CWJiPRZX44QfgAs7tJ2M/CMu88EngmfY2ZzgaXAvLDP3WYWD/vcAywDZoa3zte8Hjjg7jOAO4Fv9HcwUYvFgktYHD/TSEcIIjKC9BoI7v57YH+X5iuB+8PH9wNXpbU/5O6t7v4WsBE438zqgTJ3X+7uDvywS5/O13oEuKTz6GEkmlNXxrpdzXjVdDi2X6eeisiI0d81hFp33wkQ3o8L2ycA29P2awzbJoSPu7af1MfdO4BDQHWmNzWzZWa2wsxWNDU19bP07DqjvpSDR9s5WNwQNOgidyIyQgz2onKmf9l7D+099Tm10f1ed1/o7gvHjh3bzxKzq/O3ETZ0hBmpaSMRGSH6Gwi7w2kgwvs9YXsjMDFtvwZgR9jekKH9pD5mlgDKOXWKasSYHV7T6C+HK4IGHSGIyAjR30B4DLgufHwd8Gha+9LwzKGpBIvHL4fTSs1mtihcH7i2S5/O1/oo8Gy4zjAilY8qYHx5Maua2qF0vI4QRGTESPS2g5k9CFwM1JhZI/A14A7gYTO7HtgGfAzA3Veb2cPAGqADuMHdk+FLfYbgjKVRwBPhDeD7wI/MbCPBkcHSQRlZhE78WM402K9TT0VkZOg1ENz9E91suqSb/W8Hbs/QvgI4M0N7C2Gg5IpZdaX8ceM+UlOnEVv/RO8dRESGAX1TOQvm1JXSlkyxv2gCHGmClneiLklEpFcKhCyYVRssLG/xuqBBv54mIiOAAiELpo8dQzxmrGkJv06hhWURGQEUCFlQXBBnSvVoXjlUETQoEERkBFAgZMnsulLeaOqAMbUKBBEZERQIWTK7toyt+4+SrJymq56KyIigQMiS2XVjcIeDoyfD3g1RlyMi0isFQpbMDq9p1BibAEf36qqnIjLsKRCyZFLVaIoSMda11wYNezdGW5CISC8UCFkSjxkza8ew4nBN0LB3fbQFiYj0QoGQRbNry/jjvhKIJWCf1hFEZHhTIGTR7Lox7GhOkqyYooVlERn2FAhZ1LmwfKhkKuzTGoKIDG8KhCyaHV7TaEd8QvDltFSylx4iItFRIGRRbVkR5aMKWN9RB8k2OLg16pJERLqlQMgiM2N2XSkrjnSeaaR1BBEZvhQIWTa3vozn95UHTxQIIjKMKRCybN74Mna0lZAsqtCppyIyrCkQsmze+ODo4FDJFH1bWUSGNQVCls2sHUNhPMb2WIOOEERkWFMgZFlBPMasujGsbauFw7v1+8oiMmwpEIbAvPpyXmquCp7oKEFEhikFwhCYN6GM11vGBU90ppGIDFMKhCEwb3wZ27yWlMUVCCIybCkQhsCcujI6LMGhovGaMhKRYUuBMARKihJMrSlha6wBmvS7CCIyPCkQhsi88eX8pTU8QuhojbocEZFTKBCGyLzxZbxybDykOvTraSIyLCkQhsi88WWs9UnBk92roy1GRCSDAQWCmW0xszfM7DUzWxG2VZnZU2a2IbyvTNv/FjPbaGZvmtnlae3nha+z0cy+bWY2kLqGo3njy9nidXTECmH3qqjLERE5xWAcIbzP3ee7+8Lw+c3AM+4+E3gmfI6ZzQWWAvOAxcDdZhYP+9wDLANmhrfFg1DXsFJVUsi48hJ2FkzWEYKIDEvZmDK6Erg/fHw/cFVa+0Pu3urubwEbgfPNrB4oc/fl7u7AD9P65JR548tZnZyoQBCRYWmggeDAk2a20syWhW217r4TILwPv6LLBGB7Wt/GsG1C+Lhr+ynMbJmZrTCzFU1NTQMsfegtmFTBK8fqg2saHdkbdTkiIicZaCBc5O7nAkuAG8zsvT3sm2ldwHtoP7XR/V53X+juC8eOHXv61UZswaQK1mlhWUSGqQEFgrvvCO/3AL8Azgd2h9NAhPd7wt0bgYlp3RuAHWF7Q4b2nHN2QwXrFQgiMkz1OxDMrMTMSjsfAx8AVgGPAdeFu10HPBo+fgxYamZFZjaVYPH45XBaqdnMFoVnF12b1ienjClKUF3bwKFYhQJBRIadxAD61gK/CM8QTQA/cfffmNkrwMNmdj2wDfgYgLuvNrOHgTVAB3CDuyfD1/oM8ANgFPBEeMtJCyZVsub1iSzavSrjXJmISFT6HQjuvhk4J0P7PuCSbvrcDtyeoX0FcGZ/axlJFkyqYNWrE3n3nmewZAfEB5LJIiKDR99UHmLnTqpkXWoSsWQr7N8cdTkiIscpEIbYtJoSthdODZ7oG8siMowoEIZYLGaUTjyTJDEtLIvIsKJAiMCZk8axOVVPxy4dIYjI8KFAiMCCSRWs9Ukk334t6lJERI5TIERg/sQKXk3NpOjoLji4vfcOIiJDQIEQgYrRhewoXxA82fanaIsREQkpECJSMeUcDjMK37Y86lJERAAFQmQumFnLq8kZtG7+Y9SliIgACoTIXDSjhldSsyna/yYcOxB1OSIiCoSojCstZlfFuRgO21+OuhwREQVClCpnXUC7x+nY8mLUpYiIKBCidMHsBlb5VI5s+EPUpYiIKBCidP7UKlb6HEr2/gXaW6IuR0TynAIhQiVFCfbXnEfC22HHn6MuR0TynAIhYhWz/xsARzdp2khEoqVAiNjCuTPYkJpA8/oXoi5FRPKcAiFiZ08o57XYGZTvWQFtR6MuR0TymAIhYol4jK31V1CcOkJq1c+iLkdE8pgCYRiY9e7FrE9N4PAf7o26FBHJYwqEYWDJWfX8smAxZftf19lGIhIZBcIwUBCPUbboUxz1Ig79/jtRlyMieUqBMEx89MJ5/NIvYtSbv9DF7kQkEgqEYaKypJDds/+WQm/lyCsPRF2OiOQhBcIwsvjSy/lzagbty++F9mNRlyMieUaBMIzMqi3l2XHXUnZsO20//oSubyQiQ0qBMMxceuV13Jr6Owq3PEfHQ9dAR1vUJYlInlAgDDPnTKzg0k/exK0d/4PEpqdI/mQpvPkEHN0fdWkikuMSURcgp3rfnHEc+sgX+cojztc2P0B88zPBhuqZUDkZysZD6XgYVQnF5TCqAsoboGIyFJdFWruIjFzDJhDMbDHwLSAOfM/d74i4pEhdtWACzS2f55xfXszZbORvat/mPcVbKT20h8IdfyF2tClzx1FVMLoKisqCcCgcAwWjglu8COIFEEuE9wUQTwT7dPYrHJO2T2F4KwjuE0XhrRhi8aH9AxGRrDN3j7oGzCwOrAcuAxqBV4BPuPua7vosXLjQV6xYMUQVRmfHwWP8+KWtPPjydvYfObGekLAk4wpaGVfYSm3iCJPj+5loexhPE+UcpsSPUOJHKEy1UOgtFKZaiHs7MU8S9w5i3kHMk/2uK2UJUolReLwQLAYWwy2OJ4qDW7wIM8DBDDxWAIniYP8wYDxWgMUTWKIQixeAJSAWw2KJIKjCwLJYAZhhsRhYAovHweJYLI6ZYWZg8TC8EkGYYcEbh7VhsbAtBsaJ7Zn2s1jwehbrZlvaLZb+uuH+6Y6/b9p7Eb7/8X26bMu0T9f9Ol/3OAf3E/edfyaxcBynyFDLKbV3eT5SdH6mjdT6s8zMVrr7wkzbhssRwvnARnffDGBmDwFXAt0GQr4YXzGKmy6fwz++fyYrtx5g7+FW9h1u4+DRNo60JTna1sGR1iSb2zp4ozXJkbYOWtqTHGtPcqwtRXsyRUcyRXvK6UimSJ2U/06CJCW0UGnNVHKY0dZCAUkK6KCADhIkKbJ2CumgkOC+iHaKrY3i9jYKaSeGY+FrFVsbxbRTRFv4DsH/lAW0UmgHKaSdAjoo7Hx9S1JAkgRJ4qSIH79PUWD9DywZPKm04PGuIdWn/jGcIHaMvv0D1DEs/HvVtb1zGxleL07qpOfJ4387T/To6f3otr5M1Zzcv/temdu7e42+/Bmtnf8Vzrnq873ud7qGSyBMALanPW8E3t11JzNbBiwDmDRp0tBUNkwUF8S5aEbNgF8nmXLakymSKSfpTirlpBxS4eOkO20dQZC0dTgp95P27XzsTtpjJ5kKnoPT7tDqwet62N89+F8tFT5wgu3JVPAeHcngns59AE855h2QSgIpSCWxVBI8hXkHnkrh7uAp3JNYqoNYqh3zJHb8yDeJOZingGB/87BfJ08GRzKkgtcnBe6YJ+n8F7d5MvhA8xRGMmxLnWjHiXkKx0/+39kd63y9sMnS9wrvYuE+ZPig6/wwBQ/H5cdr8eNbAOv80DKMFDFPBa/b5QPGjh9NnCjA6PpR6SfVQ9ft7pk/W7t8lp2oyNNqtZO2e5d/yQf1BW/Y2Tv9tdK3BU/TAssMD8+VCfYP/wy888/0xJ9metEn6js1ODr7dfdBbZma097ixH+xru966u7pdfRk7Li5PW7vr+ESCH34qwXufi9wLwRTRtkuKhfFY0Zc8/8iksFwOe20EZiY9rwB2BFRLSIieWm4BMIrwEwzm2pmhcBS4LGIaxIRySvDYsrI3TvM7LPAbwlOO73P3VdHXJaISF4ZFoEA4O6PA49HXYeISL4aLlNGIiISMQWCiIgACgQREQkpEEREBBgm1zLqDzNrArb2s3sNsHcQyxkp8nHc+ThmyM9x5+OY4fTHPdndx2baMGIDYSDMbEV3F3fKZfk47nwcM+TnuPNxzDC449aUkYiIAAoEEREJ5Wsg3Bt1ARHJx3Hn45ghP8edj2OGQRx3Xq4hiIjIqfL1CEFERLpQIIiICJCHgWBmi83sTTPbaGY3R11PNpjZRDN7zszWmtlqM7sxbK8ys6fMbEN4Xxl1rYPNzOJm9mcz+1X4PB/GXGFmj5jZuvC/+QW5Pm4z+6fw7/YqM3vQzIpzccxmdp+Z7TGzVWlt3Y7TzG4JP9veNLPLT/f98ioQzCwO/BewBJgLfMLMsvNbdNHqAL7g7mcAi4AbwnHeDDzj7jOBZ8LnueZGYG3a83wY87eA37j7HOAcgvHn7LjNbALwOWChu59JcMn8peTmmH8ALO7SlnGc4f/jS4F5YZ+7w8+8PsurQADOBza6+2Z3bwMeAq6MuKZB5+473f3V8HEzwQfEBIKx3h/udj9wVSQFZomZNQAfBL6X1pzrYy4D3gt8H8Dd29z9IDk+boJL948yswQwmuAXFnNuzO7+e2B/l+buxnkl8JC7t7r7W8BGgs+8Psu3QJgAbE973hi25SwzmwIsAF4Cat19JwShAYyLsLRsuAv4ZyCV1pbrY54GNAH/N5wq+56ZlZDD43b3t4H/A2wDdgKH3P1JcnjMXXQ3zgF/vuVbIFiGtpw979bMxgA/Az7v7u9EXU82mdmHgD3uvjLqWoZYAjgXuMfdFwBHyI2pkm6Fc+ZXAlOB8UCJmV0TbVXDwoA/3/ItEBqBiWnPGwgONXOOmRUQhMGP3f3nYfNuM6sPt9cDe6KqLwsuAj5sZlsIpgLfb2YPkNtjhuDvdKO7vxQ+f4QgIHJ53JcCb7l7k7u3Az8HLiS3x5yuu3EO+PMt3wLhFWCmmU01s0KCBZjHIq5p0JmZEcwpr3X3b6Ztegy4Lnx8HfDoUNeWLe5+i7s3uPsUgv+uz7r7NeTwmAHcfRew3cxmh02XAGvI7XFvAxaZ2ejw7/olBOtkuTzmdN2N8zFgqZkVmdlUYCbw8mm9srvn1Q24AlgPbAK+HHU9WRrjewgOFV8HXgtvVwDVBGclbAjvq6KuNUvjvxj4Vfg458cMzAdWhP+9/x9QmevjBm4D1gGrgB8BRbk4ZuBBgnWSdoIjgOt7Gifw5fCz7U1gyem+ny5dISIiQP5NGYmISDcUCCIiAigQREQkpEAQERFAgSAiIiEFgoiIAAoEEREJ/X9kgjPFX7fHOQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/16 [=====================>........] - ETA: 0s - loss: 21062.8906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:26:57.125013: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step - loss: 20295.9668 - val_loss: 26007.0176\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 20001.4766 - val_loss: 25545.6113\n",
      "Epoch 3/100\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 24657.2031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:26:57.338221: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 7ms/step - loss: 19521.4297 - val_loss: 24780.1504\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 18723.6816 - val_loss: 23604.3613\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 17533.2695 - val_loss: 21946.5215\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 15941.4668 - val_loss: 19775.9180\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 14062.1523 - val_loss: 17324.4219\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11930.3799 - val_loss: 14521.6445\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9523.9355 - val_loss: 11550.3496\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 7232.4922 - val_loss: 8640.4443\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 4993.4912 - val_loss: 5997.0454\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3145.8135 - val_loss: 3683.9570\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1713.3297 - val_loss: 1973.6189\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 752.1866 - val_loss: 919.0411\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 315.7116 - val_loss: 511.3823\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 197.5293 - val_loss: 428.0562\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 170.9353 - val_loss: 407.5282\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 146.6593 - val_loss: 348.1553\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 127.0592 - val_loss: 310.6371\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 114.9090 - val_loss: 295.8510\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 104.6113 - val_loss: 268.1423\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 92.9443 - val_loss: 247.2054\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 84.8572 - val_loss: 229.3538\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 77.0140 - val_loss: 201.7999\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 72.2845 - val_loss: 186.2093\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 59.0149 - val_loss: 173.7579\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 55.5182 - val_loss: 150.7530\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 51.3484 - val_loss: 142.1102\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 45.8160 - val_loss: 131.4237\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 44.6801 - val_loss: 120.1493\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 39.2709 - val_loss: 116.7905\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.5270 - val_loss: 100.5444\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 34.5094 - val_loss: 99.4550\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 30.4752 - val_loss: 95.6966\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 27.2924 - val_loss: 98.1671\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 25.7158 - val_loss: 84.9758\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 24.5909 - val_loss: 79.4424\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 21.4249 - val_loss: 75.9159\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 20.3894 - val_loss: 68.6790\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 18.4144 - val_loss: 70.6016\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 16.3616 - val_loss: 60.7756\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 16.2674 - val_loss: 55.3197\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 13.9177 - val_loss: 62.0310\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 14.0974 - val_loss: 54.6419\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 11.9110 - val_loss: 48.2197\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 10.7956 - val_loss: 46.9278\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.8019 - val_loss: 47.6072\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 8.5012 - val_loss: 42.9894\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 9.1257 - val_loss: 40.6000\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.8204 - val_loss: 44.5509\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.0263 - val_loss: 42.1887\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 7.1228 - val_loss: 38.0013\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 6.7386 - val_loss: 36.4967\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.7689 - val_loss: 34.0198\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.3679 - val_loss: 32.8540\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.5236 - val_loss: 31.0799\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.9052 - val_loss: 31.0043\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 3.5792 - val_loss: 30.2463\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.0763 - val_loss: 29.3601\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.8533 - val_loss: 25.4276\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.5341 - val_loss: 24.8479\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.8027 - val_loss: 24.0358\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2446 - val_loss: 23.8677\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6325 - val_loss: 21.6421\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4262 - val_loss: 20.8108\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.9648 - val_loss: 20.2794\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2267 - val_loss: 19.6816\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2093 - val_loss: 22.0880\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.5645 - val_loss: 18.8649\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.2592 - val_loss: 18.8283\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 2.1514 - val_loss: 20.3156\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.1069 - val_loss: 19.7666\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2115 - val_loss: 18.3382\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8911 - val_loss: 18.9617\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2446 - val_loss: 17.9337\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5906 - val_loss: 18.2830\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0835 - val_loss: 17.9167\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9829 - val_loss: 17.0809\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.9505 - val_loss: 17.3412\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5618 - val_loss: 17.3624\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8491 - val_loss: 18.5296\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.6468 - val_loss: 20.0720\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.0188 - val_loss: 18.4419\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1450 - val_loss: 16.3732\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7614 - val_loss: 17.9888\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.7073 - val_loss: 17.7436\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4420 - val_loss: 16.5365\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5942 - val_loss: 18.3323\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.1430 - val_loss: 18.6233\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.0514 - val_loss: 18.6319\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7454 - val_loss: 18.1684\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8837 - val_loss: 18.9229\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.8342 - val_loss: 18.0493\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6526 - val_loss: 16.2311\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.7384 - val_loss: 16.4020\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5538 - val_loss: 15.9950\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5209 - val_loss: 16.2711\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3990 - val_loss: 15.6749\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.5994 - val_loss: 16.3934\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2535 - val_loss: 18.2438\n",
      "Train MSE: 1.918, Test MSE: 18.244\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train mse': 0.8111572861671448, 'test mse': 23.701637268066406, 'clip size': 1.0}\n",
      "{'train mse': 0.8086370229721069, 'test mse': 17.64940071105957, 'clip size': 2.0}\n",
      "{'train mse': 1.370605707168579, 'test mse': 16.970876693725586, 'clip size': 3.0}\n",
      "{'train mse': 0.3387235105037689, 'test mse': 17.982851028442383, 'clip size': 4.0}\n",
      "{'train mse': 0.5092090964317322, 'test mse': 17.870302200317383, 'clip size': 5.0}\n",
      "{'train mse': 1.917959213256836, 'test mse': 18.243789672851562, 'clip size': 6.0}\n"
     ]
    }
   ],
   "source": [
    "# mlp with unscaled data for the regression problem\n",
    "from sklearn.datasets    import make_regression\n",
    "from keras.layers        import Dense\n",
    "from keras.models        import Sequential\n",
    "from tensorflow.keras.optimizers    import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the regression dataset.\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "\n",
    "plt.hist(y)\n",
    "plt.title(\"Unscaled Input\")\n",
    "plt.show()\n",
    "\n",
    "# Split into train and test.\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "clipResults = []\n",
    "def buildModel(clipSize):\n",
    "    # Define the model.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25,input_dim=20, activation='relu',kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model.\n",
    "    opt = SGD(lr=0.01, momentum=0.9, clipnorm=0.9, clipvalue=clipSize)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "    # Fit the model.\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=1)\n",
    "\n",
    "    # Evaluate the model.\n",
    "    train_mse = model.evaluate(trainX, trainy, verbose=0)\n",
    "    test_mse = model.evaluate(testX, testy, verbose=0)\n",
    "    print('Train MSE: %.3f, Test MSE: %.3f' % (train_mse, test_mse))\n",
    "    clipResults.append({'train mse': train_mse, 'test mse':test_mse,\n",
    "                        'clip size':clipSize})\n",
    "    # Plot losses during training.\n",
    "    plt.title('Losses')\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "clipSizes = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
    "for i in range(0, len(clipSizes)):\n",
    "    buildModel(clipSizes[i])\n",
    "\n",
    "for clipResult in clipResults:\n",
    "    print(clipResult)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.8211"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:29:36.764495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-08 00:29:36.924504: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step - loss: 1.7262 - val_loss: 0.7397\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4603 - val_loss: 0.2742\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1773 - val_loss: 0.1660\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.1046 - val_loss: 0.1202\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0795 - val_loss: 0.0996\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0633 - val_loss: 0.0867\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0512 - val_loss: 0.0830\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0469 - val_loss: 0.0695\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0397 - val_loss: 0.0645\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0345 - val_loss: 0.0614\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0315 - val_loss: 0.0570\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0280 - val_loss: 0.0516\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0263 - val_loss: 0.0492\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0231 - val_loss: 0.0453\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0208 - val_loss: 0.0465\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0213 - val_loss: 0.0425\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0181 - val_loss: 0.0412\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0178 - val_loss: 0.0375\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0164 - val_loss: 0.0363\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0155 - val_loss: 0.0354\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0147 - val_loss: 0.0331\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0142 - val_loss: 0.0323\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0131 - val_loss: 0.0308\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0124 - val_loss: 0.0301\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0123 - val_loss: 0.0314\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0125 - val_loss: 0.0283\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0114 - val_loss: 0.0268\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0106 - val_loss: 0.0270\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0100 - val_loss: 0.0258\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0099 - val_loss: 0.0254\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0096 - val_loss: 0.0243\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0094 - val_loss: 0.0240\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0088 - val_loss: 0.0238\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0087 - val_loss: 0.0234\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0084 - val_loss: 0.0224\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0082 - val_loss: 0.0224\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0080 - val_loss: 0.0215\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0208\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0076 - val_loss: 0.0207\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0075 - val_loss: 0.0202\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0074 - val_loss: 0.0196\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0072 - val_loss: 0.0198\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0068 - val_loss: 0.0190\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0065 - val_loss: 0.0190\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0066 - val_loss: 0.0183\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0062 - val_loss: 0.0181\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0178\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0175\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0058 - val_loss: 0.0174\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0060 - val_loss: 0.0177\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0059 - val_loss: 0.0175\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0055 - val_loss: 0.0162\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0059 - val_loss: 0.0164\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0052 - val_loss: 0.0156\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0051 - val_loss: 0.0156\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0051 - val_loss: 0.0156\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0049 - val_loss: 0.0154\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0048 - val_loss: 0.0149\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0149\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0046 - val_loss: 0.0149\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.0144\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0045 - val_loss: 0.0139\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0044 - val_loss: 0.0141\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0047 - val_loss: 0.0137\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0043 - val_loss: 0.0139\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0042 - val_loss: 0.0134\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0040 - val_loss: 0.0133\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0042 - val_loss: 0.0130\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0041 - val_loss: 0.0130\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0127\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0040 - val_loss: 0.0128\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0038 - val_loss: 0.0124\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0038 - val_loss: 0.0132\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0041 - val_loss: 0.0124\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0121\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0035 - val_loss: 0.0121\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0037 - val_loss: 0.0124\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0119\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0119\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0036 - val_loss: 0.0116\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0034 - val_loss: 0.0113\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0112\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0033 - val_loss: 0.0110\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0116\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0035 - val_loss: 0.0108\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0033 - val_loss: 0.0109\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0034 - val_loss: 0.0123\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0036 - val_loss: 0.0111\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0031 - val_loss: 0.0108\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0032 - val_loss: 0.0103\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0103\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0101\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0030 - val_loss: 0.0101\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0105\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0099\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0097\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0096\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0096\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0030 - val_loss: 0.0096\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0094\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0092\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0029 - val_loss: 0.0093\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0092\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0028 - val_loss: 0.0092\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0027 - val_loss: 0.0094\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0091\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0026 - val_loss: 0.0088\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0088\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0027 - val_loss: 0.0087\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0087\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0086\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0026 - val_loss: 0.0085\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - val_loss: 0.0084\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0084\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0082\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0024 - val_loss: 0.0082\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0082\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0083\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0081\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0081\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0078\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0023 - val_loss: 0.0079\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0023 - val_loss: 0.0078\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0080\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0024 - val_loss: 0.0078\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0025 - val_loss: 0.0079\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0023 - val_loss: 0.0078\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0077\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0022 - val_loss: 0.0075\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0022 - val_loss: 0.0075\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0076\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0074\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0076\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0073\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0073\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0021 - val_loss: 0.0071\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0073\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0072\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0074\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0072\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0071\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0021 - val_loss: 0.0068\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0068\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.0020 - val_loss: 0.0069\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0020 - val_loss: 0.0068\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0069\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0019 - val_loss: 0.0065\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0065\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0019 - val_loss: 0.0066\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0064\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0018 - val_loss: 0.0062\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.0017 - val_loss: 0.0062\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0018 - val_loss: 0.0060\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0017 - val_loss: 0.0061\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0017 - val_loss: 0.0060\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0060\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0059\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0057\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0054\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0057\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0050\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0014 - val_loss: 0.0049\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.0013 - val_loss: 0.0049\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.0013 - val_loss: 0.0048\n",
      "Train loss: 0.001, Test loss: 0.005\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets   import make_regression\n",
    "from keras.layers       import Dense\n",
    "from keras.models       import Sequential\n",
    "from tensorflow.keras.optimizers   import SGD\n",
    "from matplotlib         import pyplot\n",
    "\n",
    "# Generate regression set.\n",
    "X, y = make_regression(n_samples=1000, n_features=20,\n",
    "                       noise=0.1, random_state=1)\n",
    "\n",
    "# Split data into train and test.\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "normSizeEvaluations = []\n",
    "\n",
    "# Define the model.\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu',\n",
    "                kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=SGD(lr=0.01, momentum=0.9))\n",
    "\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy  = testy.reshape(len(trainy), 1)\n",
    "\n",
    "# Scale y\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(trainy)\n",
    "trainy = scaler.transform(trainy)\n",
    "testy  = scaler.transform(testy)\n",
    "\n",
    "# Scale x\n",
    "xscaler = StandardScaler()\n",
    "xscaler.fit(trainX)\n",
    "trainX = xscaler.transform(trainX)\n",
    "testX  = xscaler.transform(testX)\n",
    "\n",
    "# Fit the model.\n",
    "history = model.fit(trainX, trainy,\n",
    "                    validation_data=(testX, testy),\n",
    "                    epochs=200, verbose=1)\n",
    "\n",
    "# Evaluate the model.\n",
    "train_mse = model.evaluate(trainX, trainy, verbose=0)\n",
    "test_mse  = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train loss: %.3f, Test loss: %.3f' % (train_mse, test_mse))\n",
    "\n",
    "normSizeEvaluations.append({'train mse':train_mse,\n",
    "                            'test mse':test_mse,\n",
    "                            'size':1})\n",
    "\n",
    "# Plot the loss during training.\n",
    "pyplot.title('Mean Squared Error - norm size: ')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scatter plot of blobs dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "# generate 2d classification dataset\n",
    "X, y = make_blobs(n_samples=1000, centers=3, n_features=2, cluster_std=2, random_state=2)\n",
    "# scatter plot for each class value\n",
    "for class_value in range(3):\n",
    "    # select indices of points with the class label\n",
    "    row_ix = where(y == class_value)\n",
    "    # scatter plot for points with a different color\n",
    "    pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n",
    "    # show plot\n",
    "pyplot.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanleung/miniforge3/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "2022-02-08 00:31:56.679334: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8360\n",
      " 1/16 [>.............................] - ETA: 0s - loss: 0.7426 - accuracy: 0.6875"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 00:32:05.587330: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8180\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8160\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8200\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4028 - accuracy: 0.8260\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.8200\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8220\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8180\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8320\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8340\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8300\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8280\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4080 - accuracy: 0.8340\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8300\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4125 - accuracy: 0.8140\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8340\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8220\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8260\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8320\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8260\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8260\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8100\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.8200\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.8160\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8240\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8300\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4043 - accuracy: 0.8160\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8340\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8360\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8300\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8340\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8200\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3997 - accuracy: 0.8260\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8260\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8300\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4126 - accuracy: 0.8160\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4087 - accuracy: 0.8320\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8340\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3960 - accuracy: 0.8320\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8320\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8180\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8240\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8220\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4144 - accuracy: 0.8240\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8180\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.8140\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8240\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8340\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8280\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8260\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8340\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8320\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8260\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8260\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8300\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8320\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8280\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8280\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8220\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8200\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8320\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8220\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8280\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8240\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8300\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8240\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8240\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8340\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8220\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.8260\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8300\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8260\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8260\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8160\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8280\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8180\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8280\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.8300\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8220\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8260\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3989 - accuracy: 0.8120\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8300\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8280\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8280\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8300\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8280\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8260\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8300\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4079 - accuracy: 0.8200\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8280\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8420\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8300\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3998 - accuracy: 0.8280\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.8140\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4089 - accuracy: 0.8200\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8300\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8240\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8380\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4016 - accuracy: 0.8260\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8160\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3997 - accuracy: 0.8260\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.8160\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.8180\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.8080\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8140\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8280\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8240\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8380\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8280\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8300\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8320\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4092 - accuracy: 0.8280\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8240\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.8160\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.8280\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8320\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8360\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8260\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8180\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8240\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8140\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8180\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8320\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4117 - accuracy: 0.8200\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8280\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8200\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8240\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8260\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8160\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8320\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8220\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8360\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4070 - accuracy: 0.8220\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8320\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8320\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8300\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4060 - accuracy: 0.8220\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8220\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.8320\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8320\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8240\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8340\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8300\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8300\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8260\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8320\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4035 - accuracy: 0.8300\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.8200\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8320\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8300\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8300\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8240\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8300\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8240\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4000 - accuracy: 0.8240\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8300\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8280\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.8300\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8140\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4031 - accuracy: 0.8280\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8260\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8200\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8300\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.8220\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8280\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4088 - accuracy: 0.8340\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3993 - accuracy: 0.8240\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8360\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8320\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8320\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4010 - accuracy: 0.8240\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8280\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8300\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8300\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8320\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4020 - accuracy: 0.8240\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8300\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8320\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8260\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8260\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8260\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8220\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3949 - accuracy: 0.8280\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8360\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8260\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8300\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8300\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8220\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4137 - accuracy: 0.8180\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8260\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8280\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3978 - accuracy: 0.8240\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8300\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3998 - accuracy: 0.8280\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8280\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8320\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8240\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8300\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4017 - accuracy: 0.8340\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8260\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8260\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8420\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8240\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8260\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8360\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4196 - accuracy: 0.8160\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8340\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8260\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8280\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4064 - accuracy: 0.8180\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8240\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8320\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4030 - accuracy: 0.8280\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8200\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8340\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8380\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4135 - accuracy: 0.8240\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8220\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8260\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8280\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8240\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8260\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3939 - accuracy: 0.8320\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8300\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.8220\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8220\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8180\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8200\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8320\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8360\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8300\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8280\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8300\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8320\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8280\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8240\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8280\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.3974 - accuracy: 0.8360\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8400\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8240\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8340\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8300\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8360\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8300\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8260\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8280\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8300\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4048 - accuracy: 0.8240\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8300\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8260\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8200\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8300\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8320\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4009 - accuracy: 0.8220\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8260\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8220\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8360\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8320\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8220\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8300\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8260\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8400\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8260\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8300\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8340\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8260\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8300\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8240\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8300\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8280\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8220\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8220\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8240\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8240\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4073 - accuracy: 0.8240\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8300\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8220\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8140\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8300\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8280\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8400\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8260\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8280\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4015 - accuracy: 0.8320\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8220\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8320\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8200\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8320\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8400\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8240\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.8140\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.8260\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8260\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8260\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8260\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8300\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4115 - accuracy: 0.8180\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8140\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8300\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8280\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8140\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8320\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8240\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8280\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8220\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8260\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8340\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4314 - accuracy: 0.8140\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4011 - accuracy: 0.8280\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8280\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8260\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8300\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8300\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8220\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8360\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8260\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4040 - accuracy: 0.8240\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8280\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8260\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8220\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8360\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8320\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8240\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8240\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3983 - accuracy: 0.8300\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8280\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4083 - accuracy: 0.8240\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4104 - accuracy: 0.8260\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8280\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8200\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8280\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8260\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8280\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8320\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8340\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8300\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8240\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8280\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8340\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.8300\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8120\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.8200\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8220\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8280\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8260\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8220\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8280\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8260\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8240\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8280\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8300\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8180\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8340\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8280\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8220\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8300\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4165 - accuracy: 0.8260\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.8180\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8260\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8220\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8280\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8280\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8280\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4041 - accuracy: 0.8200\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8200\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8220\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4025 - accuracy: 0.8300\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8280\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8240\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8280\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4011 - accuracy: 0.8280\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8200\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8300\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8280\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8280\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8300\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.8220\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8180\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8280\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4044 - accuracy: 0.8240\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8160\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8200\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4067 - accuracy: 0.8260\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3926 - accuracy: 0.8300\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8280\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8220\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8220\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8300\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8220\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8240\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3981 - accuracy: 0.8280\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8260\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8240\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8140\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8360\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3965 - accuracy: 0.8320\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8320\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.8260\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.8100\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4059 - accuracy: 0.8180\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8260\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8280\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8240\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8260\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8360\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8300\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8220\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8240\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8240\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4267 - accuracy: 0.8160\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3917 - accuracy: 0.8260\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8280\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8240\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8220\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8300\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3919 - accuracy: 0.8280\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3959 - accuracy: 0.8280\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3925 - accuracy: 0.8280\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8240\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8240\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8200\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8260\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3961 - accuracy: 0.8300\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8180\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8260\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8200\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3958 - accuracy: 0.8340\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3967 - accuracy: 0.8360\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8220\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3888 - accuracy: 0.8340\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8140\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8220\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3930 - accuracy: 0.8320\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3979 - accuracy: 0.8220\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8200\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8240\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.8140\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3926 - accuracy: 0.8260\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8260\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4145 - accuracy: 0.8220\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8240\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3956 - accuracy: 0.8260\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8280\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3971 - accuracy: 0.8200\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8240\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4006 - accuracy: 0.8340\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8200\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8240\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8260\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8200\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8180\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8260\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8260\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8260\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.8240\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8220\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8280\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8120\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3988 - accuracy: 0.8360\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8320\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8180\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8280\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8260\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8120\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8260\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.8260\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4031 - accuracy: 0.8140\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4144 - accuracy: 0.8160\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8260\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4049 - accuracy: 0.8160\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3960 - accuracy: 0.8200\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8340\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8180\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8240\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4050 - accuracy: 0.8220\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4071 - accuracy: 0.8260\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8180\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8380\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8200\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8240\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8260\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8220\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8220\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3884 - accuracy: 0.8340\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8280\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8240\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8320\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4136 - accuracy: 0.8200\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3931 - accuracy: 0.8140\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3973 - accuracy: 0.8260\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3937 - accuracy: 0.8380\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.8220\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3953 - accuracy: 0.8200\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8260\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8300\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8300\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8260\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8300\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8260\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8340\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8300\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8140\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8320\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8280\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8180\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8260\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8260\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8280\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8260\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8320\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8320\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.8180\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8320\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8280\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8200\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8300\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8300\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.8120\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8260\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8260\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8180\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8240\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8340\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8260\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8180\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8280\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8280\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8300\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3881 - accuracy: 0.8240\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8240\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8280\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8300\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8340\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8340\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8400\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8260\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8340\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8240\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8260\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8220\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8220\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8320\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3999 - accuracy: 0.8200\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3920 - accuracy: 0.8180\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4035 - accuracy: 0.8200\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8220\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8200\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.8300\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8400\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8340\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8280\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8220\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8240\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8300\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8340\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8140\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8260\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8220\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8360\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4176 - accuracy: 0.8120\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8260\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8220\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8340\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8300\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8300\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4139 - accuracy: 0.8100\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8160\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8220\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.8140\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8360\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4122 - accuracy: 0.8200\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.8180\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8340\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8300\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4032 - accuracy: 0.8140\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3947 - accuracy: 0.8340\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3969 - accuracy: 0.8200\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3937 - accuracy: 0.8320\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3968 - accuracy: 0.8220\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3947 - accuracy: 0.8260\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3946 - accuracy: 0.8280\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3949 - accuracy: 0.8300\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8320\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8240\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8340\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8180\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8300\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8340\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8260\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3990 - accuracy: 0.8240\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8260\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8360\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8280\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8240\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8220\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8220\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8300\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.8280\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3944 - accuracy: 0.8160\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8240\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.8380\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3923 - accuracy: 0.8180\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8320\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8240\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8160\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8340\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8180\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8200\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4132 - accuracy: 0.8220\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8340\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8180\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8160\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8400\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8280\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8160\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8260\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8240\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8280\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8240\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8320\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8240\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8220\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4046 - accuracy: 0.8180\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4077 - accuracy: 0.8180\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8140\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8280\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8320\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8340\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8220\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8180\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8200\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8160\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8300\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8220\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8120\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.8320\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.8080\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8300\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8320\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8220\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8260\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8320\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8340\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8280\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.8200\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8300\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8260\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8320\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8260\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8300\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8300\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.8340\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8280\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8240\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4043 - accuracy: 0.8260\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8260\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3954 - accuracy: 0.8240\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.8300\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8400\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8260\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8260\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4062 - accuracy: 0.8240\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8120\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8260\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.8160\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8240\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8280\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8380\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8300\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3908 - accuracy: 0.8180\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8340\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8220\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8300\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8260\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8360\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8260\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8240\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8280\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8280\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8260\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8300\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3906 - accuracy: 0.8200\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4013 - accuracy: 0.8360\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.8120\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8260\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8240\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8180\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8300\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8340\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8300\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8300\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8200\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8200\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8300\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4160 - accuracy: 0.8160\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8240\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8220\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8320\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8280\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8300\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8160\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8320\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4114 - accuracy: 0.8160\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8260\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8300\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8320\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8400\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8260\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8320\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8340\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3948 - accuracy: 0.8280\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8100\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4095 - accuracy: 0.8240\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.8220\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.8260\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8180\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3906 - accuracy: 0.8340\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8300\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8340\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.8240\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8180\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8260\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8320\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8240\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8320\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8400\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8280\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8240\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8300\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3877 - accuracy: 0.8200\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8340\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8220\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8280\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8300\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8340\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8120\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8340\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3906 - accuracy: 0.8300\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8260\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8200\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8280\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8280\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4054 - accuracy: 0.8080\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8320\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8160\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8220\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8300\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8300\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8340\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8240\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8320\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8180\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8360\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8160\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8260\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8340\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8180\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8440\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8300\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8260\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8220\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8300\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8320\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.8360\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8260\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8240\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8180\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8240\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8220\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8220\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3929 - accuracy: 0.8240\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3897 - accuracy: 0.8360\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3911 - accuracy: 0.8260\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8220\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8160\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8300\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8180\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8360\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8200\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8160\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8280\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8300\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8140\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8300\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8260\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8320\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8220\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4087 - accuracy: 0.8220\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3974 - accuracy: 0.8240\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8280\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4028 - accuracy: 0.8100\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8260\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8260\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8380\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8220\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8320\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8200\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8280\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8180\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8320\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8300\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8280\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8200\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8200\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8200\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8220\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8220\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8240\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3959 - accuracy: 0.8360\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8200\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8280\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8180\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8340\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8220\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8300\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8280\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8340\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.8240\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.8040\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8280\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3985 - accuracy: 0.8340\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4047 - accuracy: 0.8220\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8280\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8200\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3997 - accuracy: 0.8200\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3912 - accuracy: 0.8200\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3962 - accuracy: 0.8280\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4022 - accuracy: 0.8220\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8280\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8200\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8160\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8320\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8240\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4008 - accuracy: 0.8180\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4156 - accuracy: 0.8140\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8220\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8320\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8280\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8240\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8220\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8220\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8320\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3964 - accuracy: 0.8260\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8260\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3910 - accuracy: 0.8300\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8360\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8220\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8260\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8340\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8280\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8320\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.8220\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4232 - accuracy: 0.8100\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8260\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8260\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8280\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8340\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3894 - accuracy: 0.8360\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.8220\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8300\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8220\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8300\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8280\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8260\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8320\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8240\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8380\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8280\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8260\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8220\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3899 - accuracy: 0.8280\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3894 - accuracy: 0.8280\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8260\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.7960\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8380\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8220\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8300\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8340\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8280\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8320\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8260\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.3896 - accuracy: 0.8300\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8200\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8180\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8300\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4033 - accuracy: 0.8180\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8240\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8200\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8200\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8220\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8160\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8360\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8320\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8280\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4002 - accuracy: 0.8220\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8280\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8240\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8300\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8260\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8400\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8260\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8340\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8260\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8240\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.8400\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8320\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8340\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8300\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8360\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4007 - accuracy: 0.8180\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8240\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8240\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8300\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8280\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8280\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8280\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8340\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.8040\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3980 - accuracy: 0.8200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4129 - accuracy: 0.8280\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8200\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8260\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8300\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8320\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8140\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3923 - accuracy: 0.8240\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8320\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8240\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8320\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8280\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8320\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8260\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8200\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3887 - accuracy: 0.8320\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8120\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8200\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3980 - accuracy: 0.8320\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8120\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.8280\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8360\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3976 - accuracy: 0.8160\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8220\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3994 - accuracy: 0.8300\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8260\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8200\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8240\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3993 - accuracy: 0.8200\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3922 - accuracy: 0.8200\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8380\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3942 - accuracy: 0.8260\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8220\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8180\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3946 - accuracy: 0.8260\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8360\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3957 - accuracy: 0.8220\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8240\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3950 - accuracy: 0.8240\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3899 - accuracy: 0.8360\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3952 - accuracy: 0.8280\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8300\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8300\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8180\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8280\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8300\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8340\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8220\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8400\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8180\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3903 - accuracy: 0.8260\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8300\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8160\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8220\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8280\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8380\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8340\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8240\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.8140\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8320\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8280\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8260\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8300\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8340\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8280\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8260\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8360\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8380\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8200\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.8240\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3977 - accuracy: 0.8340\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8160\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8280\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8320\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8240\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8260\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8240\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3969 - accuracy: 0.8220\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8260\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3940 - accuracy: 0.8400\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.3934 - accuracy: 0.8280\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8280\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4017 - accuracy: 0.8160\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8320\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3929 - accuracy: 0.8260\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8340\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3958 - accuracy: 0.8160\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8200\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8300\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4072 - accuracy: 0.8240\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8080\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8180\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8280\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3906 - accuracy: 0.8300\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8320\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8260\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.8140\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8160\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8220\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8320\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.3936 - accuracy: 0.8160\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8400\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8380\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.8180\n",
      "    # layers  train_acc  test_acc  train_loss  test_loss\n",
      "0       -1.0      0.836     0.818    0.393851   0.416189\n",
      "1        0.0      0.818     0.808    0.428204   0.469397\n",
      "2        1.0      0.836     0.816    0.388880   0.419593\n",
      "3        2.0      0.834     0.814    0.392334   0.431365\n",
      "4        3.0      0.824     0.816    0.388609   0.426704\n",
      "5        4.0      0.832     0.818    0.386585   0.425790\n",
      "6        5.0      0.840     0.828    0.385974   0.421330\n",
      "7        6.0      0.826     0.818    0.386141   0.416238\n",
      "8        7.0      0.834     0.824    0.385063   0.418755\n",
      "9        8.0      0.820     0.828    0.398019   0.412926\n",
      "10       9.0      0.838     0.818    0.388168   0.434064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets   import make_blobs\n",
    "from keras.layers       import Dense\n",
    "from keras.models       import Sequential\n",
    "from tensorflow.keras.optimizers   import SGD\n",
    "from tensorflow.keras.utils        import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the data.\n",
    "def prepare_data():\n",
    "    X, y    = make_blobs(n_samples=1000, centers=3,\n",
    "                         n_features=2, cluster_std=2, random_state=2)\n",
    "    y       = to_categorical(y)\n",
    "    n_train = 500\n",
    "    trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "    trainy, testy = y[:n_train], y[n_train:]\n",
    "    return trainX, testX, trainy, testy\n",
    "\n",
    "# Build the base model.\n",
    "def get_base_model(trainX, trainy):\n",
    "    # Define the model.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=2, activation='relu',\n",
    "                    kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compile the model.\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model.\n",
    "    model.fit(trainX, trainy, epochs=100, verbose=0)\n",
    "    return model\n",
    "\n",
    "stats = []\n",
    "# Evaluate the model.\n",
    "def evaluate_model(numLayers, model, trainX, testX, trainy, testy):\n",
    "    train_loss, train_acc = model.evaluate(trainX, trainy, verbose=1)\n",
    "    test_loss, test_acc = model.evaluate(testX, testy, verbose=1)\n",
    "    stats.append({ '# layers':numLayers, 'train_acc':train_acc, 'test_acc':test_acc,\n",
    "                   'train_loss':train_loss, 'test_loss':test_loss })\n",
    "\n",
    "# Add one new layer and re-train only the new layer.\n",
    "def add_layer(model, trainX, trainy):\n",
    "    # Store the output layer.\n",
    "    output_layer = model.layers[-1]\n",
    "\n",
    "    # Remove the output layer.\n",
    "    model.pop()\n",
    "\n",
    "    # Mark all remaining layers as non-trainable.\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add a new hidden layer.\n",
    "    model.add(Dense(10, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "    # Add the output layer back.\n",
    "    model.add(output_layer)\n",
    "\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=100, verbose=1)\n",
    "    return model\n",
    "\n",
    "# Get the data and build the base model.\n",
    "trainX, testX, trainy, testy = prepare_data()\n",
    "model = get_base_model(trainX, trainy)\n",
    "\n",
    "# Evaluate the base model\n",
    "scores = dict()\n",
    "evaluate_model(-1, model, trainX, testX, trainy, testy)\n",
    "\n",
    "# add layers and evaluate the updated model\n",
    "n_layers = 10\n",
    "for i in range(n_layers):\n",
    "    model = add_layer(model, trainX, trainy)\n",
    "    evaluate_model(i, model, trainX, testX, trainy, testy)\n",
    "\n",
    "import pandas as pd\n",
    "columns = ['# layers', 'train_acc', 'test_acc', 'train_loss', 'test_loss']\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "for i in range(0, len(stats)):\n",
    "    df = df.append(stats[i], ignore_index=True)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "52/52 [==============================] - 0s 416us/step - loss: 48.4028 - accuracy: 0.5798\n",
      "Epoch 2/200\n",
      "52/52 [==============================] - 0s 389us/step - loss: 39.0134 - accuracy: 0.5875\n",
      "Epoch 3/200\n",
      "52/52 [==============================] - 0s 323us/step - loss: 8.0600 - accuracy: 0.6226\n",
      "Epoch 4/200\n",
      "52/52 [==============================] - 0s 341us/step - loss: 4.5995 - accuracy: 0.6712\n",
      "Epoch 5/200\n",
      "52/52 [==============================] - 0s 331us/step - loss: 0.9448 - accuracy: 0.6479\n",
      "Epoch 6/200\n",
      "52/52 [==============================] - 0s 314us/step - loss: 0.8069 - accuracy: 0.6848\n",
      "Epoch 7/200\n",
      "52/52 [==============================] - 0s 318us/step - loss: 0.6810 - accuracy: 0.6946\n",
      "Epoch 8/200\n",
      "52/52 [==============================] - 0s 322us/step - loss: 0.6948 - accuracy: 0.7043\n",
      "Epoch 9/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.7700 - accuracy: 0.6868\n",
      "Epoch 10/200\n",
      "52/52 [==============================] - 0s 310us/step - loss: 0.6729 - accuracy: 0.7082\n",
      "Epoch 11/200\n",
      "52/52 [==============================] - 0s 301us/step - loss: 0.6223 - accuracy: 0.7121\n",
      "Epoch 12/200\n",
      "52/52 [==============================] - 0s 303us/step - loss: 0.6211 - accuracy: 0.7276\n",
      "Epoch 13/200\n",
      "52/52 [==============================] - 0s 300us/step - loss: 0.6036 - accuracy: 0.7354\n",
      "Epoch 14/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.5522 - accuracy: 0.7335\n",
      "Epoch 15/200\n",
      "52/52 [==============================] - 0s 301us/step - loss: 0.6279 - accuracy: 0.7062\n",
      "Epoch 16/200\n",
      "52/52 [==============================] - 0s 314us/step - loss: 0.6636 - accuracy: 0.7276\n",
      "Epoch 17/200\n",
      "52/52 [==============================] - 0s 296us/step - loss: 0.6370 - accuracy: 0.7276\n",
      "Epoch 18/200\n",
      "52/52 [==============================] - 0s 303us/step - loss: 0.6034 - accuracy: 0.7432\n",
      "Epoch 19/200\n",
      "52/52 [==============================] - 0s 318us/step - loss: 0.6217 - accuracy: 0.7276\n",
      "Epoch 20/200\n",
      "52/52 [==============================] - 0s 345us/step - loss: 0.5699 - accuracy: 0.7374\n",
      "Epoch 21/200\n",
      "52/52 [==============================] - 0s 318us/step - loss: 0.5949 - accuracy: 0.7276\n",
      "Epoch 22/200\n",
      "52/52 [==============================] - 0s 319us/step - loss: 0.5667 - accuracy: 0.7471\n",
      "Epoch 23/200\n",
      "52/52 [==============================] - 0s 330us/step - loss: 0.5547 - accuracy: 0.7432\n",
      "Epoch 24/200\n",
      "52/52 [==============================] - 0s 323us/step - loss: 0.6007 - accuracy: 0.7549\n",
      "Epoch 25/200\n",
      "52/52 [==============================] - 0s 321us/step - loss: 0.6592 - accuracy: 0.7315\n",
      "Epoch 26/200\n",
      "52/52 [==============================] - 0s 311us/step - loss: 0.5162 - accuracy: 0.7432\n",
      "Epoch 27/200\n",
      "52/52 [==============================] - 0s 302us/step - loss: 0.6242 - accuracy: 0.7510\n",
      "Epoch 28/200\n",
      "52/52 [==============================] - 0s 308us/step - loss: 0.6568 - accuracy: 0.7335\n",
      "Epoch 29/200\n",
      "52/52 [==============================] - 0s 311us/step - loss: 0.5600 - accuracy: 0.7568\n",
      "Epoch 30/200\n",
      "52/52 [==============================] - 0s 330us/step - loss: 0.5208 - accuracy: 0.7529\n",
      "Epoch 31/200\n",
      "52/52 [==============================] - 0s 313us/step - loss: 0.6029 - accuracy: 0.7374\n",
      "Epoch 32/200\n",
      "52/52 [==============================] - 0s 371us/step - loss: 0.5509 - accuracy: 0.7490\n",
      "Epoch 33/200\n",
      "52/52 [==============================] - 0s 346us/step - loss: 0.5068 - accuracy: 0.7588\n",
      "Epoch 34/200\n",
      "52/52 [==============================] - 0s 316us/step - loss: 0.5517 - accuracy: 0.7646\n",
      "Epoch 35/200\n",
      "52/52 [==============================] - 0s 300us/step - loss: 0.5543 - accuracy: 0.7588\n",
      "Epoch 36/200\n",
      "52/52 [==============================] - 0s 307us/step - loss: 0.5803 - accuracy: 0.7510\n",
      "Epoch 37/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.5904 - accuracy: 0.7490\n",
      "Epoch 38/200\n",
      "52/52 [==============================] - 0s 314us/step - loss: 0.5117 - accuracy: 0.7607\n",
      "Epoch 39/200\n",
      "52/52 [==============================] - 0s 314us/step - loss: 0.5499 - accuracy: 0.7685\n",
      "Epoch 40/200\n",
      "52/52 [==============================] - 0s 328us/step - loss: 0.5595 - accuracy: 0.7743\n",
      "Epoch 41/200\n",
      "52/52 [==============================] - 0s 310us/step - loss: 0.6296 - accuracy: 0.7393\n",
      "Epoch 42/200\n",
      "52/52 [==============================] - 0s 324us/step - loss: 0.5769 - accuracy: 0.7432\n",
      "Epoch 43/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.5248 - accuracy: 0.7607\n",
      "Epoch 44/200\n",
      "52/52 [==============================] - 0s 335us/step - loss: 0.5970 - accuracy: 0.7432\n",
      "Epoch 45/200\n",
      "52/52 [==============================] - 0s 320us/step - loss: 0.5373 - accuracy: 0.7490\n",
      "Epoch 46/200\n",
      "52/52 [==============================] - 0s 304us/step - loss: 0.5287 - accuracy: 0.7665\n",
      "Epoch 47/200\n",
      "52/52 [==============================] - 0s 294us/step - loss: 0.4965 - accuracy: 0.7743\n",
      "Epoch 48/200\n",
      "52/52 [==============================] - 0s 311us/step - loss: 0.5442 - accuracy: 0.7451\n",
      "Epoch 49/200\n",
      "52/52 [==============================] - 0s 297us/step - loss: 0.5174 - accuracy: 0.7646\n",
      "Epoch 50/200\n",
      "52/52 [==============================] - 0s 305us/step - loss: 0.5370 - accuracy: 0.7529\n",
      "Epoch 51/200\n",
      "52/52 [==============================] - 0s 300us/step - loss: 0.4960 - accuracy: 0.7665\n",
      "Epoch 52/200\n",
      "52/52 [==============================] - 0s 304us/step - loss: 0.4983 - accuracy: 0.7588\n",
      "Epoch 53/200\n",
      "52/52 [==============================] - 0s 297us/step - loss: 0.5170 - accuracy: 0.7549\n",
      "Epoch 54/200\n",
      "52/52 [==============================] - 0s 308us/step - loss: 0.5145 - accuracy: 0.7451\n",
      "Epoch 55/200\n",
      "52/52 [==============================] - 0s 303us/step - loss: 0.5677 - accuracy: 0.7588\n",
      "Epoch 56/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.4750 - accuracy: 0.7607\n",
      "Epoch 57/200\n",
      "52/52 [==============================] - 0s 313us/step - loss: 0.5129 - accuracy: 0.7607\n",
      "Epoch 58/200\n",
      "52/52 [==============================] - 0s 329us/step - loss: 0.5652 - accuracy: 0.7510\n",
      "Epoch 59/200\n",
      "52/52 [==============================] - 0s 331us/step - loss: 0.5247 - accuracy: 0.7510\n",
      "Epoch 60/200\n",
      "52/52 [==============================] - 0s 307us/step - loss: 0.4964 - accuracy: 0.7782\n",
      "Epoch 61/200\n",
      "52/52 [==============================] - 0s 294us/step - loss: 0.4822 - accuracy: 0.7821\n",
      "Epoch 62/200\n",
      "52/52 [==============================] - 0s 316us/step - loss: 0.5258 - accuracy: 0.7510\n",
      "Epoch 63/200\n",
      "52/52 [==============================] - 0s 297us/step - loss: 0.5320 - accuracy: 0.7724\n",
      "Epoch 64/200\n",
      "52/52 [==============================] - 0s 299us/step - loss: 0.4724 - accuracy: 0.7763\n",
      "Epoch 65/200\n",
      "52/52 [==============================] - 0s 331us/step - loss: 0.5445 - accuracy: 0.7685\n",
      "Epoch 66/200\n",
      "52/52 [==============================] - 0s 310us/step - loss: 0.5071 - accuracy: 0.7529\n",
      "Epoch 67/200\n",
      "52/52 [==============================] - 0s 302us/step - loss: 0.5096 - accuracy: 0.7626\n",
      "Epoch 68/200\n",
      "52/52 [==============================] - 0s 338us/step - loss: 0.4784 - accuracy: 0.7588\n",
      "Epoch 69/200\n",
      "52/52 [==============================] - 0s 320us/step - loss: 0.5329 - accuracy: 0.7471\n",
      "Epoch 70/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.5317 - accuracy: 0.7471\n",
      "Epoch 71/200\n",
      "52/52 [==============================] - 0s 323us/step - loss: 0.5073 - accuracy: 0.7724\n",
      "Epoch 72/200\n",
      "52/52 [==============================] - 0s 307us/step - loss: 0.5633 - accuracy: 0.7393\n",
      "Epoch 73/200\n",
      "52/52 [==============================] - 0s 298us/step - loss: 0.4919 - accuracy: 0.7724\n",
      "Epoch 74/200\n",
      "52/52 [==============================] - 0s 309us/step - loss: 0.5507 - accuracy: 0.7412\n",
      "Epoch 75/200\n",
      "52/52 [==============================] - 0s 304us/step - loss: 0.5061 - accuracy: 0.7821\n",
      "Epoch 76/200\n",
      "52/52 [==============================] - 0s 310us/step - loss: 0.5010 - accuracy: 0.7704\n",
      "Epoch 77/200\n",
      "52/52 [==============================] - 0s 304us/step - loss: 0.5065 - accuracy: 0.7782\n",
      "Epoch 78/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.5010 - accuracy: 0.7763\n",
      "Epoch 79/200\n",
      "52/52 [==============================] - 0s 302us/step - loss: 0.4859 - accuracy: 0.7685\n",
      "Epoch 80/200\n",
      "52/52 [==============================] - 0s 303us/step - loss: 0.4839 - accuracy: 0.7568\n",
      "Epoch 81/200\n",
      "52/52 [==============================] - 0s 309us/step - loss: 0.4888 - accuracy: 0.7626\n",
      "Epoch 82/200\n",
      "52/52 [==============================] - 0s 306us/step - loss: 0.5053 - accuracy: 0.7646\n",
      "Epoch 83/200\n",
      "52/52 [==============================] - 0s 306us/step - loss: 0.5071 - accuracy: 0.7646\n",
      "Epoch 84/200\n",
      "52/52 [==============================] - 0s 316us/step - loss: 0.5573 - accuracy: 0.7724\n",
      "Epoch 85/200\n",
      "52/52 [==============================] - 0s 303us/step - loss: 0.6102 - accuracy: 0.7393\n",
      "Epoch 86/200\n",
      "52/52 [==============================] - 0s 313us/step - loss: 0.4994 - accuracy: 0.7665\n",
      "Epoch 87/200\n",
      "52/52 [==============================] - 0s 309us/step - loss: 0.4675 - accuracy: 0.7626\n",
      "Epoch 88/200\n",
      "52/52 [==============================] - 0s 315us/step - loss: 0.5053 - accuracy: 0.7665\n",
      "Epoch 89/200\n",
      "52/52 [==============================] - 0s 303us/step - loss: 0.5001 - accuracy: 0.7101\n",
      "Epoch 90/200\n",
      "52/52 [==============================] - 0s 318us/step - loss: 0.5147 - accuracy: 0.7763\n",
      "Epoch 91/200\n",
      "52/52 [==============================] - 0s 313us/step - loss: 0.5070 - accuracy: 0.7724\n",
      "Epoch 92/200\n",
      "52/52 [==============================] - 0s 363us/step - loss: 0.5139 - accuracy: 0.7626\n",
      "Epoch 93/200\n",
      "52/52 [==============================] - 0s 308us/step - loss: 0.5295 - accuracy: 0.7490\n",
      "Epoch 94/200\n",
      "52/52 [==============================] - 0s 315us/step - loss: 0.5059 - accuracy: 0.7588\n",
      "Epoch 95/200\n",
      "52/52 [==============================] - 0s 330us/step - loss: 0.4998 - accuracy: 0.7646\n",
      "Epoch 96/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.4925 - accuracy: 0.7607\n",
      "Epoch 97/200\n",
      "52/52 [==============================] - 0s 309us/step - loss: 0.4890 - accuracy: 0.7607\n",
      "Epoch 98/200\n",
      "52/52 [==============================] - 0s 326us/step - loss: 0.5008 - accuracy: 0.7626\n",
      "Epoch 99/200\n",
      "52/52 [==============================] - 0s 315us/step - loss: 0.4985 - accuracy: 0.7957\n",
      "Epoch 100/200\n",
      "52/52 [==============================] - 0s 313us/step - loss: 0.4974 - accuracy: 0.7704\n",
      "Epoch 101/200\n",
      "52/52 [==============================] - 0s 320us/step - loss: 0.4796 - accuracy: 0.7646\n",
      "Epoch 102/200\n",
      "52/52 [==============================] - 0s 314us/step - loss: 0.5359 - accuracy: 0.7588\n",
      "Epoch 103/200\n",
      "52/52 [==============================] - 0s 309us/step - loss: 0.4789 - accuracy: 0.7743\n",
      "Epoch 104/200\n",
      "52/52 [==============================] - 0s 328us/step - loss: 0.4583 - accuracy: 0.7802\n",
      "Epoch 105/200\n",
      "52/52 [==============================] - 0s 303us/step - loss: 0.5085 - accuracy: 0.7588\n",
      "Epoch 106/200\n",
      "52/52 [==============================] - 0s 304us/step - loss: 0.5021 - accuracy: 0.7568\n",
      "Epoch 107/200\n",
      "52/52 [==============================] - 0s 308us/step - loss: 0.4621 - accuracy: 0.7510\n",
      "Epoch 108/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.5070 - accuracy: 0.7549\n",
      "Epoch 109/200\n",
      "52/52 [==============================] - 0s 298us/step - loss: 0.4705 - accuracy: 0.7763\n",
      "Epoch 110/200\n",
      "52/52 [==============================] - 0s 308us/step - loss: 0.4935 - accuracy: 0.7724\n",
      "Epoch 111/200\n",
      "52/52 [==============================] - 0s 303us/step - loss: 0.4890 - accuracy: 0.7665\n",
      "Epoch 112/200\n",
      "52/52 [==============================] - 0s 310us/step - loss: 0.4981 - accuracy: 0.7510\n",
      "Epoch 113/200\n",
      "52/52 [==============================] - 0s 299us/step - loss: 0.5359 - accuracy: 0.7393\n",
      "Epoch 114/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.4927 - accuracy: 0.7549\n",
      "Epoch 115/200\n",
      "52/52 [==============================] - 0s 308us/step - loss: 0.5022 - accuracy: 0.7665\n",
      "Epoch 116/200\n",
      "52/52 [==============================] - 0s 315us/step - loss: 0.5081 - accuracy: 0.7685\n",
      "Epoch 117/200\n",
      "52/52 [==============================] - 0s 308us/step - loss: 0.4808 - accuracy: 0.7724\n",
      "Epoch 118/200\n",
      "52/52 [==============================] - 0s 308us/step - loss: 0.4672 - accuracy: 0.7802\n",
      "Epoch 119/200\n",
      "52/52 [==============================] - 0s 306us/step - loss: 0.4978 - accuracy: 0.7704\n",
      "Epoch 120/200\n",
      "52/52 [==============================] - 0s 323us/step - loss: 0.4990 - accuracy: 0.7685\n",
      "Epoch 121/200\n",
      "52/52 [==============================] - 0s 303us/step - loss: 0.5729 - accuracy: 0.7412\n",
      "Epoch 122/200\n",
      "52/52 [==============================] - 0s 297us/step - loss: 0.4578 - accuracy: 0.7860\n",
      "Epoch 123/200\n",
      "52/52 [==============================] - 0s 320us/step - loss: 0.5157 - accuracy: 0.7471\n",
      "Epoch 124/200\n",
      "52/52 [==============================] - 0s 313us/step - loss: 0.4607 - accuracy: 0.7646\n",
      "Epoch 125/200\n",
      "52/52 [==============================] - 0s 305us/step - loss: 0.4763 - accuracy: 0.7802\n",
      "Epoch 126/200\n",
      "52/52 [==============================] - 0s 305us/step - loss: 0.4683 - accuracy: 0.7782\n",
      "Epoch 127/200\n",
      "52/52 [==============================] - 0s 301us/step - loss: 0.4983 - accuracy: 0.7490\n",
      "Epoch 128/200\n",
      "52/52 [==============================] - 0s 305us/step - loss: 0.4866 - accuracy: 0.7802\n",
      "Epoch 129/200\n",
      "52/52 [==============================] - 0s 306us/step - loss: 0.5015 - accuracy: 0.7840\n",
      "Epoch 130/200\n",
      "52/52 [==============================] - 0s 304us/step - loss: 0.5341 - accuracy: 0.7471\n",
      "Epoch 131/200\n",
      "52/52 [==============================] - 0s 302us/step - loss: 0.4700 - accuracy: 0.7782\n",
      "Epoch 132/200\n",
      "52/52 [==============================] - 0s 317us/step - loss: 0.4623 - accuracy: 0.7899\n",
      "Epoch 133/200\n",
      "52/52 [==============================] - 0s 301us/step - loss: 0.5066 - accuracy: 0.7646\n",
      "Epoch 134/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.4849 - accuracy: 0.7626\n",
      "Epoch 135/200\n",
      "52/52 [==============================] - 0s 305us/step - loss: 0.5247 - accuracy: 0.7549\n",
      "Epoch 136/200\n",
      "52/52 [==============================] - 0s 303us/step - loss: 0.4888 - accuracy: 0.7821\n",
      "Epoch 137/200\n",
      "52/52 [==============================] - 0s 298us/step - loss: 0.5303 - accuracy: 0.7724\n",
      "Epoch 138/200\n",
      "52/52 [==============================] - 0s 324us/step - loss: 0.4600 - accuracy: 0.7782\n",
      "Epoch 139/200\n",
      "52/52 [==============================] - 0s 313us/step - loss: 0.4502 - accuracy: 0.7821\n",
      "Epoch 140/200\n",
      "52/52 [==============================] - 0s 308us/step - loss: 0.4858 - accuracy: 0.7782\n",
      "Epoch 141/200\n",
      "52/52 [==============================] - 0s 305us/step - loss: 0.4821 - accuracy: 0.7685\n",
      "Epoch 142/200\n",
      "52/52 [==============================] - 0s 327us/step - loss: 0.4638 - accuracy: 0.7782\n",
      "Epoch 143/200\n",
      "52/52 [==============================] - 0s 311us/step - loss: 0.4681 - accuracy: 0.8035\n",
      "Epoch 144/200\n",
      "52/52 [==============================] - 0s 350us/step - loss: 0.4451 - accuracy: 0.7860\n",
      "Epoch 145/200\n",
      "52/52 [==============================] - 0s 327us/step - loss: 0.5065 - accuracy: 0.7568\n",
      "Epoch 146/200\n",
      "52/52 [==============================] - 0s 337us/step - loss: 0.4685 - accuracy: 0.7879\n",
      "Epoch 147/200\n",
      "52/52 [==============================] - 0s 311us/step - loss: 0.4927 - accuracy: 0.7724\n",
      "Epoch 148/200\n",
      "52/52 [==============================] - 0s 330us/step - loss: 0.4503 - accuracy: 0.7879\n",
      "Epoch 149/200\n",
      "52/52 [==============================] - 0s 332us/step - loss: 0.4568 - accuracy: 0.7665\n",
      "Epoch 150/200\n",
      "52/52 [==============================] - 0s 355us/step - loss: 0.4415 - accuracy: 0.7763\n",
      "Epoch 151/200\n",
      "52/52 [==============================] - 0s 356us/step - loss: 0.4743 - accuracy: 0.7802\n",
      "Epoch 152/200\n",
      "52/52 [==============================] - 0s 369us/step - loss: 0.4367 - accuracy: 0.7879\n",
      "Epoch 153/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.4784 - accuracy: 0.7763\n",
      "Epoch 154/200\n",
      "52/52 [==============================] - 0s 360us/step - loss: 0.4529 - accuracy: 0.7724\n",
      "Epoch 155/200\n",
      "52/52 [==============================] - 0s 321us/step - loss: 0.4717 - accuracy: 0.7704\n",
      "Epoch 156/200\n",
      "52/52 [==============================] - 0s 344us/step - loss: 0.4819 - accuracy: 0.7821\n",
      "Epoch 157/200\n",
      "52/52 [==============================] - 0s 338us/step - loss: 0.4766 - accuracy: 0.7704\n",
      "Epoch 158/200\n",
      "52/52 [==============================] - 0s 332us/step - loss: 0.4831 - accuracy: 0.7704\n",
      "Epoch 159/200\n",
      "52/52 [==============================] - 0s 324us/step - loss: 0.5560 - accuracy: 0.7665\n",
      "Epoch 160/200\n",
      "52/52 [==============================] - 0s 342us/step - loss: 0.4836 - accuracy: 0.7724\n",
      "Epoch 161/200\n",
      "52/52 [==============================] - 0s 317us/step - loss: 0.4788 - accuracy: 0.7568\n",
      "Epoch 162/200\n",
      "52/52 [==============================] - 0s 332us/step - loss: 0.4660 - accuracy: 0.7685\n",
      "Epoch 163/200\n",
      "52/52 [==============================] - 0s 321us/step - loss: 0.4744 - accuracy: 0.7607\n",
      "Epoch 164/200\n",
      "52/52 [==============================] - 0s 390us/step - loss: 0.5196 - accuracy: 0.7315\n",
      "Epoch 165/200\n",
      "52/52 [==============================] - 0s 392us/step - loss: 0.4692 - accuracy: 0.7821\n",
      "Epoch 166/200\n",
      "52/52 [==============================] - 0s 395us/step - loss: 0.4454 - accuracy: 0.7724\n",
      "Epoch 167/200\n",
      "52/52 [==============================] - 0s 366us/step - loss: 0.5062 - accuracy: 0.7704\n",
      "Epoch 168/200\n",
      "52/52 [==============================] - 0s 345us/step - loss: 0.5304 - accuracy: 0.7646\n",
      "Epoch 169/200\n",
      "52/52 [==============================] - 0s 312us/step - loss: 0.4618 - accuracy: 0.7724\n",
      "Epoch 170/200\n",
      "52/52 [==============================] - 0s 313us/step - loss: 0.4788 - accuracy: 0.7549\n",
      "Epoch 171/200\n",
      "52/52 [==============================] - 0s 341us/step - loss: 0.4708 - accuracy: 0.7724\n",
      "Epoch 172/200\n",
      "52/52 [==============================] - 0s 316us/step - loss: 0.4619 - accuracy: 0.7763\n",
      "Epoch 173/200\n",
      "52/52 [==============================] - 0s 350us/step - loss: 0.4904 - accuracy: 0.7568\n",
      "Epoch 174/200\n",
      "52/52 [==============================] - 0s 316us/step - loss: 0.4495 - accuracy: 0.7626\n",
      "Epoch 175/200\n",
      "52/52 [==============================] - 0s 324us/step - loss: 0.4567 - accuracy: 0.7802\n",
      "Epoch 176/200\n",
      "52/52 [==============================] - 0s 316us/step - loss: 0.5376 - accuracy: 0.7549\n",
      "Epoch 177/200\n",
      "52/52 [==============================] - 0s 330us/step - loss: 0.5265 - accuracy: 0.7685\n",
      "Epoch 178/200\n",
      "52/52 [==============================] - 0s 437us/step - loss: 0.4475 - accuracy: 0.7899\n",
      "Epoch 179/200\n",
      "52/52 [==============================] - 0s 396us/step - loss: 0.4313 - accuracy: 0.7840\n",
      "Epoch 180/200\n",
      "52/52 [==============================] - 0s 343us/step - loss: 0.4175 - accuracy: 0.7957\n",
      "Epoch 181/200\n",
      "52/52 [==============================] - 0s 339us/step - loss: 0.4381 - accuracy: 0.7918\n",
      "Epoch 182/200\n",
      "52/52 [==============================] - 0s 296us/step - loss: 0.4259 - accuracy: 0.8035\n",
      "Epoch 183/200\n",
      "52/52 [==============================] - 0s 302us/step - loss: 0.4312 - accuracy: 0.8016\n",
      "Epoch 184/200\n",
      "52/52 [==============================] - 0s 298us/step - loss: 0.4300 - accuracy: 0.7918\n",
      "Epoch 185/200\n",
      "52/52 [==============================] - 0s 322us/step - loss: 0.4651 - accuracy: 0.7879\n",
      "Epoch 186/200\n",
      "52/52 [==============================] - 0s 292us/step - loss: 0.4390 - accuracy: 0.7918\n",
      "Epoch 187/200\n",
      "52/52 [==============================] - 0s 308us/step - loss: 0.4388 - accuracy: 0.7879\n",
      "Epoch 188/200\n",
      "52/52 [==============================] - 0s 294us/step - loss: 0.5264 - accuracy: 0.7568\n",
      "Epoch 189/200\n",
      "52/52 [==============================] - 0s 297us/step - loss: 0.4750 - accuracy: 0.7685\n",
      "Epoch 190/200\n",
      "52/52 [==============================] - 0s 297us/step - loss: 0.4229 - accuracy: 0.8016\n",
      "Epoch 191/200\n",
      "52/52 [==============================] - 0s 305us/step - loss: 0.4343 - accuracy: 0.7918\n",
      "Epoch 192/200\n",
      "52/52 [==============================] - 0s 297us/step - loss: 0.4670 - accuracy: 0.7588\n",
      "Epoch 193/200\n",
      "52/52 [==============================] - 0s 299us/step - loss: 0.4529 - accuracy: 0.7840\n",
      "Epoch 194/200\n",
      "52/52 [==============================] - 0s 293us/step - loss: 0.4398 - accuracy: 0.7821\n",
      "Epoch 195/200\n",
      "52/52 [==============================] - 0s 291us/step - loss: 0.4142 - accuracy: 0.8035\n",
      "Epoch 196/200\n",
      "52/52 [==============================] - 0s 287us/step - loss: 0.4810 - accuracy: 0.7724\n",
      "Epoch 197/200\n",
      "52/52 [==============================] - 0s 294us/step - loss: 0.4523 - accuracy: 0.7743\n",
      "Epoch 198/200\n",
      "52/52 [==============================] - 0s 294us/step - loss: 0.4992 - accuracy: 0.7646\n",
      "Epoch 199/200\n",
      "52/52 [==============================] - 0s 303us/step - loss: 0.4586 - accuracy: 0.7821\n",
      "Epoch 200/200\n",
      "52/52 [==============================] - 0s 292us/step - loss: 0.5046 - accuracy: 0.7665\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4852 - accuracy: 0.7821\n",
      "8/8 [==============================] - 0s 426us/step - loss: 1.0502 - accuracy: 0.6811\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.4304 - accuracy: 0.8016\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.7470 - accuracy: 0.7374\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.6026 - accuracy: 0.7704\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.5129 - accuracy: 0.7432\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.4448 - accuracy: 0.7665\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4269 - accuracy: 0.7743\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4101 - accuracy: 0.7782\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.4124 - accuracy: 0.7938\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.4134 - accuracy: 0.7996\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4078 - accuracy: 0.8035\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3954 - accuracy: 0.8093\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4324 - accuracy: 0.7938\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.3955 - accuracy: 0.8093\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 415us/step - loss: 0.3883 - accuracy: 0.8132\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.3897 - accuracy: 0.8152\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3945 - accuracy: 0.8152\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3897 - accuracy: 0.8035\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3895 - accuracy: 0.8113\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3951 - accuracy: 0.8054\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.4012 - accuracy: 0.8054\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3862 - accuracy: 0.8152\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3812 - accuracy: 0.8113\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3831 - accuracy: 0.8191\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3905 - accuracy: 0.8074\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3946 - accuracy: 0.8035\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3770 - accuracy: 0.8210\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3859 - accuracy: 0.8113\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.3896 - accuracy: 0.8171\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4014 - accuracy: 0.7840\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3889 - accuracy: 0.8171\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3795 - accuracy: 0.8152\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3888 - accuracy: 0.8093\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3868 - accuracy: 0.8268\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3827 - accuracy: 0.8074\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3725 - accuracy: 0.8113\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3774 - accuracy: 0.8210\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3782 - accuracy: 0.8307\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3934 - accuracy: 0.8074\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.3858 - accuracy: 0.8113\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3743 - accuracy: 0.8268\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3877 - accuracy: 0.8152\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4207 - accuracy: 0.7938\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3957 - accuracy: 0.8054\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3947 - accuracy: 0.8171\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3811 - accuracy: 0.8249\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3739 - accuracy: 0.8268\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.3702 - accuracy: 0.8171\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3742 - accuracy: 0.8132\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3750 - accuracy: 0.8366\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 419us/step - loss: 0.4207 - accuracy: 0.7996\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.4017 - accuracy: 0.7918\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3863 - accuracy: 0.8171\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3797 - accuracy: 0.8132\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3791 - accuracy: 0.8016\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3832 - accuracy: 0.8113\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3793 - accuracy: 0.8171\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3804 - accuracy: 0.8132\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3749 - accuracy: 0.8268\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4200 - accuracy: 0.7957\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4135 - accuracy: 0.8035\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.4009 - accuracy: 0.7938\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3890 - accuracy: 0.8016\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3799 - accuracy: 0.8132\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.4290 - accuracy: 0.7938\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4000 - accuracy: 0.8016\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3842 - accuracy: 0.8016\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3749 - accuracy: 0.8171\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.3770 - accuracy: 0.8268\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3753 - accuracy: 0.8230\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3811 - accuracy: 0.8288\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4098 - accuracy: 0.7802\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 411us/step - loss: 0.3968 - accuracy: 0.8054\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3746 - accuracy: 0.8035\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3808 - accuracy: 0.8152\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.4077 - accuracy: 0.7957\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3959 - accuracy: 0.8016\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 315us/step - loss: 0.4097 - accuracy: 0.8016\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3849 - accuracy: 0.8113\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3844 - accuracy: 0.8113\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4087 - accuracy: 0.7938\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4466 - accuracy: 0.7782\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.4014 - accuracy: 0.8093\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.5229 - accuracy: 0.7412\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4367 - accuracy: 0.7802\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.3939 - accuracy: 0.7996\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4007 - accuracy: 0.8054\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3798 - accuracy: 0.8093\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4112 - accuracy: 0.7879\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3963 - accuracy: 0.8307\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.4253 - accuracy: 0.7899\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3888 - accuracy: 0.8054\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4021 - accuracy: 0.8113\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3732 - accuracy: 0.8210\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3750 - accuracy: 0.8210\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3804 - accuracy: 0.8074\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3819 - accuracy: 0.8307\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 428us/step - loss: 0.3786 - accuracy: 0.8249\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3762 - accuracy: 0.8230\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3695 - accuracy: 0.8249\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3730 - accuracy: 0.8230\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3753 - accuracy: 0.8191\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4262 - accuracy: 0.7840\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3910 - accuracy: 0.8035\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.4102 - accuracy: 0.7996\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3770 - accuracy: 0.8191\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3776 - accuracy: 0.8152\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3650 - accuracy: 0.8385\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 431us/step - loss: 0.3681 - accuracy: 0.8346\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3671 - accuracy: 0.8346\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3990 - accuracy: 0.8016\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3875 - accuracy: 0.8113\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3762 - accuracy: 0.8268\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3642 - accuracy: 0.8210\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3967 - accuracy: 0.8035\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3891 - accuracy: 0.8210\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.4205 - accuracy: 0.8093\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3913 - accuracy: 0.8074\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4343 - accuracy: 0.7802\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4039 - accuracy: 0.7957\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 405us/step - loss: 0.3831 - accuracy: 0.8152\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3759 - accuracy: 0.8093\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3830 - accuracy: 0.8230\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3706 - accuracy: 0.8230\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3701 - accuracy: 0.8152\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.4788 - accuracy: 0.7860\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.4186 - accuracy: 0.8074\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.4101 - accuracy: 0.8093\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4978 - accuracy: 0.7763\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.5872 - accuracy: 0.7354\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4585 - accuracy: 0.7879\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4010 - accuracy: 0.8016\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.4100 - accuracy: 0.8171\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3995 - accuracy: 0.8113\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3985 - accuracy: 0.8016\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3901 - accuracy: 0.8054\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3762 - accuracy: 0.8210\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3746 - accuracy: 0.8268\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3659 - accuracy: 0.8171\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.4027 - accuracy: 0.8132\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3797 - accuracy: 0.8210\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4005 - accuracy: 0.7918\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3793 - accuracy: 0.8307\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3820 - accuracy: 0.8210\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4025 - accuracy: 0.8132\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3809 - accuracy: 0.8249\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3758 - accuracy: 0.8288\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3818 - accuracy: 0.7996\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4000 - accuracy: 0.8191\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 513us/step - loss: 0.3774 - accuracy: 0.8191\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3764 - accuracy: 0.8249\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3830 - accuracy: 0.8385\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3625 - accuracy: 0.8268\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.3651 - accuracy: 0.8171\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3769 - accuracy: 0.8249\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3728 - accuracy: 0.8230\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 423us/step - loss: 0.3701 - accuracy: 0.8210\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3666 - accuracy: 0.8288\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3849 - accuracy: 0.8093\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3661 - accuracy: 0.8288\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3605 - accuracy: 0.8210\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3581 - accuracy: 0.8346\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3791 - accuracy: 0.8288\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3740 - accuracy: 0.8230\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3565 - accuracy: 0.8385\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3821 - accuracy: 0.8152\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3949 - accuracy: 0.8191\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3927 - accuracy: 0.7938\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4162 - accuracy: 0.8171\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3812 - accuracy: 0.8152\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3844 - accuracy: 0.8171\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3741 - accuracy: 0.8288\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3719 - accuracy: 0.8152\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3942 - accuracy: 0.8113\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.4007 - accuracy: 0.7763\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4106 - accuracy: 0.7957\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.4157 - accuracy: 0.7938\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4017 - accuracy: 0.8093\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.3965 - accuracy: 0.7977\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3712 - accuracy: 0.8249\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3607 - accuracy: 0.8268\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3572 - accuracy: 0.8463\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.3613 - accuracy: 0.8268\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3574 - accuracy: 0.8327\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3736 - accuracy: 0.8230\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.3672 - accuracy: 0.8249\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3609 - accuracy: 0.8366\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3525 - accuracy: 0.8346\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3735 - accuracy: 0.8327\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.4434 - accuracy: 0.7840\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3908 - accuracy: 0.8016\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4201 - accuracy: 0.7860\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.5296 - accuracy: 0.7743\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.4365 - accuracy: 0.7938\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4171 - accuracy: 0.7938\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3985 - accuracy: 0.8035\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.3910 - accuracy: 0.8016\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3712 - accuracy: 0.8132\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3671 - accuracy: 0.8113\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3640 - accuracy: 0.8249\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.4069 - accuracy: 0.7996\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4326 - accuracy: 0.7879\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3890 - accuracy: 0.7977\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3887 - accuracy: 0.8035\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.3729 - accuracy: 0.8074\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3861 - accuracy: 0.8113\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3803 - accuracy: 0.8132\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3671 - accuracy: 0.8132\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3589 - accuracy: 0.8288\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3622 - accuracy: 0.8210\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3799 - accuracy: 0.8249\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 426us/step - loss: 0.3836 - accuracy: 0.8074\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3879 - accuracy: 0.8093\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3865 - accuracy: 0.8054\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3894 - accuracy: 0.7996\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 420us/step - loss: 0.3727 - accuracy: 0.8191\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3756 - accuracy: 0.8230\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3932 - accuracy: 0.8191\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.3762 - accuracy: 0.8113\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 419us/step - loss: 0.4457 - accuracy: 0.7685\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.4179 - accuracy: 0.7918\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.4039 - accuracy: 0.8191\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3918 - accuracy: 0.7957\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.4104 - accuracy: 0.7840\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4474 - accuracy: 0.7821\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4570 - accuracy: 0.7704\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 425us/step - loss: 0.3931 - accuracy: 0.8054\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3716 - accuracy: 0.8054\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4176 - accuracy: 0.7860\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3845 - accuracy: 0.8152\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 400us/step - loss: 0.3754 - accuracy: 0.8132\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4066 - accuracy: 0.7957\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3931 - accuracy: 0.8074\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4155 - accuracy: 0.7996\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 419us/step - loss: 0.3839 - accuracy: 0.8191\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3747 - accuracy: 0.8230\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3686 - accuracy: 0.8249\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 416us/step - loss: 0.3599 - accuracy: 0.8210\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3624 - accuracy: 0.8210\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3759 - accuracy: 0.7996\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3795 - accuracy: 0.8093\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.3754 - accuracy: 0.8171\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3856 - accuracy: 0.8132\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3981 - accuracy: 0.8113\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3688 - accuracy: 0.8191\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3710 - accuracy: 0.8171\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3649 - accuracy: 0.8132\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3628 - accuracy: 0.8268\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3613 - accuracy: 0.8288\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3616 - accuracy: 0.8191\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3610 - accuracy: 0.8249\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3541 - accuracy: 0.8210\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.3591 - accuracy: 0.8191\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3590 - accuracy: 0.8210\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3547 - accuracy: 0.8230\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3612 - accuracy: 0.8171\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.3638 - accuracy: 0.8327\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3643 - accuracy: 0.8132\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3563 - accuracy: 0.8191\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4277 - accuracy: 0.7899\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 410us/step - loss: 0.3713 - accuracy: 0.8093\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4298 - accuracy: 0.8016\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3889 - accuracy: 0.7996\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3754 - accuracy: 0.8113\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4122 - accuracy: 0.7860\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3764 - accuracy: 0.8268\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4278 - accuracy: 0.8035\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3920 - accuracy: 0.7996\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3726 - accuracy: 0.8191\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3561 - accuracy: 0.8268\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3532 - accuracy: 0.8210\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3620 - accuracy: 0.8191\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3525 - accuracy: 0.8249\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.4061 - accuracy: 0.7977\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3882 - accuracy: 0.8152\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 434us/step - loss: 0.3824 - accuracy: 0.8016\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.3830 - accuracy: 0.8191\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3515 - accuracy: 0.8346\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3652 - accuracy: 0.8327\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3584 - accuracy: 0.8366\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3576 - accuracy: 0.8230\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3833 - accuracy: 0.8016\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3662 - accuracy: 0.8113\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4029 - accuracy: 0.7938\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3641 - accuracy: 0.8230\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3915 - accuracy: 0.8171\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3777 - accuracy: 0.8093\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3671 - accuracy: 0.8132\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.3566 - accuracy: 0.8307\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3584 - accuracy: 0.8288\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3574 - accuracy: 0.8132\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3612 - accuracy: 0.8249\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3645 - accuracy: 0.8249\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.7035 - accuracy: 0.7257\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 313us/step - loss: 0.5180 - accuracy: 0.7568\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4145 - accuracy: 0.8035\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 443us/step - loss: 0.4012 - accuracy: 0.8152\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3935 - accuracy: 0.8016\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3776 - accuracy: 0.8230\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3824 - accuracy: 0.8307\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3714 - accuracy: 0.8230\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3583 - accuracy: 0.8327\n",
      "8/8 [==============================] - 0s 384us/step - loss: 0.9501 - accuracy: 0.7008\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3715 - accuracy: 0.8171\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3643 - accuracy: 0.8385\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3710 - accuracy: 0.8307\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3875 - accuracy: 0.8113\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3823 - accuracy: 0.8171\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3694 - accuracy: 0.8171\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3582 - accuracy: 0.8385\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3595 - accuracy: 0.8405\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 426us/step - loss: 0.3667 - accuracy: 0.8327\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3826 - accuracy: 0.8307\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3978 - accuracy: 0.7957\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3852 - accuracy: 0.8288\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 422us/step - loss: 0.4047 - accuracy: 0.8035\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3841 - accuracy: 0.8210\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3696 - accuracy: 0.8171\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.5142 - accuracy: 0.7685\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4441 - accuracy: 0.7879\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4359 - accuracy: 0.8016\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3828 - accuracy: 0.8327\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.4247 - accuracy: 0.7977\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3894 - accuracy: 0.8113\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4000 - accuracy: 0.8074\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3620 - accuracy: 0.8288\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 411us/step - loss: 0.3612 - accuracy: 0.8366\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3719 - accuracy: 0.8210\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4075 - accuracy: 0.8054\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4098 - accuracy: 0.8035\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3734 - accuracy: 0.8268\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4597 - accuracy: 0.8113\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4192 - accuracy: 0.8093\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.3898 - accuracy: 0.8113\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3709 - accuracy: 0.8249\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3738 - accuracy: 0.8249\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3635 - accuracy: 0.8210\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3692 - accuracy: 0.8210\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.3546 - accuracy: 0.8385\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3635 - accuracy: 0.8230\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3625 - accuracy: 0.8191\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.3607 - accuracy: 0.8327\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3634 - accuracy: 0.8191\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4281 - accuracy: 0.7996\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.4546 - accuracy: 0.7977\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.3928 - accuracy: 0.8093\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3623 - accuracy: 0.8366\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3599 - accuracy: 0.8346\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.3746 - accuracy: 0.8054\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3666 - accuracy: 0.8385\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3676 - accuracy: 0.8191\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3943 - accuracy: 0.8054\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3733 - accuracy: 0.8268\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.6194 - accuracy: 0.7743\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4693 - accuracy: 0.8016\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4182 - accuracy: 0.8054\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3825 - accuracy: 0.8016\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3748 - accuracy: 0.8366\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4094 - accuracy: 0.8035\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3720 - accuracy: 0.8230\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3694 - accuracy: 0.8191\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3628 - accuracy: 0.8307\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3650 - accuracy: 0.8249\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3784 - accuracy: 0.8288\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.3908 - accuracy: 0.8268\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.3779 - accuracy: 0.8346\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3738 - accuracy: 0.8307\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3631 - accuracy: 0.8171\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3679 - accuracy: 0.8230\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3630 - accuracy: 0.8327\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3588 - accuracy: 0.8327\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3687 - accuracy: 0.8230\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3601 - accuracy: 0.8327\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3591 - accuracy: 0.8288\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3519 - accuracy: 0.8502\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3634 - accuracy: 0.8191\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3744 - accuracy: 0.8171\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3603 - accuracy: 0.8405\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4275 - accuracy: 0.7879\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.3877 - accuracy: 0.8191\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3615 - accuracy: 0.8152\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3597 - accuracy: 0.8191\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 546us/step - loss: 0.3651 - accuracy: 0.8307\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 487us/step - loss: 0.3557 - accuracy: 0.8171\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 624us/step - loss: 0.3543 - accuracy: 0.8268\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 437us/step - loss: 0.3634 - accuracy: 0.8210\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3515 - accuracy: 0.8366\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3564 - accuracy: 0.8288\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3525 - accuracy: 0.8268\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.4069 - accuracy: 0.8113\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3954 - accuracy: 0.8132\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3816 - accuracy: 0.8113\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 428us/step - loss: 0.3696 - accuracy: 0.8152\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3542 - accuracy: 0.8210\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3617 - accuracy: 0.8307\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3490 - accuracy: 0.8346\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 420us/step - loss: 0.6204 - accuracy: 0.7782\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.6495 - accuracy: 0.7840\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4302 - accuracy: 0.7879\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4252 - accuracy: 0.7743\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.3922 - accuracy: 0.8132\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 400us/step - loss: 0.4172 - accuracy: 0.7938\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.3811 - accuracy: 0.8230\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 438us/step - loss: 0.3743 - accuracy: 0.8171\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3610 - accuracy: 0.8346\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3611 - accuracy: 0.8230\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3624 - accuracy: 0.8230\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3718 - accuracy: 0.8405\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3787 - accuracy: 0.8230\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4120 - accuracy: 0.8016\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3804 - accuracy: 0.8093\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3906 - accuracy: 0.8074\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3861 - accuracy: 0.7899\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3630 - accuracy: 0.8268\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4026 - accuracy: 0.7938\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3800 - accuracy: 0.8113\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3673 - accuracy: 0.8249\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3593 - accuracy: 0.8152\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.7253 - accuracy: 0.7802\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4676 - accuracy: 0.7977\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.4466 - accuracy: 0.7704\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4148 - accuracy: 0.7802\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3918 - accuracy: 0.7996\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3891 - accuracy: 0.7957\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3912 - accuracy: 0.7938\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3862 - accuracy: 0.8035\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3932 - accuracy: 0.7938\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.4720 - accuracy: 0.7646\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.4134 - accuracy: 0.8074\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 311us/step - loss: 0.3928 - accuracy: 0.8016\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4067 - accuracy: 0.7977\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4868 - accuracy: 0.7665\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4257 - accuracy: 0.7918\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3857 - accuracy: 0.8171\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3931 - accuracy: 0.8113\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 400us/step - loss: 0.3774 - accuracy: 0.7918\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3733 - accuracy: 0.8268\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3762 - accuracy: 0.8074\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4098 - accuracy: 0.8054\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3818 - accuracy: 0.7996\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.5562 - accuracy: 0.7471\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4642 - accuracy: 0.7646\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3992 - accuracy: 0.7821\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3895 - accuracy: 0.7977\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.5472 - accuracy: 0.7607\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4441 - accuracy: 0.7899\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4110 - accuracy: 0.8035\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.4222 - accuracy: 0.7821\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4855 - accuracy: 0.7626\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4039 - accuracy: 0.7802\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4111 - accuracy: 0.8074\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3834 - accuracy: 0.7899\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3873 - accuracy: 0.8074\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4933 - accuracy: 0.7646\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.4222 - accuracy: 0.7743\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3755 - accuracy: 0.8074\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3802 - accuracy: 0.8054\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.4239 - accuracy: 0.8054\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3925 - accuracy: 0.7977\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3992 - accuracy: 0.7782\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.4708 - accuracy: 0.7626\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4294 - accuracy: 0.7840\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.3909 - accuracy: 0.7996\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3762 - accuracy: 0.8113\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4165 - accuracy: 0.8093\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3974 - accuracy: 0.7918\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.4561 - accuracy: 0.8074\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3874 - accuracy: 0.7996\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3637 - accuracy: 0.8093\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4058 - accuracy: 0.8113\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3768 - accuracy: 0.8132\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3824 - accuracy: 0.8113\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3846 - accuracy: 0.8113\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3739 - accuracy: 0.8113\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3626 - accuracy: 0.8074\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3669 - accuracy: 0.8191\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3880 - accuracy: 0.8074\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3733 - accuracy: 0.7996\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3679 - accuracy: 0.8132\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3705 - accuracy: 0.8054\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3893 - accuracy: 0.8035\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3811 - accuracy: 0.8191\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3721 - accuracy: 0.7938\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.5086 - accuracy: 0.7996\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4676 - accuracy: 0.8093\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.4342 - accuracy: 0.8171\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4036 - accuracy: 0.8191\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3696 - accuracy: 0.8171\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 317us/step - loss: 0.3798 - accuracy: 0.8113\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3586 - accuracy: 0.8230\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3646 - accuracy: 0.8035\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3706 - accuracy: 0.8113\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3629 - accuracy: 0.8268\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3561 - accuracy: 0.8171\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3627 - accuracy: 0.8113\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.4407 - accuracy: 0.7899\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3928 - accuracy: 0.7996\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3674 - accuracy: 0.8035\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3739 - accuracy: 0.8093\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3740 - accuracy: 0.8113\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3626 - accuracy: 0.8230\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3752 - accuracy: 0.8074\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 431us/step - loss: 0.3685 - accuracy: 0.8249\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3786 - accuracy: 0.8113\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4411 - accuracy: 0.7704\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3844 - accuracy: 0.8016\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3812 - accuracy: 0.8093\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3852 - accuracy: 0.8093\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3743 - accuracy: 0.8113\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3681 - accuracy: 0.8210\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3641 - accuracy: 0.8307\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3632 - accuracy: 0.8171\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3608 - accuracy: 0.8152\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3711 - accuracy: 0.8152\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3600 - accuracy: 0.8191\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3576 - accuracy: 0.8191\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3660 - accuracy: 0.8249\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3693 - accuracy: 0.8230\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.4336 - accuracy: 0.7802\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4211 - accuracy: 0.7918\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4103 - accuracy: 0.7938\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4133 - accuracy: 0.7957\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3667 - accuracy: 0.8113\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3521 - accuracy: 0.8327\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3569 - accuracy: 0.8249\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3483 - accuracy: 0.8327\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3585 - accuracy: 0.8307\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.3500 - accuracy: 0.8346\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3519 - accuracy: 0.8327\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3544 - accuracy: 0.8288\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3442 - accuracy: 0.8288\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3553 - accuracy: 0.8132\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3967 - accuracy: 0.7957\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3604 - accuracy: 0.8249\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3835 - accuracy: 0.8152\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 410us/step - loss: 0.3783 - accuracy: 0.8113\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3592 - accuracy: 0.8346\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 589us/step - loss: 0.3608 - accuracy: 0.8191\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 619us/step - loss: 0.3841 - accuracy: 0.8054\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 506us/step - loss: 0.5259 - accuracy: 0.7763\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 506us/step - loss: 0.4381 - accuracy: 0.7743\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 500us/step - loss: 0.4062 - accuracy: 0.7996\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 457us/step - loss: 0.3791 - accuracy: 0.8191\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 539us/step - loss: 0.3789 - accuracy: 0.8210\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 529us/step - loss: 0.3806 - accuracy: 0.8074\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 434us/step - loss: 0.3945 - accuracy: 0.8171\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 524us/step - loss: 0.3663 - accuracy: 0.8113\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 571us/step - loss: 0.3712 - accuracy: 0.8230\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.3669 - accuracy: 0.8268\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 515us/step - loss: 0.3538 - accuracy: 0.8327\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7782\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 663us/step - loss: 0.8254 - accuracy: 0.6984\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 885us/step - loss: 0.5766 - accuracy: 0.7471\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 530us/step - loss: 0.5347 - accuracy: 0.7490\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 534us/step - loss: 0.4385 - accuracy: 0.7938\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 448us/step - loss: 0.4300 - accuracy: 0.7704\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 432us/step - loss: 0.4118 - accuracy: 0.7879\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 556us/step - loss: 0.3936 - accuracy: 0.8210\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3829 - accuracy: 0.7938\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3779 - accuracy: 0.8249\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3925 - accuracy: 0.8035\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 612us/step - loss: 0.3937 - accuracy: 0.8074\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4143 - accuracy: 0.7899\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.4078 - accuracy: 0.7821\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.4046 - accuracy: 0.8093\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3800 - accuracy: 0.8191\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.3744 - accuracy: 0.8249\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3790 - accuracy: 0.8132\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 441us/step - loss: 0.3766 - accuracy: 0.8152\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3758 - accuracy: 0.8288\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3928 - accuracy: 0.8171\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.4023 - accuracy: 0.8093\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 525us/step - loss: 0.3895 - accuracy: 0.8016\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.3915 - accuracy: 0.7957\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3652 - accuracy: 0.8230\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3633 - accuracy: 0.8288\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.3863 - accuracy: 0.8132\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4035 - accuracy: 0.7996\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3900 - accuracy: 0.8152\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4040 - accuracy: 0.8132\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3859 - accuracy: 0.8230\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3841 - accuracy: 0.8054\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4296 - accuracy: 0.7918\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3917 - accuracy: 0.8054\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.3812 - accuracy: 0.7977\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3828 - accuracy: 0.7996\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4314 - accuracy: 0.7743\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4205 - accuracy: 0.7840\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3920 - accuracy: 0.8113\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3948 - accuracy: 0.8035\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 436us/step - loss: 0.3937 - accuracy: 0.8132\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3926 - accuracy: 0.8035\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3783 - accuracy: 0.8113\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3765 - accuracy: 0.8210\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3826 - accuracy: 0.8152\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4377 - accuracy: 0.7957\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.3846 - accuracy: 0.8113\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3811 - accuracy: 0.8249\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3698 - accuracy: 0.8307\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3655 - accuracy: 0.8191\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3906 - accuracy: 0.8035\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3803 - accuracy: 0.8054\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3680 - accuracy: 0.8132\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3549 - accuracy: 0.8444\n",
      "8/8 [==============================] - 0s 482us/step - loss: 0.9654 - accuracy: 0.7126\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.3750 - accuracy: 0.8093\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 522us/step - loss: 0.4831 - accuracy: 0.7996\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 1.0916 - accuracy: 0.7374\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.6050 - accuracy: 0.7296\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4471 - accuracy: 0.7821\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 442us/step - loss: 0.4174 - accuracy: 0.7879\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.4372 - accuracy: 0.7918\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.3982 - accuracy: 0.8054\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.4038 - accuracy: 0.8016\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 456us/step - loss: 0.3873 - accuracy: 0.8016\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3998 - accuracy: 0.8016\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.3914 - accuracy: 0.8093\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 489us/step - loss: 0.6582 - accuracy: 0.7218\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 405us/step - loss: 0.4992 - accuracy: 0.7665\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 434us/step - loss: 0.4305 - accuracy: 0.7977\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 415us/step - loss: 0.4036 - accuracy: 0.8171\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 419us/step - loss: 0.4093 - accuracy: 0.8093\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4154 - accuracy: 0.7821\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.4041 - accuracy: 0.8132\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3883 - accuracy: 0.8035\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3777 - accuracy: 0.8074\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 411us/step - loss: 0.3733 - accuracy: 0.7977\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 698us/step - loss: 0.3852 - accuracy: 0.8132\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 481us/step - loss: 0.3853 - accuracy: 0.8230\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 440us/step - loss: 0.3998 - accuracy: 0.7938\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.3778 - accuracy: 0.8249\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.3843 - accuracy: 0.8035\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.3762 - accuracy: 0.8152\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3868 - accuracy: 0.8035\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.3790 - accuracy: 0.8093\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.3746 - accuracy: 0.8249\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 474us/step - loss: 0.3845 - accuracy: 0.8171\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.3708 - accuracy: 0.8191\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 464us/step - loss: 0.4721 - accuracy: 0.7704\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 440us/step - loss: 0.3957 - accuracy: 0.8035\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.3779 - accuracy: 0.8288\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3677 - accuracy: 0.8327\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.4730 - accuracy: 0.7957\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 436us/step - loss: 0.4155 - accuracy: 0.7724\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 437us/step - loss: 0.3817 - accuracy: 0.8035\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.4230 - accuracy: 0.8307\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 447us/step - loss: 0.4075 - accuracy: 0.7860\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 430us/step - loss: 0.3840 - accuracy: 0.7977\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3719 - accuracy: 0.8191\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3681 - accuracy: 0.8132\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3988 - accuracy: 0.8035\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.3896 - accuracy: 0.8268\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3800 - accuracy: 0.8268\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 400us/step - loss: 0.3690 - accuracy: 0.8307\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 468us/step - loss: 0.3967 - accuracy: 0.7938\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.3789 - accuracy: 0.8054\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 410us/step - loss: 0.3869 - accuracy: 0.8035\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4211 - accuracy: 0.7821\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.4070 - accuracy: 0.7899\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 413us/step - loss: 0.4228 - accuracy: 0.7724\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.4006 - accuracy: 0.7957\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3952 - accuracy: 0.7977\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 452us/step - loss: 0.4137 - accuracy: 0.7977\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.3821 - accuracy: 0.8191\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 401us/step - loss: 0.3923 - accuracy: 0.8132\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 405us/step - loss: 0.4126 - accuracy: 0.7879\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 465us/step - loss: 0.5259 - accuracy: 0.7685\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.4233 - accuracy: 0.7957\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.3929 - accuracy: 0.8132\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.4616 - accuracy: 0.7802\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 420us/step - loss: 0.3788 - accuracy: 0.8152\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3761 - accuracy: 0.8171\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.6434 - accuracy: 0.7471\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 420us/step - loss: 0.7962 - accuracy: 0.7354\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.5997 - accuracy: 0.7568\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4937 - accuracy: 0.7743\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 501us/step - loss: 0.4782 - accuracy: 0.7763\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.4614 - accuracy: 0.7763\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 428us/step - loss: 0.4526 - accuracy: 0.7879\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.4399 - accuracy: 0.7918\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 462us/step - loss: 0.4308 - accuracy: 0.7996\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.4177 - accuracy: 0.7996\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.4081 - accuracy: 0.8074\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4097 - accuracy: 0.8054\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.4143 - accuracy: 0.7899\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 441us/step - loss: 0.4135 - accuracy: 0.8132\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 419us/step - loss: 0.4163 - accuracy: 0.8093\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 428us/step - loss: 0.4081 - accuracy: 0.8113\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 426us/step - loss: 0.5305 - accuracy: 0.7626\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 453us/step - loss: 0.4478 - accuracy: 0.7685\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 442us/step - loss: 0.4418 - accuracy: 0.7763\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.4151 - accuracy: 0.7957\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 461us/step - loss: 0.4099 - accuracy: 0.8054\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4067 - accuracy: 0.8054\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4078 - accuracy: 0.7957\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4126 - accuracy: 0.7957\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.4313 - accuracy: 0.7938\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 569us/step - loss: 0.4133 - accuracy: 0.8035\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 425us/step - loss: 0.4192 - accuracy: 0.8191\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 480us/step - loss: 0.4339 - accuracy: 0.7996\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 429us/step - loss: 0.4236 - accuracy: 0.8093\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.4158 - accuracy: 0.8113\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.4059 - accuracy: 0.8016\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 479us/step - loss: 0.3961 - accuracy: 0.8307\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 415us/step - loss: 0.3967 - accuracy: 0.8230\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.4040 - accuracy: 0.8230\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3976 - accuracy: 0.8132\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 479us/step - loss: 0.4135 - accuracy: 0.8074\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.4122 - accuracy: 0.8152\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.4129 - accuracy: 0.8113\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4074 - accuracy: 0.7996\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 458us/step - loss: 0.3982 - accuracy: 0.8210\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3936 - accuracy: 0.8093\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.4129 - accuracy: 0.8152\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.4810 - accuracy: 0.7957\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 461us/step - loss: 0.4164 - accuracy: 0.8093\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.5402 - accuracy: 0.7665\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.4996 - accuracy: 0.7879\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 486us/step - loss: 0.4333 - accuracy: 0.7899\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 434us/step - loss: 0.3985 - accuracy: 0.8093\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.3991 - accuracy: 0.8191\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.4140 - accuracy: 0.8074\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 446us/step - loss: 0.4035 - accuracy: 0.8093\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 431us/step - loss: 0.3905 - accuracy: 0.8191\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3975 - accuracy: 0.8191\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 317us/step - loss: 0.3957 - accuracy: 0.8074\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.4223 - accuracy: 0.7918\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4287 - accuracy: 0.7977\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4241 - accuracy: 0.7996\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4476 - accuracy: 0.7782\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.4427 - accuracy: 0.7957\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4205 - accuracy: 0.7977\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4154 - accuracy: 0.8093\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4135 - accuracy: 0.8152\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4104 - accuracy: 0.8016\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.4204 - accuracy: 0.7977\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4118 - accuracy: 0.7918\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4065 - accuracy: 0.8016\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4014 - accuracy: 0.8171\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4041 - accuracy: 0.8113\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4055 - accuracy: 0.8132\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.4211 - accuracy: 0.7957\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4123 - accuracy: 0.8113\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4064 - accuracy: 0.8230\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.4078 - accuracy: 0.8152\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3988 - accuracy: 0.8093\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3965 - accuracy: 0.8346\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.4028 - accuracy: 0.8210\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4565 - accuracy: 0.7607\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4165 - accuracy: 0.7899\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4223 - accuracy: 0.7938\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.5306 - accuracy: 0.7685\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4164 - accuracy: 0.8171\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4372 - accuracy: 0.7899\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4237 - accuracy: 0.8093\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4175 - accuracy: 0.7899\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4067 - accuracy: 0.7977\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 633us/step - loss: 0.4130 - accuracy: 0.8054\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4047 - accuracy: 0.7996\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4205 - accuracy: 0.8074\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.4105 - accuracy: 0.8230\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4026 - accuracy: 0.8288\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.4479 - accuracy: 0.8054\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.4190 - accuracy: 0.8054\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4152 - accuracy: 0.7879\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.4047 - accuracy: 0.8171\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3986 - accuracy: 0.8152\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4056 - accuracy: 0.8113\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4241 - accuracy: 0.7821\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 413us/step - loss: 0.4108 - accuracy: 0.8035\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4043 - accuracy: 0.8230\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.5227 - accuracy: 0.7724\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4219 - accuracy: 0.8035\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.4094 - accuracy: 0.8171\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4051 - accuracy: 0.7957\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4343 - accuracy: 0.7918\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4142 - accuracy: 0.7957\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.4089 - accuracy: 0.8191\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4011 - accuracy: 0.8016\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4011 - accuracy: 0.8113\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 588us/step - loss: 0.3994 - accuracy: 0.8093\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 436us/step - loss: 0.3992 - accuracy: 0.8171\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3977 - accuracy: 0.8171\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3974 - accuracy: 0.8268\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3990 - accuracy: 0.8035\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.4287 - accuracy: 0.8074\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.4280 - accuracy: 0.7996\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4237 - accuracy: 0.8152\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4579 - accuracy: 0.7743\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4155 - accuracy: 0.8191\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4271 - accuracy: 0.7996\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.4343 - accuracy: 0.7802\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4291 - accuracy: 0.8074\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.4053 - accuracy: 0.8113\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3978 - accuracy: 0.8288\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3948 - accuracy: 0.8268\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3924 - accuracy: 0.8230\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3970 - accuracy: 0.8132\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4088 - accuracy: 0.8288\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4246 - accuracy: 0.7918\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4176 - accuracy: 0.8035\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4109 - accuracy: 0.8171\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4089 - accuracy: 0.8074\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3995 - accuracy: 0.8288\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 422us/step - loss: 0.3946 - accuracy: 0.8288\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3942 - accuracy: 0.8249\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3923 - accuracy: 0.8230\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 315us/step - loss: 0.3929 - accuracy: 0.8268\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3928 - accuracy: 0.8444\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3918 - accuracy: 0.8249\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.4051 - accuracy: 0.8152\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4008 - accuracy: 0.8191\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4042 - accuracy: 0.8074\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 410us/step - loss: 0.4069 - accuracy: 0.8016\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4604 - accuracy: 0.7743\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4397 - accuracy: 0.7899\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4207 - accuracy: 0.8093\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4080 - accuracy: 0.8152\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4145 - accuracy: 0.8016\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3954 - accuracy: 0.8054\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4404 - accuracy: 0.7918\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4361 - accuracy: 0.8054\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.4843 - accuracy: 0.7782\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.4570 - accuracy: 0.7782\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 314us/step - loss: 0.4366 - accuracy: 0.7938\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.4199 - accuracy: 0.7938\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3970 - accuracy: 0.8307\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3977 - accuracy: 0.8171\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3952 - accuracy: 0.8093\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3885 - accuracy: 0.8152\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3929 - accuracy: 0.8191\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3938 - accuracy: 0.8366\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4018 - accuracy: 0.8171\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3934 - accuracy: 0.8113\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4478 - accuracy: 0.7996\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4204 - accuracy: 0.8074\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.4212 - accuracy: 0.8132\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4105 - accuracy: 0.8346\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4027 - accuracy: 0.8113\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3978 - accuracy: 0.8268\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3985 - accuracy: 0.8113\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3906 - accuracy: 0.8191\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4126 - accuracy: 0.8249\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.4009 - accuracy: 0.8210\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.4404 - accuracy: 0.8035\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4064 - accuracy: 0.8152\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4136 - accuracy: 0.8093\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 317us/step - loss: 0.3999 - accuracy: 0.8132\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 415us/step - loss: 0.3958 - accuracy: 0.8171\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3884 - accuracy: 0.8327\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3908 - accuracy: 0.8327\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4117 - accuracy: 0.8016\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3869 - accuracy: 0.8152\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3999 - accuracy: 0.8171\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3975 - accuracy: 0.8307\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3901 - accuracy: 0.8346\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4038 - accuracy: 0.8016\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3973 - accuracy: 0.8191\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3909 - accuracy: 0.8132\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3836 - accuracy: 0.8288\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3814 - accuracy: 0.8346\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3797 - accuracy: 0.8346\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.4209 - accuracy: 0.7840\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3934 - accuracy: 0.8307\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3972 - accuracy: 0.8016\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3861 - accuracy: 0.8366\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3900 - accuracy: 0.8230\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3810 - accuracy: 0.8249\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4023 - accuracy: 0.7860\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3990 - accuracy: 0.8016\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.3811 - accuracy: 0.8288\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3812 - accuracy: 0.8307\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.4140 - accuracy: 0.8016\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.4250 - accuracy: 0.7821\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3994 - accuracy: 0.8054\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3934 - accuracy: 0.8093\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3862 - accuracy: 0.8210\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3904 - accuracy: 0.8249\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3977 - accuracy: 0.8171\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3910 - accuracy: 0.8152\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 442us/step - loss: 0.3860 - accuracy: 0.8210\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3848 - accuracy: 0.8230\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4028 - accuracy: 0.8171\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.3969 - accuracy: 0.8113\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.4436 - accuracy: 0.7724\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4165 - accuracy: 0.7977\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3936 - accuracy: 0.8113\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3846 - accuracy: 0.8113\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3920 - accuracy: 0.8152\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.3904 - accuracy: 0.8171\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3776 - accuracy: 0.8268\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3833 - accuracy: 0.8249\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 318us/step - loss: 0.4443 - accuracy: 0.7996\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.4228 - accuracy: 0.7996\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3852 - accuracy: 0.8210\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3832 - accuracy: 0.8230\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.3748 - accuracy: 0.8210\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3752 - accuracy: 0.8366\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3821 - accuracy: 0.8191\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3831 - accuracy: 0.8210\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3768 - accuracy: 0.8210\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3800 - accuracy: 0.8307\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4076 - accuracy: 0.7957\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.5177 - accuracy: 0.7840\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4093 - accuracy: 0.8074\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3832 - accuracy: 0.8249\n",
      "8/8 [==============================] - 0s 371us/step - loss: 1.0293 - accuracy: 0.7008\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4062 - accuracy: 0.8132\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4108 - accuracy: 0.7996\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3850 - accuracy: 0.8152\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3852 - accuracy: 0.8132\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3987 - accuracy: 0.8249\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3907 - accuracy: 0.8191\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4025 - accuracy: 0.7977\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.4021 - accuracy: 0.8093\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3828 - accuracy: 0.8307\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3794 - accuracy: 0.8171\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3898 - accuracy: 0.8210\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3948 - accuracy: 0.8288\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.3848 - accuracy: 0.8346\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4032 - accuracy: 0.8093\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3974 - accuracy: 0.8230\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3960 - accuracy: 0.8132\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3854 - accuracy: 0.8249\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3746 - accuracy: 0.8288\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4454 - accuracy: 0.7918\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.5173 - accuracy: 0.7996\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4088 - accuracy: 0.8191\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.4044 - accuracy: 0.7996\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3906 - accuracy: 0.8230\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3946 - accuracy: 0.8210\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.4050 - accuracy: 0.7996\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4133 - accuracy: 0.8113\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4056 - accuracy: 0.8113\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4002 - accuracy: 0.8132\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4015 - accuracy: 0.8016\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3966 - accuracy: 0.8093\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.4567 - accuracy: 0.8093\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3840 - accuracy: 0.8249\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3774 - accuracy: 0.8327\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3851 - accuracy: 0.8191\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3974 - accuracy: 0.8113\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3782 - accuracy: 0.8210\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3757 - accuracy: 0.8327\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3936 - accuracy: 0.8307\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3903 - accuracy: 0.8093\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.3745 - accuracy: 0.8444\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3747 - accuracy: 0.8307\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3759 - accuracy: 0.8268\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3716 - accuracy: 0.8268\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.3659 - accuracy: 0.8424\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3684 - accuracy: 0.8444\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3768 - accuracy: 0.8249\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3687 - accuracy: 0.8463\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4441 - accuracy: 0.7938\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3920 - accuracy: 0.8016\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3878 - accuracy: 0.8191\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 424us/step - loss: 0.4318 - accuracy: 0.7899\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4125 - accuracy: 0.8035\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 460us/step - loss: 0.3779 - accuracy: 0.8249\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3739 - accuracy: 0.8268\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3933 - accuracy: 0.8171\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3904 - accuracy: 0.8093\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4484 - accuracy: 0.7840\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4956 - accuracy: 0.7957\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4445 - accuracy: 0.8074\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4233 - accuracy: 0.8016\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3987 - accuracy: 0.8171\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3921 - accuracy: 0.8191\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3798 - accuracy: 0.8366\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3993 - accuracy: 0.7996\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3886 - accuracy: 0.8171\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3967 - accuracy: 0.8152\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3756 - accuracy: 0.8482\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3748 - accuracy: 0.8288\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3738 - accuracy: 0.8210\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3754 - accuracy: 0.8327\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.4022 - accuracy: 0.7996\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4134 - accuracy: 0.7957\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4131 - accuracy: 0.8230\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.5439 - accuracy: 0.7685\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4325 - accuracy: 0.7938\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3945 - accuracy: 0.8171\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3870 - accuracy: 0.8152\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3792 - accuracy: 0.8424\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3854 - accuracy: 0.8210\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 415us/step - loss: 0.3703 - accuracy: 0.8346\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3854 - accuracy: 0.8249\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3802 - accuracy: 0.8210\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3899 - accuracy: 0.8210\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3925 - accuracy: 0.8191\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3808 - accuracy: 0.8249\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3749 - accuracy: 0.8288\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3720 - accuracy: 0.8268\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 316us/step - loss: 0.3732 - accuracy: 0.8424\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3725 - accuracy: 0.8307\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4004 - accuracy: 0.8093\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.4194 - accuracy: 0.7899\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.3755 - accuracy: 0.8366\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.3712 - accuracy: 0.8385\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3766 - accuracy: 0.8307\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3696 - accuracy: 0.8385\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3687 - accuracy: 0.8366\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3701 - accuracy: 0.8346\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 512us/step - loss: 0.3715 - accuracy: 0.8210\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 451us/step - loss: 0.3703 - accuracy: 0.8230\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3703 - accuracy: 0.8502\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3977 - accuracy: 0.8230\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3863 - accuracy: 0.8210\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3726 - accuracy: 0.8268\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 400us/step - loss: 0.3752 - accuracy: 0.8268\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3928 - accuracy: 0.8113\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3936 - accuracy: 0.8230\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3719 - accuracy: 0.8327\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 422us/step - loss: 0.3702 - accuracy: 0.8210\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3632 - accuracy: 0.8327\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3794 - accuracy: 0.8249\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3810 - accuracy: 0.8307\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3787 - accuracy: 0.8268\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.3794 - accuracy: 0.8230\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3758 - accuracy: 0.8249\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4668 - accuracy: 0.7918\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3916 - accuracy: 0.8113\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 401us/step - loss: 0.3788 - accuracy: 0.8268\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3696 - accuracy: 0.8385\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3774 - accuracy: 0.8132\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3810 - accuracy: 0.8268\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3787 - accuracy: 0.8230\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4316 - accuracy: 0.8035\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4033 - accuracy: 0.8191\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3879 - accuracy: 0.8132\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3762 - accuracy: 0.8327\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.4084 - accuracy: 0.8288\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3835 - accuracy: 0.8268\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 315us/step - loss: 0.5262 - accuracy: 0.7821\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.4402 - accuracy: 0.7938\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.4005 - accuracy: 0.7996\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3735 - accuracy: 0.8152\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3791 - accuracy: 0.8230\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3854 - accuracy: 0.8191\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3701 - accuracy: 0.8327\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3670 - accuracy: 0.8327\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3680 - accuracy: 0.8346\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3663 - accuracy: 0.8268\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3683 - accuracy: 0.8327\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.4141 - accuracy: 0.8074\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4198 - accuracy: 0.7879\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 425us/step - loss: 0.3971 - accuracy: 0.8191\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3959 - accuracy: 0.8152\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3913 - accuracy: 0.8210\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.4071 - accuracy: 0.7977\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3910 - accuracy: 0.8113\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3761 - accuracy: 0.8327\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3839 - accuracy: 0.8132\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3809 - accuracy: 0.8307\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3772 - accuracy: 0.8288\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 413us/step - loss: 0.3674 - accuracy: 0.8327\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3761 - accuracy: 0.8171\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3803 - accuracy: 0.8249\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3913 - accuracy: 0.8210\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3687 - accuracy: 0.8307\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.3705 - accuracy: 0.8327\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3704 - accuracy: 0.8288\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4028 - accuracy: 0.8210\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3677 - accuracy: 0.8366\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 400us/step - loss: 0.3621 - accuracy: 0.8424\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4105 - accuracy: 0.8132\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4092 - accuracy: 0.8074\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3771 - accuracy: 0.8152\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3777 - accuracy: 0.8288\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.3735 - accuracy: 0.8249\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3693 - accuracy: 0.8385\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3886 - accuracy: 0.8268\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3807 - accuracy: 0.8249\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.3716 - accuracy: 0.8346\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3764 - accuracy: 0.8346\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3701 - accuracy: 0.8171\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3730 - accuracy: 0.8405\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4193 - accuracy: 0.8016\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.4281 - accuracy: 0.7957\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3952 - accuracy: 0.8191\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3953 - accuracy: 0.8230\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3880 - accuracy: 0.8074\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3829 - accuracy: 0.8210\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4079 - accuracy: 0.8035\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3859 - accuracy: 0.8191\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3781 - accuracy: 0.8230\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3813 - accuracy: 0.8152\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 400us/step - loss: 0.3793 - accuracy: 0.8288\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3772 - accuracy: 0.8268\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3631 - accuracy: 0.8385\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3622 - accuracy: 0.8463\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3727 - accuracy: 0.8230\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3655 - accuracy: 0.8366\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3709 - accuracy: 0.8288\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3625 - accuracy: 0.8268\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3839 - accuracy: 0.8288\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3697 - accuracy: 0.8327\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3665 - accuracy: 0.8366\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3685 - accuracy: 0.8230\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3737 - accuracy: 0.8230\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.3682 - accuracy: 0.8366\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3651 - accuracy: 0.8191\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4150 - accuracy: 0.7957\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4045 - accuracy: 0.8191\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3765 - accuracy: 0.8210\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 426us/step - loss: 0.3684 - accuracy: 0.8288\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.6343 - accuracy: 0.7490\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.4147 - accuracy: 0.7996\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4121 - accuracy: 0.8035\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3801 - accuracy: 0.8268\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.3843 - accuracy: 0.8152\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3998 - accuracy: 0.8074\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3925 - accuracy: 0.8249\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.4504 - accuracy: 0.7782\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3912 - accuracy: 0.8171\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 430us/step - loss: 0.3962 - accuracy: 0.7977\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3708 - accuracy: 0.8346\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3845 - accuracy: 0.8210\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3915 - accuracy: 0.8230\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3864 - accuracy: 0.8346\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3805 - accuracy: 0.8268\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3806 - accuracy: 0.8113\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3861 - accuracy: 0.8249\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3758 - accuracy: 0.8307\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3736 - accuracy: 0.8288\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3666 - accuracy: 0.8327\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3688 - accuracy: 0.8385\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3720 - accuracy: 0.8307\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3667 - accuracy: 0.8249\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 416us/step - loss: 0.4237 - accuracy: 0.8210\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.6605 - accuracy: 0.7899\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4642 - accuracy: 0.7918\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.5615 - accuracy: 0.7568\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4430 - accuracy: 0.7840\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.4157 - accuracy: 0.7879\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3994 - accuracy: 0.8035\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4800 - accuracy: 0.7879\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4293 - accuracy: 0.7918\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4427 - accuracy: 0.7782\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3959 - accuracy: 0.7977\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3885 - accuracy: 0.8113\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3973 - accuracy: 0.7977\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3844 - accuracy: 0.8132\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3829 - accuracy: 0.8016\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.3777 - accuracy: 0.8230\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3804 - accuracy: 0.8249\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3780 - accuracy: 0.8249\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3733 - accuracy: 0.8191\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4026 - accuracy: 0.7996\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.3902 - accuracy: 0.8210\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3675 - accuracy: 0.8307\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3703 - accuracy: 0.8346\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3687 - accuracy: 0.8249\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.4132 - accuracy: 0.8113\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4847 - accuracy: 0.7802\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.5436 - accuracy: 0.7568\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4462 - accuracy: 0.7860\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4107 - accuracy: 0.7957\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.3930 - accuracy: 0.8093\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3843 - accuracy: 0.8210\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3724 - accuracy: 0.8268\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3850 - accuracy: 0.8016\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3717 - accuracy: 0.8171\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3680 - accuracy: 0.8288\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3744 - accuracy: 0.8288\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4016 - accuracy: 0.8210\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3799 - accuracy: 0.8327\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3847 - accuracy: 0.8210\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3755 - accuracy: 0.8230\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3783 - accuracy: 0.8230\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3809 - accuracy: 0.8249\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.4234 - accuracy: 0.7918\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.4420 - accuracy: 0.8093\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4256 - accuracy: 0.7996\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3986 - accuracy: 0.8093\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3773 - accuracy: 0.8171\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3631 - accuracy: 0.8385\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3704 - accuracy: 0.8268\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3838 - accuracy: 0.8191\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3746 - accuracy: 0.8307\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3784 - accuracy: 0.8249\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3948 - accuracy: 0.8074\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 441us/step - loss: 0.3888 - accuracy: 0.8074\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3652 - accuracy: 0.8385\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.3625 - accuracy: 0.8288\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3677 - accuracy: 0.8191\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3935 - accuracy: 0.8132\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3832 - accuracy: 0.8249\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3905 - accuracy: 0.8132\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4132 - accuracy: 0.8132\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.3773 - accuracy: 0.8230\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3802 - accuracy: 0.8054\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3764 - accuracy: 0.8210\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3630 - accuracy: 0.8307\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3928 - accuracy: 0.8191\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4914 - accuracy: 0.7802\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4202 - accuracy: 0.7879\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3863 - accuracy: 0.8093\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4558 - accuracy: 0.7724\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.4079 - accuracy: 0.8093\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4010 - accuracy: 0.8016\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.4026 - accuracy: 0.8366\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3900 - accuracy: 0.8307\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3799 - accuracy: 0.8152\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4057 - accuracy: 0.8054\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3785 - accuracy: 0.8230\n",
      "17/17 [==============================] - 0s 306us/step - loss: 0.3623 - accuracy: 0.8191\n",
      "8/8 [==============================] - 0s 347us/step - loss: 1.0391 - accuracy: 0.7283\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3674 - accuracy: 0.8230\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3653 - accuracy: 0.8346\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4108 - accuracy: 0.8054\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3889 - accuracy: 0.8035\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3956 - accuracy: 0.8249\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.3832 - accuracy: 0.8268\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3844 - accuracy: 0.8307\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3817 - accuracy: 0.8171\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.5058 - accuracy: 0.7860\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.4396 - accuracy: 0.7899\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3954 - accuracy: 0.8074\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3750 - accuracy: 0.8230\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3728 - accuracy: 0.8249\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.3877 - accuracy: 0.8210\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.4518 - accuracy: 0.8054\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.4530 - accuracy: 0.7802\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4281 - accuracy: 0.8074\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.4118 - accuracy: 0.7977\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4726 - accuracy: 0.7918\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3990 - accuracy: 0.8074\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3960 - accuracy: 0.8327\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3875 - accuracy: 0.8191\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3738 - accuracy: 0.8191\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3873 - accuracy: 0.8191\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3813 - accuracy: 0.8307\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.4532 - accuracy: 0.7918\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4313 - accuracy: 0.7802\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4015 - accuracy: 0.8171\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.4316 - accuracy: 0.7938\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 401us/step - loss: 0.3753 - accuracy: 0.8327\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.3663 - accuracy: 0.8288\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3780 - accuracy: 0.8191\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4094 - accuracy: 0.7996\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3786 - accuracy: 0.8366\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4701 - accuracy: 0.7899\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3799 - accuracy: 0.8191\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3868 - accuracy: 0.8307\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3843 - accuracy: 0.8327\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3694 - accuracy: 0.8191\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3662 - accuracy: 0.8366\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 315us/step - loss: 0.3819 - accuracy: 0.8191\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4022 - accuracy: 0.8093\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3674 - accuracy: 0.8307\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3829 - accuracy: 0.8288\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3877 - accuracy: 0.8249\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3733 - accuracy: 0.8210\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3746 - accuracy: 0.8191\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3747 - accuracy: 0.8307\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3923 - accuracy: 0.8288\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3829 - accuracy: 0.8346\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3661 - accuracy: 0.8444\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4138 - accuracy: 0.7996\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3677 - accuracy: 0.8268\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 438us/step - loss: 0.3676 - accuracy: 0.8268\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3617 - accuracy: 0.8385\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3597 - accuracy: 0.8521\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3864 - accuracy: 0.8307\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3982 - accuracy: 0.8035\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3932 - accuracy: 0.8152\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3794 - accuracy: 0.8210\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3705 - accuracy: 0.8385\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.3707 - accuracy: 0.8366\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3701 - accuracy: 0.8307\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.3799 - accuracy: 0.8346\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3678 - accuracy: 0.8346\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3625 - accuracy: 0.8230\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4984 - accuracy: 0.7860\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4221 - accuracy: 0.7957\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.3967 - accuracy: 0.8171\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3944 - accuracy: 0.8035\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3808 - accuracy: 0.8249\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3720 - accuracy: 0.8288\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4775 - accuracy: 0.8113\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 423us/step - loss: 0.3887 - accuracy: 0.8054\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4080 - accuracy: 0.8191\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3759 - accuracy: 0.8191\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3909 - accuracy: 0.8093\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4005 - accuracy: 0.8152\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3846 - accuracy: 0.8113\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3690 - accuracy: 0.8327\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3634 - accuracy: 0.8210\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3734 - accuracy: 0.8152\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3746 - accuracy: 0.8093\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3761 - accuracy: 0.8132\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3802 - accuracy: 0.8171\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3709 - accuracy: 0.8288\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3667 - accuracy: 0.8385\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3773 - accuracy: 0.8444\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3608 - accuracy: 0.8366\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3558 - accuracy: 0.8424\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3561 - accuracy: 0.8385\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3578 - accuracy: 0.8405\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3549 - accuracy: 0.8405\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.3570 - accuracy: 0.8268\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3680 - accuracy: 0.8346\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3701 - accuracy: 0.8210\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3656 - accuracy: 0.8405\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3745 - accuracy: 0.8307\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.3738 - accuracy: 0.8249\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3603 - accuracy: 0.8346\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3823 - accuracy: 0.8366\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3765 - accuracy: 0.8171\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4052 - accuracy: 0.8132\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.4265 - accuracy: 0.7879\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3739 - accuracy: 0.8210\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3697 - accuracy: 0.8288\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.3751 - accuracy: 0.8249\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3739 - accuracy: 0.8268\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.3768 - accuracy: 0.8230\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3578 - accuracy: 0.8346\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3547 - accuracy: 0.8346\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3687 - accuracy: 0.8327\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3629 - accuracy: 0.8307\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.3579 - accuracy: 0.8288\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4104 - accuracy: 0.8054\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3875 - accuracy: 0.8249\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3659 - accuracy: 0.8210\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3592 - accuracy: 0.8230\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3647 - accuracy: 0.8327\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3685 - accuracy: 0.8327\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3631 - accuracy: 0.8346\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3860 - accuracy: 0.8113\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4052 - accuracy: 0.7957\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4043 - accuracy: 0.7996\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3723 - accuracy: 0.8230\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3673 - accuracy: 0.8230\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3826 - accuracy: 0.8132\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3583 - accuracy: 0.8327\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 405us/step - loss: 0.3624 - accuracy: 0.8230\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3722 - accuracy: 0.8113\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3624 - accuracy: 0.8288\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3677 - accuracy: 0.8230\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3647 - accuracy: 0.8288\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3574 - accuracy: 0.8307\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3831 - accuracy: 0.8113\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.4387 - accuracy: 0.8074\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3840 - accuracy: 0.8132\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3905 - accuracy: 0.8230\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 410us/step - loss: 0.3640 - accuracy: 0.8385\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4754 - accuracy: 0.7918\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.5108 - accuracy: 0.7529\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4068 - accuracy: 0.8152\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.4041 - accuracy: 0.8113\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3981 - accuracy: 0.8191\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3836 - accuracy: 0.8424\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3893 - accuracy: 0.8288\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3937 - accuracy: 0.8230\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.3985 - accuracy: 0.8132\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.3879 - accuracy: 0.8346\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.4513 - accuracy: 0.7840\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4124 - accuracy: 0.8035\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3936 - accuracy: 0.8249\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3918 - accuracy: 0.8191\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4044 - accuracy: 0.8113\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3943 - accuracy: 0.8230\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4109 - accuracy: 0.8288\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4041 - accuracy: 0.8152\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.3971 - accuracy: 0.8288\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.4006 - accuracy: 0.8152\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4129 - accuracy: 0.8132\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3897 - accuracy: 0.8093\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4225 - accuracy: 0.7899\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.5281 - accuracy: 0.7821\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4167 - accuracy: 0.8035\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4739 - accuracy: 0.7763\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4168 - accuracy: 0.7996\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3915 - accuracy: 0.8327\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.3897 - accuracy: 0.8171\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3878 - accuracy: 0.8230\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3824 - accuracy: 0.8307\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3916 - accuracy: 0.8210\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4310 - accuracy: 0.8016\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 411us/step - loss: 0.4416 - accuracy: 0.7899\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4575 - accuracy: 0.7996\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4161 - accuracy: 0.7957\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3907 - accuracy: 0.8093\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3962 - accuracy: 0.8249\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 423us/step - loss: 0.3929 - accuracy: 0.8210\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3898 - accuracy: 0.8152\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3921 - accuracy: 0.8152\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3895 - accuracy: 0.8249\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.4059 - accuracy: 0.8171\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3999 - accuracy: 0.8288\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3841 - accuracy: 0.8346\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3852 - accuracy: 0.8210\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4146 - accuracy: 0.8074\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3918 - accuracy: 0.8016\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.3792 - accuracy: 0.8132\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3817 - accuracy: 0.8210\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 318us/step - loss: 0.3742 - accuracy: 0.8385\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3759 - accuracy: 0.8346\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3881 - accuracy: 0.8191\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4026 - accuracy: 0.8191\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3926 - accuracy: 0.8113\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.3813 - accuracy: 0.8191\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3707 - accuracy: 0.8327\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3907 - accuracy: 0.8288\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3798 - accuracy: 0.8307\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3780 - accuracy: 0.8288\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3819 - accuracy: 0.8444\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.6060 - accuracy: 0.7685\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4901 - accuracy: 0.7938\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 401us/step - loss: 0.4330 - accuracy: 0.7918\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4344 - accuracy: 0.7840\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4282 - accuracy: 0.7860\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4571 - accuracy: 0.7704\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4435 - accuracy: 0.7782\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 430us/step - loss: 0.4262 - accuracy: 0.7802\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.4232 - accuracy: 0.7918\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 541us/step - loss: 0.4130 - accuracy: 0.8113\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 526us/step - loss: 0.3989 - accuracy: 0.7996\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 961us/step - loss: 0.4176 - accuracy: 0.8152\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 601us/step - loss: 0.4283 - accuracy: 0.8035\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 580us/step - loss: 0.4005 - accuracy: 0.8210\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 597us/step - loss: 0.3958 - accuracy: 0.8210\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 559us/step - loss: 0.3988 - accuracy: 0.8249\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 632us/step - loss: 0.4217 - accuracy: 0.8054\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 520us/step - loss: 0.4017 - accuracy: 0.8132\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5950 - accuracy: 0.7646\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 462us/step - loss: 0.4401 - accuracy: 0.7840\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 650us/step - loss: 0.4293 - accuracy: 0.8035\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 467us/step - loss: 0.4009 - accuracy: 0.8054\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 777us/step - loss: 0.3946 - accuracy: 0.8035\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 886us/step - loss: 0.4674 - accuracy: 0.7782\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 820us/step - loss: 0.4471 - accuracy: 0.7724\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4117 - accuracy: 0.7957\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 661us/step - loss: 0.4308 - accuracy: 0.8016\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 440us/step - loss: 0.4199 - accuracy: 0.7977\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 419us/step - loss: 0.4025 - accuracy: 0.8191\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 654us/step - loss: 0.4026 - accuracy: 0.8113\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 431us/step - loss: 0.3925 - accuracy: 0.8249\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3931 - accuracy: 0.8288\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3902 - accuracy: 0.8210\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 500us/step - loss: 0.4006 - accuracy: 0.8288\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.4010 - accuracy: 0.8230\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4157 - accuracy: 0.8035\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.4047 - accuracy: 0.8191\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 537us/step - loss: 0.4050 - accuracy: 0.8171\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 469us/step - loss: 0.3903 - accuracy: 0.8230\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3856 - accuracy: 0.8230\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3856 - accuracy: 0.8132\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 432us/step - loss: 0.4216 - accuracy: 0.8093\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4093 - accuracy: 0.8191\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 461us/step - loss: 0.3829 - accuracy: 0.8268\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.3781 - accuracy: 0.8385\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 421us/step - loss: 0.4508 - accuracy: 0.7996\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 546us/step - loss: 0.4392 - accuracy: 0.7860\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.5794 - accuracy: 0.7724\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.4553 - accuracy: 0.7918\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4527 - accuracy: 0.7724\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.4145 - accuracy: 0.8249\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.4077 - accuracy: 0.8288\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.4138 - accuracy: 0.8132\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.4085 - accuracy: 0.8054\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 467us/step - loss: 0.3951 - accuracy: 0.8171\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.4062 - accuracy: 0.8171\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 416us/step - loss: 0.4051 - accuracy: 0.8074\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4049 - accuracy: 0.8074\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 487us/step - loss: 0.4073 - accuracy: 0.8016\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 415us/step - loss: 0.3958 - accuracy: 0.8210\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4343 - accuracy: 0.7802\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 401us/step - loss: 0.4109 - accuracy: 0.8171\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4042 - accuracy: 0.8171\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 433us/step - loss: 0.3973 - accuracy: 0.8171\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3926 - accuracy: 0.8152\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.3978 - accuracy: 0.8054\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.4155 - accuracy: 0.8171\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 450us/step - loss: 0.4385 - accuracy: 0.7918\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.4183 - accuracy: 0.8035\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3958 - accuracy: 0.8210\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 437us/step - loss: 0.4025 - accuracy: 0.8093\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4014 - accuracy: 0.8132\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 455us/step - loss: 0.3947 - accuracy: 0.8249\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 410us/step - loss: 0.3958 - accuracy: 0.8074\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 438us/step - loss: 0.3909 - accuracy: 0.8171\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3901 - accuracy: 0.8132\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3947 - accuracy: 0.8093\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 505us/step - loss: 0.3987 - accuracy: 0.8191\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 451us/step - loss: 0.3889 - accuracy: 0.8171\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 424us/step - loss: 0.4084 - accuracy: 0.8230\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.4023 - accuracy: 0.8152\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 452us/step - loss: 0.4155 - accuracy: 0.8191\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.4416 - accuracy: 0.8016\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.4215 - accuracy: 0.7996\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4118 - accuracy: 0.8113\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3949 - accuracy: 0.8268\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 431us/step - loss: 0.3924 - accuracy: 0.8171\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.3896 - accuracy: 0.8191\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 401us/step - loss: 0.3898 - accuracy: 0.8152\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3931 - accuracy: 0.8210\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 478us/step - loss: 0.4469 - accuracy: 0.8054\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.3999 - accuracy: 0.8152\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 415us/step - loss: 0.3953 - accuracy: 0.8191\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.4099 - accuracy: 0.8171\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 428us/step - loss: 0.4175 - accuracy: 0.8113\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.5122 - accuracy: 0.7782\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.4158 - accuracy: 0.8093\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4061 - accuracy: 0.8249\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3931 - accuracy: 0.8210\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 427us/step - loss: 0.4136 - accuracy: 0.8074\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3991 - accuracy: 0.8268\n",
      "8/8 [==============================] - 0s 369us/step - loss: 0.9848 - accuracy: 0.7126\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 430us/step - loss: 0.3925 - accuracy: 0.8230\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3878 - accuracy: 0.8268\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 424us/step - loss: 0.4427 - accuracy: 0.7918\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 566us/step - loss: 0.4027 - accuracy: 0.8152\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3966 - accuracy: 0.8093\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 419us/step - loss: 0.4032 - accuracy: 0.7938\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4085 - accuracy: 0.8093\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 455us/step - loss: 0.4034 - accuracy: 0.8132\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.4587 - accuracy: 0.7899\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 429us/step - loss: 0.4456 - accuracy: 0.7802\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.4092 - accuracy: 0.8191\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3937 - accuracy: 0.8230\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 447us/step - loss: 0.3937 - accuracy: 0.8132\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 400us/step - loss: 0.3964 - accuracy: 0.8210\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.4004 - accuracy: 0.8210\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4036 - accuracy: 0.8191\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 430us/step - loss: 0.3982 - accuracy: 0.8268\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 426us/step - loss: 0.3928 - accuracy: 0.8171\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3970 - accuracy: 0.8113\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.3900 - accuracy: 0.8210\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3980 - accuracy: 0.8210\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 451us/step - loss: 0.3899 - accuracy: 0.8152\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.4493 - accuracy: 0.7860\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.4055 - accuracy: 0.8113\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4539 - accuracy: 0.7840\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.4054 - accuracy: 0.8074\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 483us/step - loss: 0.3852 - accuracy: 0.8288\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3915 - accuracy: 0.8327\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4061 - accuracy: 0.8113\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4058 - accuracy: 0.8132\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4710 - accuracy: 0.7957\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4139 - accuracy: 0.8249\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3926 - accuracy: 0.8152\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.4245 - accuracy: 0.8132\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3949 - accuracy: 0.8093\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3949 - accuracy: 0.8268\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.4031 - accuracy: 0.7977\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4090 - accuracy: 0.8191\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4114 - accuracy: 0.8152\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.4063 - accuracy: 0.8230\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3917 - accuracy: 0.8113\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 405us/step - loss: 0.3944 - accuracy: 0.8230\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3980 - accuracy: 0.8249\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3854 - accuracy: 0.8210\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4083 - accuracy: 0.8074\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3949 - accuracy: 0.8171\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 420us/step - loss: 0.3831 - accuracy: 0.8191\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3852 - accuracy: 0.8288\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.4014 - accuracy: 0.7996\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4063 - accuracy: 0.8230\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3986 - accuracy: 0.8016\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.3868 - accuracy: 0.8288\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3838 - accuracy: 0.8307\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3962 - accuracy: 0.8074\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3905 - accuracy: 0.8230\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3953 - accuracy: 0.8191\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4052 - accuracy: 0.8268\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3945 - accuracy: 0.8171\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3986 - accuracy: 0.8074\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4028 - accuracy: 0.8171\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4028 - accuracy: 0.8132\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4165 - accuracy: 0.8054\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3961 - accuracy: 0.8249\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 413us/step - loss: 0.3827 - accuracy: 0.8268\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3759 - accuracy: 0.8366\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.3944 - accuracy: 0.8132\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3962 - accuracy: 0.8113\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 318us/step - loss: 0.3892 - accuracy: 0.8113\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3969 - accuracy: 0.8132\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4051 - accuracy: 0.8249\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.4000 - accuracy: 0.7957\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3891 - accuracy: 0.8191\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4249 - accuracy: 0.8113\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4109 - accuracy: 0.7977\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4135 - accuracy: 0.8152\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4102 - accuracy: 0.8074\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4181 - accuracy: 0.7977\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.3911 - accuracy: 0.8074\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3902 - accuracy: 0.8191\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4065 - accuracy: 0.8035\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3892 - accuracy: 0.8171\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4083 - accuracy: 0.8191\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.4301 - accuracy: 0.8132\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4026 - accuracy: 0.8113\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4109 - accuracy: 0.8074\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3881 - accuracy: 0.8210\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3878 - accuracy: 0.8307\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3849 - accuracy: 0.8385\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3897 - accuracy: 0.8346\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3782 - accuracy: 0.8230\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3749 - accuracy: 0.8307\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3903 - accuracy: 0.8132\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3984 - accuracy: 0.8191\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4095 - accuracy: 0.8191\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4048 - accuracy: 0.8152\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3908 - accuracy: 0.8152\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3929 - accuracy: 0.8210\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3838 - accuracy: 0.8346\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.3845 - accuracy: 0.8385\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3785 - accuracy: 0.8405\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4341 - accuracy: 0.7879\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.3996 - accuracy: 0.8171\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3944 - accuracy: 0.8249\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 413us/step - loss: 0.3930 - accuracy: 0.8210\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3956 - accuracy: 0.8288\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3829 - accuracy: 0.8327\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3807 - accuracy: 0.8424\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3775 - accuracy: 0.8405\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.4099 - accuracy: 0.8113\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4004 - accuracy: 0.8191\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3864 - accuracy: 0.8191\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3764 - accuracy: 0.8346\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3898 - accuracy: 0.8210\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.3829 - accuracy: 0.8171\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3758 - accuracy: 0.8346\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 436us/step - loss: 0.4210 - accuracy: 0.8191\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3966 - accuracy: 0.8307\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3812 - accuracy: 0.8249\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.4141 - accuracy: 0.8113\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4176 - accuracy: 0.8054\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4215 - accuracy: 0.8210\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4167 - accuracy: 0.7938\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.5009 - accuracy: 0.8016\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4365 - accuracy: 0.7646\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.4001 - accuracy: 0.8113\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3901 - accuracy: 0.8210\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3881 - accuracy: 0.8346\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 315us/step - loss: 0.4707 - accuracy: 0.7918\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.4721 - accuracy: 0.7607\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4825 - accuracy: 0.7918\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.4237 - accuracy: 0.8016\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4200 - accuracy: 0.7977\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4184 - accuracy: 0.8171\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3957 - accuracy: 0.8132\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.3986 - accuracy: 0.8171\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3894 - accuracy: 0.8288\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3841 - accuracy: 0.8327\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4230 - accuracy: 0.8054\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.4065 - accuracy: 0.8191\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 401us/step - loss: 0.3865 - accuracy: 0.8132\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4014 - accuracy: 0.8191\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 312us/step - loss: 0.4106 - accuracy: 0.8093\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3820 - accuracy: 0.8288\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.3887 - accuracy: 0.8210\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3863 - accuracy: 0.8444\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.4301 - accuracy: 0.7977\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3968 - accuracy: 0.8113\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3967 - accuracy: 0.8113\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.3851 - accuracy: 0.8230\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3889 - accuracy: 0.8093\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 410us/step - loss: 0.3898 - accuracy: 0.8074\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3770 - accuracy: 0.8288\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3878 - accuracy: 0.8249\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3944 - accuracy: 0.8191\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4003 - accuracy: 0.8191\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3919 - accuracy: 0.8288\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3834 - accuracy: 0.8288\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3754 - accuracy: 0.8249\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3947 - accuracy: 0.8152\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.5193 - accuracy: 0.7918\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.4532 - accuracy: 0.7743\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.4201 - accuracy: 0.8035\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4165 - accuracy: 0.7957\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4036 - accuracy: 0.7957\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3911 - accuracy: 0.8191\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3971 - accuracy: 0.8074\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3885 - accuracy: 0.8191\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3816 - accuracy: 0.8327\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.3881 - accuracy: 0.8210\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.8642 - accuracy: 0.7665\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.6066 - accuracy: 0.7782\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.4669 - accuracy: 0.7763\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4338 - accuracy: 0.7860\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4564 - accuracy: 0.7665\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4218 - accuracy: 0.7977\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4454 - accuracy: 0.7763\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4330 - accuracy: 0.7918\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.4176 - accuracy: 0.8132\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4091 - accuracy: 0.8132\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.4972 - accuracy: 0.8054\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4359 - accuracy: 0.7879\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4131 - accuracy: 0.8152\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.4049 - accuracy: 0.8346\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4035 - accuracy: 0.8132\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4198 - accuracy: 0.8152\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4296 - accuracy: 0.8074\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4240 - accuracy: 0.8074\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.4446 - accuracy: 0.7918\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4130 - accuracy: 0.8152\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.4125 - accuracy: 0.8113\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4063 - accuracy: 0.7977\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4168 - accuracy: 0.8074\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3982 - accuracy: 0.8035\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.4195 - accuracy: 0.7996\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4006 - accuracy: 0.8054\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3977 - accuracy: 0.8268\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3902 - accuracy: 0.8152\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4618 - accuracy: 0.8152\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.4150 - accuracy: 0.8230\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4012 - accuracy: 0.8093\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4011 - accuracy: 0.8171\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3878 - accuracy: 0.8249\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.4010 - accuracy: 0.8132\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3861 - accuracy: 0.8249\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4125 - accuracy: 0.8035\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3938 - accuracy: 0.8210\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.5723 - accuracy: 0.7432\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4798 - accuracy: 0.7646\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4242 - accuracy: 0.7899\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4329 - accuracy: 0.8035\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4211 - accuracy: 0.7938\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4009 - accuracy: 0.8152\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3938 - accuracy: 0.8171\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4009 - accuracy: 0.8171\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3936 - accuracy: 0.8093\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3795 - accuracy: 0.8268\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3810 - accuracy: 0.8191\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4215 - accuracy: 0.8230\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4151 - accuracy: 0.8016\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 413us/step - loss: 0.4076 - accuracy: 0.7938\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4115 - accuracy: 0.8093\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3864 - accuracy: 0.8327\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3921 - accuracy: 0.8191\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4501 - accuracy: 0.7938\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.4139 - accuracy: 0.8074\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4168 - accuracy: 0.7899\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3964 - accuracy: 0.8191\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3866 - accuracy: 0.8230\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3843 - accuracy: 0.8288\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3866 - accuracy: 0.8268\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3886 - accuracy: 0.8230\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.4049 - accuracy: 0.8054\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.7215 - accuracy: 0.7296\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.5235 - accuracy: 0.7646\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4029 - accuracy: 0.8093\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4052 - accuracy: 0.8230\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4012 - accuracy: 0.8307\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4056 - accuracy: 0.8191\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.4032 - accuracy: 0.8132\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4115 - accuracy: 0.8152\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4028 - accuracy: 0.8210\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.4000 - accuracy: 0.8132\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4004 - accuracy: 0.8152\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4235 - accuracy: 0.8016\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.4066 - accuracy: 0.8171\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.4055 - accuracy: 0.8016\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4127 - accuracy: 0.8249\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4083 - accuracy: 0.8113\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4069 - accuracy: 0.8113\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4287 - accuracy: 0.8016\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.4030 - accuracy: 0.8210\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4201 - accuracy: 0.7957\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3973 - accuracy: 0.8171\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4160 - accuracy: 0.8132\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4085 - accuracy: 0.8152\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 400us/step - loss: 0.4059 - accuracy: 0.7860\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3942 - accuracy: 0.8288\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3976 - accuracy: 0.8249\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4005 - accuracy: 0.8132\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.4166 - accuracy: 0.8054\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.4054 - accuracy: 0.8093\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3921 - accuracy: 0.8346\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3997 - accuracy: 0.8268\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3974 - accuracy: 0.8171\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3893 - accuracy: 0.8307\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4018 - accuracy: 0.8113\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.3926 - accuracy: 0.8366\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4055 - accuracy: 0.8054\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4663 - accuracy: 0.7665\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4307 - accuracy: 0.8113\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.5042 - accuracy: 0.7899\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4157 - accuracy: 0.7840\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4039 - accuracy: 0.8074\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4118 - accuracy: 0.8035\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4480 - accuracy: 0.8132\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4358 - accuracy: 0.7918\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4448 - accuracy: 0.7899\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.4431 - accuracy: 0.7996\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4076 - accuracy: 0.8016\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4043 - accuracy: 0.7977\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 429us/step - loss: 0.4046 - accuracy: 0.8132\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3936 - accuracy: 0.8307\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3950 - accuracy: 0.8113\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3912 - accuracy: 0.8307\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3916 - accuracy: 0.8288\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4756 - accuracy: 0.7938\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4090 - accuracy: 0.8210\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4024 - accuracy: 0.8152\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.4010 - accuracy: 0.8152\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3952 - accuracy: 0.8132\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4637 - accuracy: 0.7860\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.4348 - accuracy: 0.7957\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 316us/step - loss: 0.4051 - accuracy: 0.8210\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 401us/step - loss: 0.4050 - accuracy: 0.8152\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4119 - accuracy: 0.8093\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3905 - accuracy: 0.8054\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4121 - accuracy: 0.8152\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4061 - accuracy: 0.7996\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4043 - accuracy: 0.8093\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.4351 - accuracy: 0.7899\n",
      "17/17 [==============================] - 0s 305us/step - loss: 0.4153 - accuracy: 0.7938\n",
      "8/8 [==============================] - 0s 343us/step - loss: 0.9971 - accuracy: 0.7205\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.4248 - accuracy: 0.7977\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4208 - accuracy: 0.7996\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4320 - accuracy: 0.8035\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4476 - accuracy: 0.7802\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4192 - accuracy: 0.7977\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3991 - accuracy: 0.8093\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.4391 - accuracy: 0.8054\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4060 - accuracy: 0.8191\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4109 - accuracy: 0.8191\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4129 - accuracy: 0.8113\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3948 - accuracy: 0.8171\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4135 - accuracy: 0.8074\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.5762 - accuracy: 0.7938\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4404 - accuracy: 0.7918\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.4041 - accuracy: 0.8054\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3983 - accuracy: 0.8191\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4075 - accuracy: 0.8035\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4002 - accuracy: 0.8093\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3987 - accuracy: 0.8016\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4059 - accuracy: 0.7957\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3942 - accuracy: 0.8074\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4065 - accuracy: 0.8113\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4072 - accuracy: 0.7899\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 422us/step - loss: 0.3969 - accuracy: 0.8074\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3946 - accuracy: 0.8054\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.4264 - accuracy: 0.7918\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4308 - accuracy: 0.7879\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.7678 - accuracy: 0.7724\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.7637 - accuracy: 0.7023\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.6027 - accuracy: 0.7549\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4696 - accuracy: 0.7957\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4372 - accuracy: 0.7899\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4151 - accuracy: 0.8152\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4120 - accuracy: 0.8152\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4342 - accuracy: 0.8016\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.4313 - accuracy: 0.7996\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4051 - accuracy: 0.7977\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3890 - accuracy: 0.8230\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3912 - accuracy: 0.8210\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.3924 - accuracy: 0.8268\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3988 - accuracy: 0.8132\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3911 - accuracy: 0.8074\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 411us/step - loss: 0.3893 - accuracy: 0.8230\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 460us/step - loss: 0.3902 - accuracy: 0.8268\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 433us/step - loss: 0.4188 - accuracy: 0.8035\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.4137 - accuracy: 0.8035\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3981 - accuracy: 0.8113\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3819 - accuracy: 0.8191\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3930 - accuracy: 0.8152\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3875 - accuracy: 0.8113\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3878 - accuracy: 0.8093\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.4025 - accuracy: 0.8152\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3949 - accuracy: 0.8093\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4442 - accuracy: 0.7840\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4222 - accuracy: 0.7957\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4726 - accuracy: 0.7646\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3970 - accuracy: 0.8191\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3938 - accuracy: 0.8035\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3966 - accuracy: 0.8113\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3842 - accuracy: 0.8268\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4414 - accuracy: 0.7996\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4283 - accuracy: 0.7899\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4417 - accuracy: 0.7957\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4140 - accuracy: 0.7977\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4220 - accuracy: 0.8035\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.4285 - accuracy: 0.7899\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4055 - accuracy: 0.8152\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.3900 - accuracy: 0.8171\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3926 - accuracy: 0.8230\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.5154 - accuracy: 0.7588\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4280 - accuracy: 0.7802\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3920 - accuracy: 0.8093\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3841 - accuracy: 0.8249\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4505 - accuracy: 0.7957\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4013 - accuracy: 0.8074\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3970 - accuracy: 0.8016\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3899 - accuracy: 0.8132\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3803 - accuracy: 0.8249\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3791 - accuracy: 0.8288\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3771 - accuracy: 0.8113\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3807 - accuracy: 0.8346\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.4015 - accuracy: 0.8152\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3842 - accuracy: 0.8230\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3852 - accuracy: 0.8093\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.3790 - accuracy: 0.8152\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3674 - accuracy: 0.8249\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4226 - accuracy: 0.7957\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4084 - accuracy: 0.7938\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3925 - accuracy: 0.8113\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3937 - accuracy: 0.8171\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3897 - accuracy: 0.8171\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3923 - accuracy: 0.8113\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3753 - accuracy: 0.8230\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 317us/step - loss: 0.4388 - accuracy: 0.7938\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4140 - accuracy: 0.7996\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4198 - accuracy: 0.8093\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4089 - accuracy: 0.8113\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3847 - accuracy: 0.8210\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3882 - accuracy: 0.8249\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4291 - accuracy: 0.8016\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4017 - accuracy: 0.7996\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3806 - accuracy: 0.8074\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3766 - accuracy: 0.8288\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3985 - accuracy: 0.8035\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4199 - accuracy: 0.7996\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4008 - accuracy: 0.8152\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.5793 - accuracy: 0.7821\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4303 - accuracy: 0.7860\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3892 - accuracy: 0.8035\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3853 - accuracy: 0.8171\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3851 - accuracy: 0.8171\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3827 - accuracy: 0.8132\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.4250 - accuracy: 0.7996\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3874 - accuracy: 0.8191\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4502 - accuracy: 0.7996\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4163 - accuracy: 0.8035\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3885 - accuracy: 0.8230\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.4028 - accuracy: 0.7977\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4037 - accuracy: 0.8171\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3861 - accuracy: 0.8230\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3790 - accuracy: 0.8249\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3788 - accuracy: 0.8093\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3907 - accuracy: 0.8191\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4064 - accuracy: 0.8035\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3917 - accuracy: 0.8230\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3943 - accuracy: 0.8210\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3959 - accuracy: 0.7977\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3876 - accuracy: 0.8191\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.4202 - accuracy: 0.8093\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3810 - accuracy: 0.8191\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3772 - accuracy: 0.8307\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4114 - accuracy: 0.8016\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3956 - accuracy: 0.8093\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.5688 - accuracy: 0.7665\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.4929 - accuracy: 0.7510\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4012 - accuracy: 0.8016\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3884 - accuracy: 0.8171\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4006 - accuracy: 0.8171\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3932 - accuracy: 0.8132\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.3938 - accuracy: 0.8210\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4110 - accuracy: 0.8016\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.4580 - accuracy: 0.7782\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4037 - accuracy: 0.8074\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 598us/step - loss: 0.4078 - accuracy: 0.8152\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 447us/step - loss: 0.3792 - accuracy: 0.8346\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3862 - accuracy: 0.8327\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3917 - accuracy: 0.8249\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3911 - accuracy: 0.8132\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3823 - accuracy: 0.8268\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3902 - accuracy: 0.8210\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3798 - accuracy: 0.8210\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3843 - accuracy: 0.8307\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.3884 - accuracy: 0.8171\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4023 - accuracy: 0.7879\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3798 - accuracy: 0.8268\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3770 - accuracy: 0.8249\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.4255 - accuracy: 0.7977\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.3880 - accuracy: 0.7996\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 446us/step - loss: 0.3732 - accuracy: 0.8366\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3659 - accuracy: 0.8385\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4558 - accuracy: 0.8132\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4108 - accuracy: 0.7996\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3804 - accuracy: 0.8152\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.5166 - accuracy: 0.7899\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.5092 - accuracy: 0.7840\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.4560 - accuracy: 0.7840\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4516 - accuracy: 0.7821\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4109 - accuracy: 0.8171\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4087 - accuracy: 0.8132\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3921 - accuracy: 0.8230\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.3944 - accuracy: 0.8171\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4045 - accuracy: 0.8054\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3950 - accuracy: 0.8152\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3930 - accuracy: 0.8249\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3897 - accuracy: 0.8054\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3832 - accuracy: 0.8366\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.4809 - accuracy: 0.7879\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4481 - accuracy: 0.7977\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4155 - accuracy: 0.8093\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3998 - accuracy: 0.8171\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.3999 - accuracy: 0.8191\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3956 - accuracy: 0.8113\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3943 - accuracy: 0.8249\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3835 - accuracy: 0.8249\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3967 - accuracy: 0.8054\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3852 - accuracy: 0.8152\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4261 - accuracy: 0.7918\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3949 - accuracy: 0.8230\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3933 - accuracy: 0.8074\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3884 - accuracy: 0.8074\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3867 - accuracy: 0.8210\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4197 - accuracy: 0.7918\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3956 - accuracy: 0.8171\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.4011 - accuracy: 0.7957\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3897 - accuracy: 0.7996\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3925 - accuracy: 0.8249\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.5676 - accuracy: 0.7529\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4595 - accuracy: 0.8016\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4476 - accuracy: 0.7743\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4389 - accuracy: 0.7977\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4256 - accuracy: 0.8054\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3975 - accuracy: 0.8327\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 316us/step - loss: 0.3942 - accuracy: 0.8171\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3898 - accuracy: 0.8327\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3852 - accuracy: 0.8210\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3838 - accuracy: 0.8327\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.3772 - accuracy: 0.8327\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4337 - accuracy: 0.8054\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.4100 - accuracy: 0.8113\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3939 - accuracy: 0.8152\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.4080 - accuracy: 0.8035\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3873 - accuracy: 0.8268\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.4414 - accuracy: 0.8132\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3929 - accuracy: 0.8132\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3848 - accuracy: 0.8093\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3878 - accuracy: 0.8268\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3795 - accuracy: 0.8132\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3704 - accuracy: 0.8366\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3794 - accuracy: 0.8307\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3880 - accuracy: 0.8191\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3824 - accuracy: 0.8171\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.3737 - accuracy: 0.8230\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3828 - accuracy: 0.8113\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 421us/step - loss: 0.3799 - accuracy: 0.8288\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3796 - accuracy: 0.8210\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4079 - accuracy: 0.8035\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3897 - accuracy: 0.8210\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3773 - accuracy: 0.8249\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3768 - accuracy: 0.8230\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3762 - accuracy: 0.8385\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4085 - accuracy: 0.8113\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3889 - accuracy: 0.8152\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3759 - accuracy: 0.8210\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4257 - accuracy: 0.7957\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 470us/step - loss: 0.3946 - accuracy: 0.8191\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4488 - accuracy: 0.7996\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.4586 - accuracy: 0.7840\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4060 - accuracy: 0.8016\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3915 - accuracy: 0.8093\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3743 - accuracy: 0.8424\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 606us/step - loss: 0.3928 - accuracy: 0.8132\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.3885 - accuracy: 0.8230\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3905 - accuracy: 0.8171\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3831 - accuracy: 0.8268\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.3849 - accuracy: 0.8210\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3830 - accuracy: 0.8152\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3816 - accuracy: 0.8171\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3727 - accuracy: 0.8288\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3889 - accuracy: 0.8113\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4171 - accuracy: 0.7938\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.3903 - accuracy: 0.8171\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3762 - accuracy: 0.8268\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3706 - accuracy: 0.8268\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3730 - accuracy: 0.8171\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3895 - accuracy: 0.8152\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4142 - accuracy: 0.7918\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.4102 - accuracy: 0.7938\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3839 - accuracy: 0.8113\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.4045 - accuracy: 0.7938\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3787 - accuracy: 0.8288\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3745 - accuracy: 0.8288\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3730 - accuracy: 0.8210\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3818 - accuracy: 0.8035\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3847 - accuracy: 0.8210\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3924 - accuracy: 0.7918\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3719 - accuracy: 0.8249\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3775 - accuracy: 0.8327\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3755 - accuracy: 0.8366\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3758 - accuracy: 0.8210\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4003 - accuracy: 0.7899\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3788 - accuracy: 0.8191\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3814 - accuracy: 0.8210\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3973 - accuracy: 0.8054\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3801 - accuracy: 0.8152\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.4066 - accuracy: 0.8132\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3705 - accuracy: 0.8210\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3696 - accuracy: 0.8405\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3694 - accuracy: 0.8385\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3719 - accuracy: 0.8249\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3748 - accuracy: 0.8132\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3706 - accuracy: 0.8327\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3745 - accuracy: 0.8268\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3728 - accuracy: 0.8346\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3643 - accuracy: 0.8327\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 464us/step - loss: 0.3700 - accuracy: 0.8288\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.4715 - accuracy: 0.7782\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4041 - accuracy: 0.8054\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3884 - accuracy: 0.8113\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3876 - accuracy: 0.8268\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 411us/step - loss: 0.3766 - accuracy: 0.8210\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3838 - accuracy: 0.8093\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3709 - accuracy: 0.8346\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3934 - accuracy: 0.8230\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4249 - accuracy: 0.7918\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4167 - accuracy: 0.8035\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3820 - accuracy: 0.8249\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3957 - accuracy: 0.8171\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.4030 - accuracy: 0.8054\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3652 - accuracy: 0.8327\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3730 - accuracy: 0.8444\n",
      "17/17 [==============================] - 0s 304us/step - loss: 0.3595 - accuracy: 0.8424\n",
      "8/8 [==============================] - 0s 509us/step - loss: 1.1191 - accuracy: 0.7283\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3775 - accuracy: 0.8249\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3799 - accuracy: 0.8268\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 430us/step - loss: 0.3876 - accuracy: 0.8171\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3686 - accuracy: 0.8307\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3694 - accuracy: 0.8346\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3789 - accuracy: 0.8171\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3762 - accuracy: 0.8288\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4079 - accuracy: 0.7996\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 416us/step - loss: 0.3892 - accuracy: 0.8191\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3777 - accuracy: 0.8249\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4027 - accuracy: 0.8171\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3764 - accuracy: 0.8113\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3765 - accuracy: 0.8230\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4103 - accuracy: 0.8054\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3672 - accuracy: 0.8366\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3718 - accuracy: 0.8191\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3905 - accuracy: 0.8152\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3903 - accuracy: 0.8074\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3740 - accuracy: 0.8191\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 530us/step - loss: 0.3684 - accuracy: 0.8152\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 512us/step - loss: 0.5078 - accuracy: 0.7588\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 533us/step - loss: 0.4015 - accuracy: 0.8210\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 490us/step - loss: 0.3875 - accuracy: 0.8230\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 562us/step - loss: 0.4794 - accuracy: 0.7802\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 549us/step - loss: 0.4639 - accuracy: 0.7782\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 433us/step - loss: 0.4178 - accuracy: 0.8093\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.3861 - accuracy: 0.8093\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 512us/step - loss: 0.3842 - accuracy: 0.8171\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 464us/step - loss: 0.3928 - accuracy: 0.8152\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 442us/step - loss: 0.4036 - accuracy: 0.8191\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 447us/step - loss: 0.4073 - accuracy: 0.8074\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4151 - accuracy: 0.8074\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 619us/step - loss: 0.4275 - accuracy: 0.7996\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 564us/step - loss: 0.4261 - accuracy: 0.8074\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 466us/step - loss: 0.3850 - accuracy: 0.8230\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 470us/step - loss: 0.4190 - accuracy: 0.8035\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 620us/step - loss: 0.3959 - accuracy: 0.7977\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 439us/step - loss: 0.3817 - accuracy: 0.8210\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 525us/step - loss: 0.3994 - accuracy: 0.7996\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 467us/step - loss: 0.4403 - accuracy: 0.8016\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 643us/step - loss: 0.4118 - accuracy: 0.7840\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 500us/step - loss: 0.3901 - accuracy: 0.8054\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.4230 - accuracy: 0.7957\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3992 - accuracy: 0.8152\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.3761 - accuracy: 0.8249\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3855 - accuracy: 0.8171\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3704 - accuracy: 0.8385\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3692 - accuracy: 0.8366\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3677 - accuracy: 0.8307\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3724 - accuracy: 0.8366\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3896 - accuracy: 0.8171\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3897 - accuracy: 0.8210\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4172 - accuracy: 0.8230\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4133 - accuracy: 0.7899\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3711 - accuracy: 0.8444\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3766 - accuracy: 0.8307\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3649 - accuracy: 0.8327\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3665 - accuracy: 0.8268\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3867 - accuracy: 0.8191\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3694 - accuracy: 0.8268\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3673 - accuracy: 0.8327\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3657 - accuracy: 0.8327\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3647 - accuracy: 0.8424\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3823 - accuracy: 0.8074\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3601 - accuracy: 0.8424\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3763 - accuracy: 0.8249\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4059 - accuracy: 0.8132\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4078 - accuracy: 0.7977\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3841 - accuracy: 0.8230\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3867 - accuracy: 0.8210\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3837 - accuracy: 0.8171\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.4832 - accuracy: 0.7840\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4211 - accuracy: 0.7977\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.3927 - accuracy: 0.8191\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4068 - accuracy: 0.8074\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3798 - accuracy: 0.8191\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3766 - accuracy: 0.8249\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3776 - accuracy: 0.8210\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3975 - accuracy: 0.8366\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3881 - accuracy: 0.8074\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.4075 - accuracy: 0.8054\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3817 - accuracy: 0.8093\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.4593 - accuracy: 0.7782\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4134 - accuracy: 0.8054\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3787 - accuracy: 0.8249\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3760 - accuracy: 0.8268\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3872 - accuracy: 0.8210\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3759 - accuracy: 0.8152\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3808 - accuracy: 0.8171\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3892 - accuracy: 0.8191\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3719 - accuracy: 0.8307\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3712 - accuracy: 0.8307\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3644 - accuracy: 0.8307\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3707 - accuracy: 0.8249\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3769 - accuracy: 0.8093\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3692 - accuracy: 0.8210\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4551 - accuracy: 0.7977\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3816 - accuracy: 0.8152\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3767 - accuracy: 0.8249\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3780 - accuracy: 0.8249\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.3655 - accuracy: 0.8288\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3754 - accuracy: 0.8268\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3805 - accuracy: 0.8191\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4204 - accuracy: 0.8152\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3893 - accuracy: 0.8132\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3870 - accuracy: 0.8210\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 410us/step - loss: 0.3662 - accuracy: 0.8444\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3954 - accuracy: 0.8191\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 310us/step - loss: 0.3789 - accuracy: 0.8249\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.3792 - accuracy: 0.8268\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4117 - accuracy: 0.8093\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3749 - accuracy: 0.8327\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.3655 - accuracy: 0.8288\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3671 - accuracy: 0.8191\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3745 - accuracy: 0.8288\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.3600 - accuracy: 0.8424\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3700 - accuracy: 0.8268\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.3715 - accuracy: 0.8307\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 433us/step - loss: 0.3651 - accuracy: 0.8230\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3675 - accuracy: 0.8366\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3671 - accuracy: 0.8268\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3690 - accuracy: 0.8132\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 413us/step - loss: 0.3661 - accuracy: 0.8444\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 401us/step - loss: 0.3719 - accuracy: 0.8327\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.3868 - accuracy: 0.8074\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.4119 - accuracy: 0.8054\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3819 - accuracy: 0.8093\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 432us/step - loss: 0.3681 - accuracy: 0.8405\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.4422 - accuracy: 0.7899\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.4239 - accuracy: 0.8093\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 401us/step - loss: 0.4156 - accuracy: 0.7879\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3795 - accuracy: 0.8210\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3691 - accuracy: 0.8249\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 468us/step - loss: 0.3717 - accuracy: 0.8230\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.4418 - accuracy: 0.7840\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 433us/step - loss: 0.4013 - accuracy: 0.8210\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3734 - accuracy: 0.8210\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3727 - accuracy: 0.8268\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 445us/step - loss: 0.3696 - accuracy: 0.8327\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.3716 - accuracy: 0.8152\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.3684 - accuracy: 0.8230\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.5039 - accuracy: 0.7626\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4760 - accuracy: 0.7957\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3916 - accuracy: 0.8093\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 423us/step - loss: 0.4032 - accuracy: 0.8171\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3941 - accuracy: 0.8210\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3751 - accuracy: 0.8327\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3929 - accuracy: 0.8113\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3743 - accuracy: 0.8171\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 678us/step - loss: 0.3698 - accuracy: 0.8210\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 463us/step - loss: 0.4443 - accuracy: 0.7918\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.4080 - accuracy: 0.7996\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 549us/step - loss: 0.3877 - accuracy: 0.8132\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 422us/step - loss: 0.3702 - accuracy: 0.8249\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.3874 - accuracy: 0.8230\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3718 - accuracy: 0.8210\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4304 - accuracy: 0.7918\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 415us/step - loss: 0.3861 - accuracy: 0.8210\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.3880 - accuracy: 0.8074\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.5042 - accuracy: 0.7860\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.4370 - accuracy: 0.7996\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3818 - accuracy: 0.8210\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3951 - accuracy: 0.8191\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 434us/step - loss: 0.3786 - accuracy: 0.8191\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3631 - accuracy: 0.8444\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 424us/step - loss: 0.4008 - accuracy: 0.8054\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.4002 - accuracy: 0.8093\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3698 - accuracy: 0.8366\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 489us/step - loss: 0.3819 - accuracy: 0.8210\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 430us/step - loss: 0.3908 - accuracy: 0.8268\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.3881 - accuracy: 0.8054\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3746 - accuracy: 0.8268\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.3635 - accuracy: 0.8366\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 561us/step - loss: 0.3675 - accuracy: 0.8405\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 467us/step - loss: 0.3679 - accuracy: 0.8327\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3659 - accuracy: 0.8385\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.3647 - accuracy: 0.8346\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 445us/step - loss: 0.3719 - accuracy: 0.8171\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3727 - accuracy: 0.8230\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3674 - accuracy: 0.8346\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3698 - accuracy: 0.8268\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3682 - accuracy: 0.8230\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3764 - accuracy: 0.8249\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 450us/step - loss: 0.3591 - accuracy: 0.8424\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.3829 - accuracy: 0.8054\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3707 - accuracy: 0.8288\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3821 - accuracy: 0.8230\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3868 - accuracy: 0.8132\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 510us/step - loss: 0.3962 - accuracy: 0.8113\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.3994 - accuracy: 0.8035\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3910 - accuracy: 0.8171\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.3747 - accuracy: 0.8288\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3832 - accuracy: 0.8288\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 456us/step - loss: 0.4055 - accuracy: 0.8113\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 449us/step - loss: 0.4043 - accuracy: 0.8093\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3855 - accuracy: 0.7977\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3691 - accuracy: 0.8268\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3731 - accuracy: 0.8307\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3824 - accuracy: 0.8268\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 454us/step - loss: 0.3648 - accuracy: 0.8346\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3769 - accuracy: 0.8210\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 430us/step - loss: 0.3735 - accuracy: 0.8307\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 422us/step - loss: 0.3729 - accuracy: 0.8307\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 423us/step - loss: 0.3663 - accuracy: 0.8327\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3673 - accuracy: 0.8346\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3873 - accuracy: 0.8093\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3871 - accuracy: 0.8171\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3778 - accuracy: 0.8230\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3711 - accuracy: 0.8385\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3797 - accuracy: 0.8210\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4234 - accuracy: 0.7879\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3880 - accuracy: 0.8132\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3742 - accuracy: 0.8249\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3982 - accuracy: 0.7899\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3663 - accuracy: 0.8268\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3656 - accuracy: 0.8249\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3702 - accuracy: 0.8327\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3841 - accuracy: 0.8152\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3889 - accuracy: 0.8230\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.3763 - accuracy: 0.8191\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3611 - accuracy: 0.8249\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.5265 - accuracy: 0.7568\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4288 - accuracy: 0.7977\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4165 - accuracy: 0.8035\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.3892 - accuracy: 0.8210\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3813 - accuracy: 0.8171\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.3707 - accuracy: 0.8171\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4784 - accuracy: 0.7860\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3892 - accuracy: 0.8249\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3895 - accuracy: 0.8093\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3823 - accuracy: 0.8191\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3796 - accuracy: 0.8210\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.3773 - accuracy: 0.8191\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4520 - accuracy: 0.8074\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4086 - accuracy: 0.8152\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3864 - accuracy: 0.8093\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3819 - accuracy: 0.8152\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3779 - accuracy: 0.8054\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.4098 - accuracy: 0.8074\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4332 - accuracy: 0.7860\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.4336 - accuracy: 0.7996\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3984 - accuracy: 0.8074\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3749 - accuracy: 0.8191\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4366 - accuracy: 0.8093\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.3837 - accuracy: 0.8152\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4848 - accuracy: 0.7860\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4476 - accuracy: 0.7879\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3909 - accuracy: 0.8016\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4169 - accuracy: 0.8093\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3924 - accuracy: 0.8249\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4019 - accuracy: 0.8132\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3852 - accuracy: 0.8191\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3795 - accuracy: 0.8268\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3781 - accuracy: 0.8249\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3738 - accuracy: 0.8054\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3570 - accuracy: 0.8346\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 401us/step - loss: 0.3643 - accuracy: 0.8288\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3694 - accuracy: 0.8346\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4142 - accuracy: 0.7860\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3823 - accuracy: 0.8054\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4074 - accuracy: 0.8171\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3922 - accuracy: 0.8230\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4304 - accuracy: 0.8093\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4368 - accuracy: 0.7977\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3975 - accuracy: 0.8054\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4032 - accuracy: 0.8074\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3765 - accuracy: 0.8268\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3801 - accuracy: 0.8191\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3800 - accuracy: 0.8210\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.4623 - accuracy: 0.7763\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4022 - accuracy: 0.8054\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4105 - accuracy: 0.8035\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 317us/step - loss: 0.3943 - accuracy: 0.8016\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3873 - accuracy: 0.8152\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4010 - accuracy: 0.8132\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.3774 - accuracy: 0.8230\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3599 - accuracy: 0.8268\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.5470 - accuracy: 0.7665\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4466 - accuracy: 0.8035\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4183 - accuracy: 0.8016\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4036 - accuracy: 0.7899\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3759 - accuracy: 0.8268\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4552 - accuracy: 0.7724\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4234 - accuracy: 0.7821\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3777 - accuracy: 0.8268\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.3720 - accuracy: 0.8230\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.5128 - accuracy: 0.7529\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 423us/step - loss: 0.4193 - accuracy: 0.8035\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4868 - accuracy: 0.7899\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4316 - accuracy: 0.7782\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4079 - accuracy: 0.8035\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3732 - accuracy: 0.8113\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4061 - accuracy: 0.7860\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.4057 - accuracy: 0.8113\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3952 - accuracy: 0.8074\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3775 - accuracy: 0.8191\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.4176 - accuracy: 0.8074\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4636 - accuracy: 0.7704\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4294 - accuracy: 0.8074\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 411us/step - loss: 0.4143 - accuracy: 0.8054\n",
      "17/17 [==============================] - 0s 310us/step - loss: 0.4465 - accuracy: 0.7626\n",
      "8/8 [==============================] - 0s 377us/step - loss: 1.1985 - accuracy: 0.7205\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.4128 - accuracy: 0.8035\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3961 - accuracy: 0.8074\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3868 - accuracy: 0.7996\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3754 - accuracy: 0.8132\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3765 - accuracy: 0.8249\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3782 - accuracy: 0.8327\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 1.3809 - accuracy: 0.7510\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 430us/step - loss: 0.5007 - accuracy: 0.7743\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4237 - accuracy: 0.7918\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.4060 - accuracy: 0.8074\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3901 - accuracy: 0.8191\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4174 - accuracy: 0.7996\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4025 - accuracy: 0.8016\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 451us/step - loss: 0.4117 - accuracy: 0.7996\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.3918 - accuracy: 0.8152\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4331 - accuracy: 0.7899\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4130 - accuracy: 0.8074\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3918 - accuracy: 0.8016\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4006 - accuracy: 0.8113\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4130 - accuracy: 0.7899\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3872 - accuracy: 0.8113\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3868 - accuracy: 0.8249\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4025 - accuracy: 0.8016\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3926 - accuracy: 0.8288\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3819 - accuracy: 0.8171\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3892 - accuracy: 0.8268\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3942 - accuracy: 0.8152\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3923 - accuracy: 0.8074\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.3838 - accuracy: 0.8171\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.3912 - accuracy: 0.8288\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3771 - accuracy: 0.8307\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.3837 - accuracy: 0.8171\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3761 - accuracy: 0.8307\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4589 - accuracy: 0.7763\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4331 - accuracy: 0.7918\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3857 - accuracy: 0.8210\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4325 - accuracy: 0.8016\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3916 - accuracy: 0.8152\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4441 - accuracy: 0.8054\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4719 - accuracy: 0.7685\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3825 - accuracy: 0.8230\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3753 - accuracy: 0.8268\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3821 - accuracy: 0.8230\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 413us/step - loss: 0.3807 - accuracy: 0.8152\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3776 - accuracy: 0.8268\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3838 - accuracy: 0.8230\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3911 - accuracy: 0.8093\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3962 - accuracy: 0.8054\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3792 - accuracy: 0.8210\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 400us/step - loss: 0.3740 - accuracy: 0.8171\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.3641 - accuracy: 0.8230\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4454 - accuracy: 0.8016\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 444us/step - loss: 0.3917 - accuracy: 0.8035\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.3760 - accuracy: 0.8307\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 608us/step - loss: 0.3739 - accuracy: 0.8307\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 442us/step - loss: 0.4251 - accuracy: 0.7899\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 517us/step - loss: 0.4275 - accuracy: 0.7918\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 484us/step - loss: 0.3914 - accuracy: 0.8132\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 538us/step - loss: 0.4022 - accuracy: 0.8152\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 592us/step - loss: 0.3840 - accuracy: 0.8288\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 444us/step - loss: 0.3842 - accuracy: 0.8210\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 536us/step - loss: 0.3764 - accuracy: 0.8230\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 505us/step - loss: 0.3812 - accuracy: 0.8249\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 605us/step - loss: 0.4147 - accuracy: 0.8093\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8035\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 508us/step - loss: 0.4723 - accuracy: 0.7996\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 525us/step - loss: 0.3868 - accuracy: 0.8268\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 608us/step - loss: 0.3836 - accuracy: 0.8307\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 410us/step - loss: 0.4000 - accuracy: 0.8288\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.4023 - accuracy: 0.8113\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 471us/step - loss: 0.4065 - accuracy: 0.8054\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 605us/step - loss: 0.3838 - accuracy: 0.8171\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 462us/step - loss: 0.3815 - accuracy: 0.8093\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 607us/step - loss: 0.3859 - accuracy: 0.8268\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 509us/step - loss: 0.3812 - accuracy: 0.8288\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3770 - accuracy: 0.8288\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3818 - accuracy: 0.8366\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.3900 - accuracy: 0.8113\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3808 - accuracy: 0.8230\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 584us/step - loss: 0.4749 - accuracy: 0.7782\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 531us/step - loss: 0.4484 - accuracy: 0.7918\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 542us/step - loss: 0.3977 - accuracy: 0.7957\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 463us/step - loss: 0.3756 - accuracy: 0.8249\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 511us/step - loss: 0.3814 - accuracy: 0.8191\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 506us/step - loss: 0.3850 - accuracy: 0.8152\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 601us/step - loss: 0.3774 - accuracy: 0.8132\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 450us/step - loss: 0.3750 - accuracy: 0.8152\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.4605 - accuracy: 0.7685\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 493us/step - loss: 0.4031 - accuracy: 0.8152\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 584us/step - loss: 0.3824 - accuracy: 0.8288\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.3841 - accuracy: 0.8268\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4484 - accuracy: 0.8035\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 527us/step - loss: 0.4162 - accuracy: 0.7996\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 505us/step - loss: 0.3823 - accuracy: 0.8171\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 608us/step - loss: 0.3766 - accuracy: 0.8132\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 427us/step - loss: 0.3846 - accuracy: 0.8152\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 491us/step - loss: 0.5433 - accuracy: 0.7782\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 479us/step - loss: 0.4140 - accuracy: 0.8113\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 612us/step - loss: 0.4084 - accuracy: 0.8016\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 449us/step - loss: 0.4004 - accuracy: 0.8152\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 500us/step - loss: 0.3824 - accuracy: 0.8113\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 506us/step - loss: 0.4077 - accuracy: 0.8054\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4008 - accuracy: 0.7996\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.3976 - accuracy: 0.8074\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3876 - accuracy: 0.8113\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4241 - accuracy: 0.7977\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 480us/step - loss: 0.4395 - accuracy: 0.8035\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.3949 - accuracy: 0.8230\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 588us/step - loss: 0.3795 - accuracy: 0.8346\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.4240 - accuracy: 0.7996\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 471us/step - loss: 0.4078 - accuracy: 0.8035\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 520us/step - loss: 0.4021 - accuracy: 0.8191\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.4107 - accuracy: 0.8093\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 528us/step - loss: 0.3836 - accuracy: 0.8307\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 532us/step - loss: 0.3921 - accuracy: 0.8074\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 516us/step - loss: 0.4723 - accuracy: 0.7724\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 498us/step - loss: 0.3987 - accuracy: 0.8054\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 592us/step - loss: 0.4016 - accuracy: 0.8016\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.7821\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 527us/step - loss: 0.3807 - accuracy: 0.8152\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 472us/step - loss: 0.3844 - accuracy: 0.8230\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 588us/step - loss: 0.3828 - accuracy: 0.8249\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3891 - accuracy: 0.8230\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 519us/step - loss: 0.4425 - accuracy: 0.7918\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 543us/step - loss: 0.4129 - accuracy: 0.8016\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 490us/step - loss: 0.3845 - accuracy: 0.8268\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 569us/step - loss: 0.4268 - accuracy: 0.7977\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 468us/step - loss: 0.4189 - accuracy: 0.8074\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 487us/step - loss: 0.3763 - accuracy: 0.8307\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.3756 - accuracy: 0.8210\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3943 - accuracy: 0.8016\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3734 - accuracy: 0.8288\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.3721 - accuracy: 0.8288\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3648 - accuracy: 0.8346\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 491us/step - loss: 0.3733 - accuracy: 0.8191\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 475us/step - loss: 0.3793 - accuracy: 0.8249\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 606us/step - loss: 0.3958 - accuracy: 0.8035\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 468us/step - loss: 0.4221 - accuracy: 0.7938\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 490us/step - loss: 0.3758 - accuracy: 0.8230\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.3834 - accuracy: 0.8191\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 534us/step - loss: 0.4238 - accuracy: 0.7938\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 534us/step - loss: 0.4691 - accuracy: 0.7840\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 473us/step - loss: 0.4154 - accuracy: 0.7977\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 475us/step - loss: 0.3892 - accuracy: 0.8132\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 750us/step - loss: 0.3733 - accuracy: 0.8268\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 529us/step - loss: 0.3879 - accuracy: 0.8152\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 950us/step - loss: 0.3750 - accuracy: 0.8093\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 508us/step - loss: 0.4404 - accuracy: 0.7899\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 596us/step - loss: 0.3789 - accuracy: 0.8191\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 440us/step - loss: 0.3827 - accuracy: 0.8113\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 537us/step - loss: 0.3787 - accuracy: 0.8268\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 464us/step - loss: 0.3764 - accuracy: 0.8152\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.3750 - accuracy: 0.8152\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 470us/step - loss: 0.3715 - accuracy: 0.8132\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 431us/step - loss: 0.3689 - accuracy: 0.8288\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 435us/step - loss: 0.3741 - accuracy: 0.8152\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.3739 - accuracy: 0.8171\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 473us/step - loss: 0.3892 - accuracy: 0.8210\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3914 - accuracy: 0.8132\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.4000 - accuracy: 0.8035\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.4255 - accuracy: 0.8132\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.4243 - accuracy: 0.7938\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 579us/step - loss: 0.4084 - accuracy: 0.8074\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 483us/step - loss: 0.3896 - accuracy: 0.8113\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 523us/step - loss: 0.4727 - accuracy: 0.7704\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 519us/step - loss: 0.6510 - accuracy: 0.7374\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 524us/step - loss: 0.5692 - accuracy: 0.7393\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 610us/step - loss: 0.5255 - accuracy: 0.7704\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 464us/step - loss: 0.4453 - accuracy: 0.7899\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 530us/step - loss: 0.4411 - accuracy: 0.7957\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 484us/step - loss: 0.4545 - accuracy: 0.7802\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 645us/step - loss: 0.4524 - accuracy: 0.7743\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7802\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.4545 - accuracy: 0.7763\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 594us/step - loss: 0.4267 - accuracy: 0.7977\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 538us/step - loss: 0.4145 - accuracy: 0.7996\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 447us/step - loss: 0.4227 - accuracy: 0.8054\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 577us/step - loss: 0.4148 - accuracy: 0.7996\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 566us/step - loss: 0.4359 - accuracy: 0.7938\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 478us/step - loss: 0.4270 - accuracy: 0.7996\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 487us/step - loss: 0.4183 - accuracy: 0.7879\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 469us/step - loss: 0.4129 - accuracy: 0.7996\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 499us/step - loss: 0.4841 - accuracy: 0.7743\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.4607 - accuracy: 0.7840\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4354 - accuracy: 0.7899\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4178 - accuracy: 0.7879\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 318us/step - loss: 0.4171 - accuracy: 0.7996\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 494us/step - loss: 0.4139 - accuracy: 0.8016\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 513us/step - loss: 0.4084 - accuracy: 0.8093\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 526us/step - loss: 0.4158 - accuracy: 0.8035\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 479us/step - loss: 0.4190 - accuracy: 0.8074\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 508us/step - loss: 0.4038 - accuracy: 0.8054\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 509us/step - loss: 0.4285 - accuracy: 0.8093\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 593us/step - loss: 0.4870 - accuracy: 0.7471\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.4501 - accuracy: 0.7568\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 496us/step - loss: 0.4297 - accuracy: 0.7860\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 509us/step - loss: 0.4161 - accuracy: 0.7918\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 583us/step - loss: 0.4147 - accuracy: 0.7938\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 528us/step - loss: 0.4272 - accuracy: 0.7763\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4111 - accuracy: 0.8035\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 555us/step - loss: 0.4707 - accuracy: 0.7607\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 615us/step - loss: 0.4483 - accuracy: 0.7879\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 584us/step - loss: 0.4221 - accuracy: 0.8016\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 480us/step - loss: 0.4239 - accuracy: 0.7821\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 484us/step - loss: 0.4046 - accuracy: 0.7996\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 606us/step - loss: 0.4048 - accuracy: 0.7996\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 486us/step - loss: 0.4294 - accuracy: 0.7957\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 465us/step - loss: 0.4060 - accuracy: 0.8016\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 474us/step - loss: 0.3951 - accuracy: 0.8074\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3984 - accuracy: 0.8191\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.4033 - accuracy: 0.7938\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3991 - accuracy: 0.8113\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4011 - accuracy: 0.8016\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 509us/step - loss: 0.4410 - accuracy: 0.8074\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 506us/step - loss: 0.4374 - accuracy: 0.8054\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 610us/step - loss: 0.4302 - accuracy: 0.7996\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 481us/step - loss: 0.4204 - accuracy: 0.8035\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 506us/step - loss: 0.4078 - accuracy: 0.8016\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.4632 - accuracy: 0.7704\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 611us/step - loss: 0.4204 - accuracy: 0.7860\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 479us/step - loss: 0.4046 - accuracy: 0.7899\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 581us/step - loss: 0.4210 - accuracy: 0.7879\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.3918 - accuracy: 0.8093\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.4146 - accuracy: 0.8132\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.6027 - accuracy: 0.7549\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 521us/step - loss: 0.4396 - accuracy: 0.7918\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 638us/step - loss: 0.4184 - accuracy: 0.7977\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 502us/step - loss: 0.4136 - accuracy: 0.7957\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 587us/step - loss: 0.4190 - accuracy: 0.7879\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 627us/step - loss: 0.4144 - accuracy: 0.7938\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 622us/step - loss: 0.4032 - accuracy: 0.8016\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 486us/step - loss: 0.4184 - accuracy: 0.8054\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 546us/step - loss: 0.4132 - accuracy: 0.8074\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 506us/step - loss: 0.4013 - accuracy: 0.8113\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 445us/step - loss: 0.4229 - accuracy: 0.7802\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 571us/step - loss: 0.4187 - accuracy: 0.8093\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4005 - accuracy: 0.8093\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4091 - accuracy: 0.7938\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.4104 - accuracy: 0.7996\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4133 - accuracy: 0.7899\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4951 - accuracy: 0.7374\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 552us/step - loss: 0.4363 - accuracy: 0.7821\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 543us/step - loss: 0.4169 - accuracy: 0.7918\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 568us/step - loss: 0.4142 - accuracy: 0.8035\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 425us/step - loss: 0.4107 - accuracy: 0.7996\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 539us/step - loss: 0.4026 - accuracy: 0.7996\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 480us/step - loss: 0.4125 - accuracy: 0.7957\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.3957 - accuracy: 0.8093\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 603us/step - loss: 0.4172 - accuracy: 0.7918\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 441us/step - loss: 0.4146 - accuracy: 0.8074\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 493us/step - loss: 0.4043 - accuracy: 0.8132\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 519us/step - loss: 0.4232 - accuracy: 0.7977\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 562us/step - loss: 0.4320 - accuracy: 0.7918\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7860\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 512us/step - loss: 0.4140 - accuracy: 0.7938\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 475us/step - loss: 0.4185 - accuracy: 0.7840\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 575us/step - loss: 0.4198 - accuracy: 0.7802\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.4060 - accuracy: 0.7977\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 522us/step - loss: 0.4267 - accuracy: 0.7821\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 469us/step - loss: 0.7173 - accuracy: 0.7335\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.5186 - accuracy: 0.7374\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 500us/step - loss: 0.4557 - accuracy: 0.7763\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 467us/step - loss: 0.4380 - accuracy: 0.8035\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 416us/step - loss: 0.4270 - accuracy: 0.7938\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 481us/step - loss: 0.4189 - accuracy: 0.8035\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.4511 - accuracy: 0.7938\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.4282 - accuracy: 0.8054\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4276 - accuracy: 0.7957\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4285 - accuracy: 0.7821\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 525us/step - loss: 0.4143 - accuracy: 0.8074\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.4172 - accuracy: 0.7879\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 530us/step - loss: 0.4128 - accuracy: 0.8016\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.4080 - accuracy: 0.8191\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.4157 - accuracy: 0.7918\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.4177 - accuracy: 0.7899\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 504us/step - loss: 0.4114 - accuracy: 0.8035\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.4146 - accuracy: 0.8074\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 594us/step - loss: 0.4112 - accuracy: 0.8054\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 424us/step - loss: 0.4129 - accuracy: 0.8016\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 530us/step - loss: 0.4088 - accuracy: 0.8132\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.4362 - accuracy: 0.7899\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 558us/step - loss: 0.4303 - accuracy: 0.7840\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4447 - accuracy: 0.7607\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 486us/step - loss: 0.4242 - accuracy: 0.7879\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 516us/step - loss: 0.4415 - accuracy: 0.7821\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 530us/step - loss: 0.4250 - accuracy: 0.7918\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 422us/step - loss: 0.4114 - accuracy: 0.7957\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 520us/step - loss: 0.4631 - accuracy: 0.7802\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 467us/step - loss: 0.4254 - accuracy: 0.8093\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 558us/step - loss: 0.4424 - accuracy: 0.7860\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.5245 - accuracy: 0.7685\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 452us/step - loss: 0.4337 - accuracy: 0.7879\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 481us/step - loss: 0.4179 - accuracy: 0.7879\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4070 - accuracy: 0.8035\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4141 - accuracy: 0.8113\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.4101 - accuracy: 0.8113\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3964 - accuracy: 0.8113\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4219 - accuracy: 0.7782\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 500us/step - loss: 0.3995 - accuracy: 0.8210\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 499us/step - loss: 0.4023 - accuracy: 0.8035\n",
      "17/17 [==============================] - 0s 464us/step - loss: 0.3898 - accuracy: 0.8171\n",
      "8/8 [==============================] - 0s 597us/step - loss: 0.9370 - accuracy: 0.7283\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 494us/step - loss: 0.4005 - accuracy: 0.8054\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8074\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 583us/step - loss: 0.4050 - accuracy: 0.8113\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 481us/step - loss: 0.3928 - accuracy: 0.8191\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 587us/step - loss: 0.3979 - accuracy: 0.8132\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 471us/step - loss: 0.4000 - accuracy: 0.8152\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 427us/step - loss: 0.4010 - accuracy: 0.7996\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.4177 - accuracy: 0.7957\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 458us/step - loss: 0.4019 - accuracy: 0.8074\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 522us/step - loss: 0.4050 - accuracy: 0.8054\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 424us/step - loss: 0.4113 - accuracy: 0.7938\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 423us/step - loss: 0.4373 - accuracy: 0.7879\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 452us/step - loss: 0.5301 - accuracy: 0.7490\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 461us/step - loss: 0.4734 - accuracy: 0.7860\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.4351 - accuracy: 0.7918\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4489 - accuracy: 0.7899\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.4160 - accuracy: 0.7977\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4298 - accuracy: 0.7977\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4211 - accuracy: 0.7802\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4298 - accuracy: 0.7977\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 451us/step - loss: 0.4172 - accuracy: 0.7938\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 474us/step - loss: 0.4226 - accuracy: 0.7899\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 561us/step - loss: 0.4153 - accuracy: 0.7977\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 452us/step - loss: 0.4013 - accuracy: 0.8171\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 496us/step - loss: 0.4161 - accuracy: 0.8054\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 508us/step - loss: 0.4093 - accuracy: 0.8016\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 591us/step - loss: 0.4196 - accuracy: 0.7899\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 468us/step - loss: 0.4029 - accuracy: 0.8054\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 522us/step - loss: 0.4138 - accuracy: 0.7879\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 491us/step - loss: 0.4179 - accuracy: 0.8035\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 536us/step - loss: 0.4065 - accuracy: 0.7977\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 489us/step - loss: 0.4010 - accuracy: 0.8113\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.7840\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 511us/step - loss: 0.4178 - accuracy: 0.8054\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 507us/step - loss: 0.4029 - accuracy: 0.8074\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 487us/step - loss: 0.4785 - accuracy: 0.7840\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 437us/step - loss: 0.4400 - accuracy: 0.7821\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 499us/step - loss: 0.4142 - accuracy: 0.8132\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 474us/step - loss: 0.4276 - accuracy: 0.7938\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 544us/step - loss: 0.4114 - accuracy: 0.8093\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 421us/step - loss: 0.3985 - accuracy: 0.8074\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 679us/step - loss: 0.3974 - accuracy: 0.8093\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 589us/step - loss: 0.4279 - accuracy: 0.7957\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.3907 - accuracy: 0.8191\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4229 - accuracy: 0.7957\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.4037 - accuracy: 0.7996\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 432us/step - loss: 0.4101 - accuracy: 0.8035\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 585us/step - loss: 0.4087 - accuracy: 0.7957\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 556us/step - loss: 0.4140 - accuracy: 0.7996\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 586us/step - loss: 0.4261 - accuracy: 0.7918\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.4324 - accuracy: 0.7938\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 511us/step - loss: 0.4007 - accuracy: 0.8074\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.3983 - accuracy: 0.8016\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 623us/step - loss: 0.4165 - accuracy: 0.7996\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.3957 - accuracy: 0.8113\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.4169 - accuracy: 0.7899\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 576us/step - loss: 0.3999 - accuracy: 0.7957\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 598us/step - loss: 0.3901 - accuracy: 0.8132\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 960us/step - loss: 0.3941 - accuracy: 0.7899\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 716us/step - loss: 0.3922 - accuracy: 0.8191\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 480us/step - loss: 0.4083 - accuracy: 0.8016\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 579us/step - loss: 0.3933 - accuracy: 0.8152\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.4181 - accuracy: 0.7957\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 515us/step - loss: 0.4257 - accuracy: 0.7860\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 504us/step - loss: 0.3848 - accuracy: 0.8249\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 515us/step - loss: 0.3889 - accuracy: 0.8191\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 570us/step - loss: 0.3969 - accuracy: 0.8035\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 419us/step - loss: 0.3921 - accuracy: 0.8152\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 502us/step - loss: 0.4008 - accuracy: 0.8113\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.4163 - accuracy: 0.7860\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.4370 - accuracy: 0.7782\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 422us/step - loss: 0.4936 - accuracy: 0.7646\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4193 - accuracy: 0.8093\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3987 - accuracy: 0.8093\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.4085 - accuracy: 0.7957\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 494us/step - loss: 0.4035 - accuracy: 0.8035\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 615us/step - loss: 0.3903 - accuracy: 0.8191\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 472us/step - loss: 0.3869 - accuracy: 0.8152\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.4135 - accuracy: 0.8054\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 454us/step - loss: 0.3984 - accuracy: 0.8191\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 496us/step - loss: 0.4030 - accuracy: 0.8171\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 597us/step - loss: 0.4300 - accuracy: 0.7996\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.5010 - accuracy: 0.7879\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 505us/step - loss: 0.4676 - accuracy: 0.7840\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.4767 - accuracy: 0.7626\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 510us/step - loss: 0.4386 - accuracy: 0.8074\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 588us/step - loss: 0.4567 - accuracy: 0.7957\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4972 - accuracy: 0.7704\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 483us/step - loss: 0.4399 - accuracy: 0.7938\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 611us/step - loss: 0.4548 - accuracy: 0.7977\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 459us/step - loss: 0.4631 - accuracy: 0.7840\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.4918 - accuracy: 0.7743\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 467us/step - loss: 0.4598 - accuracy: 0.7996\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 507us/step - loss: 0.5735 - accuracy: 0.7607\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 618us/step - loss: 0.4718 - accuracy: 0.7607\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 482us/step - loss: 0.4363 - accuracy: 0.7899\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 562us/step - loss: 0.4374 - accuracy: 0.8016\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 422us/step - loss: 0.8906 - accuracy: 0.7276\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.5648 - accuracy: 0.7529\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.4467 - accuracy: 0.7957\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.4503 - accuracy: 0.7938\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4325 - accuracy: 0.8035\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4450 - accuracy: 0.7938\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 470us/step - loss: 0.4362 - accuracy: 0.7977\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 525us/step - loss: 0.4409 - accuracy: 0.7957\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 574us/step - loss: 0.4526 - accuracy: 0.7743\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 474us/step - loss: 0.4434 - accuracy: 0.7938\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 511us/step - loss: 0.4436 - accuracy: 0.8035\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 545us/step - loss: 0.4649 - accuracy: 0.7685\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 622us/step - loss: 0.4268 - accuracy: 0.7840\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.4333 - accuracy: 0.7996\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 531us/step - loss: 0.4250 - accuracy: 0.7899\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 506us/step - loss: 0.4236 - accuracy: 0.8113\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 514us/step - loss: 0.4250 - accuracy: 0.8054\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4180 - accuracy: 0.8132\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 578us/step - loss: 0.4187 - accuracy: 0.8210\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 517us/step - loss: 0.4431 - accuracy: 0.7763\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 641us/step - loss: 0.4227 - accuracy: 0.7918\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 509us/step - loss: 0.5038 - accuracy: 0.7938\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 521us/step - loss: 0.4124 - accuracy: 0.8074\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 515us/step - loss: 0.4138 - accuracy: 0.8132\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 568us/step - loss: 0.4144 - accuracy: 0.7918\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 607us/step - loss: 0.4164 - accuracy: 0.8035\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 510us/step - loss: 0.4254 - accuracy: 0.7977\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 472us/step - loss: 0.4194 - accuracy: 0.8035\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4289 - accuracy: 0.7879\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.4562 - accuracy: 0.7996\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4445 - accuracy: 0.7802\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.6669 - accuracy: 0.7626\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.5020 - accuracy: 0.7588\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.4438 - accuracy: 0.7821\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 496us/step - loss: 0.4455 - accuracy: 0.7763\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 646us/step - loss: 0.8817 - accuracy: 0.7451\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 540us/step - loss: 0.6260 - accuracy: 0.7471\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.5370 - accuracy: 0.7802\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 496us/step - loss: 0.4634 - accuracy: 0.7957\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 635us/step - loss: 0.4422 - accuracy: 0.7821\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 453us/step - loss: 0.4393 - accuracy: 0.7860\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 529us/step - loss: 0.4409 - accuracy: 0.7977\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 473us/step - loss: 0.4271 - accuracy: 0.8035\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 547us/step - loss: 0.4209 - accuracy: 0.8054\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4182 - accuracy: 0.8035\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.4179 - accuracy: 0.7938\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 864us/step - loss: 0.4205 - accuracy: 0.8054\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 881us/step - loss: 0.4323 - accuracy: 0.7802\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 930us/step - loss: 0.4924 - accuracy: 0.7665\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 904us/step - loss: 0.4266 - accuracy: 0.7957\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 802us/step - loss: 0.4144 - accuracy: 0.8171\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 636us/step - loss: 0.4187 - accuracy: 0.8171\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.7884 - accuracy: 0.7296\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 496us/step - loss: 0.5745 - accuracy: 0.7782\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.4633 - accuracy: 0.7860\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 420us/step - loss: 0.4246 - accuracy: 0.8210\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 647us/step - loss: 0.4258 - accuracy: 0.7938\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4146 - accuracy: 0.7879\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 906us/step - loss: 0.4116 - accuracy: 0.8132\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7782\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 788us/step - loss: 0.4389 - accuracy: 0.7802\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 927us/step - loss: 0.4479 - accuracy: 0.7899\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 973us/step - loss: 0.4176 - accuracy: 0.8016\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8074\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 799us/step - loss: 0.4612 - accuracy: 0.7821\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 785us/step - loss: 0.4862 - accuracy: 0.7549\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 998us/step - loss: 0.4410 - accuracy: 0.7821\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 838us/step - loss: 0.4370 - accuracy: 0.7899\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 711us/step - loss: 0.4202 - accuracy: 0.8093\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 581us/step - loss: 0.4098 - accuracy: 0.8132\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.4288 - accuracy: 0.7879\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 453us/step - loss: 0.4075 - accuracy: 0.8191\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 429us/step - loss: 0.4282 - accuracy: 0.7899\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 415us/step - loss: 0.4251 - accuracy: 0.8054\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.4418 - accuracy: 0.7782\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4485 - accuracy: 0.7918\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4093 - accuracy: 0.8074\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 490us/step - loss: 0.4105 - accuracy: 0.8074\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 423us/step - loss: 0.4448 - accuracy: 0.7840\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 416us/step - loss: 0.4201 - accuracy: 0.8152\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.3980 - accuracy: 0.8132\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4711 - accuracy: 0.7724\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 471us/step - loss: 0.5882 - accuracy: 0.7374\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 480us/step - loss: 0.4888 - accuracy: 0.7899\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 445us/step - loss: 0.4315 - accuracy: 0.7957\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.4204 - accuracy: 0.7996\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.4469 - accuracy: 0.7704\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.5299 - accuracy: 0.7763\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 416us/step - loss: 0.5054 - accuracy: 0.7704\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4605 - accuracy: 0.7646\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4336 - accuracy: 0.7860\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.4085 - accuracy: 0.8152\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.4244 - accuracy: 0.8035\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4279 - accuracy: 0.7938\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 459us/step - loss: 0.5410 - accuracy: 0.7549\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.4767 - accuracy: 0.7743\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 440us/step - loss: 0.5010 - accuracy: 0.7510\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.4409 - accuracy: 0.7840\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4186 - accuracy: 0.8074\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.4021 - accuracy: 0.8171\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 431us/step - loss: 0.4079 - accuracy: 0.8054\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.4166 - accuracy: 0.8035\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 423us/step - loss: 0.4050 - accuracy: 0.8113\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4097 - accuracy: 0.7996\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 825us/step - loss: 0.4045 - accuracy: 0.8268\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 917us/step - loss: 0.4578 - accuracy: 0.7665\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8191\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 749us/step - loss: 0.4051 - accuracy: 0.8152\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 909us/step - loss: 0.4063 - accuracy: 0.8113\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4064 - accuracy: 0.8191\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4067 - accuracy: 0.8113\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.4084 - accuracy: 0.8113\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 525us/step - loss: 0.4039 - accuracy: 0.8035\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 638us/step - loss: 0.4137 - accuracy: 0.7977\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.4330 - accuracy: 0.7899\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 458us/step - loss: 0.4381 - accuracy: 0.7724\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 473us/step - loss: 0.4072 - accuracy: 0.8152\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 517us/step - loss: 0.4032 - accuracy: 0.8054\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.4007 - accuracy: 0.8210\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 544us/step - loss: 0.4028 - accuracy: 0.8016\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 450us/step - loss: 0.4120 - accuracy: 0.7957\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4298 - accuracy: 0.7938\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4071 - accuracy: 0.8132\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.3993 - accuracy: 0.8171\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4101 - accuracy: 0.8210\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4007 - accuracy: 0.8268\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 453us/step - loss: 0.4242 - accuracy: 0.7938\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 499us/step - loss: 0.4195 - accuracy: 0.7957\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 536us/step - loss: 0.4351 - accuracy: 0.8016\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 515us/step - loss: 0.4171 - accuracy: 0.7918\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 437us/step - loss: 0.4103 - accuracy: 0.8132\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 460us/step - loss: 0.4298 - accuracy: 0.7918\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.4435 - accuracy: 0.8132\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 602us/step - loss: 0.4230 - accuracy: 0.7977\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 486us/step - loss: 0.4359 - accuracy: 0.7977\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 440us/step - loss: 0.4387 - accuracy: 0.8152\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 475us/step - loss: 0.4105 - accuracy: 0.8054\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 532us/step - loss: 0.4181 - accuracy: 0.7996\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4209 - accuracy: 0.8035\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 619us/step - loss: 0.4906 - accuracy: 0.7743\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 520us/step - loss: 0.4262 - accuracy: 0.8074\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 600us/step - loss: 0.4191 - accuracy: 0.7977\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 520us/step - loss: 0.4158 - accuracy: 0.8016\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 481us/step - loss: 0.4014 - accuracy: 0.8210\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 470us/step - loss: 0.4049 - accuracy: 0.8113\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.4311 - accuracy: 0.7802\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 562us/step - loss: 0.4193 - accuracy: 0.8113\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 442us/step - loss: 0.4285 - accuracy: 0.8016\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.4062 - accuracy: 0.8152\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.4026 - accuracy: 0.7938\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 316us/step - loss: 0.3937 - accuracy: 0.8191\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.4025 - accuracy: 0.8035\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4102 - accuracy: 0.8054\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4399 - accuracy: 0.7938\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3979 - accuracy: 0.8191\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4015 - accuracy: 0.8035\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 314us/step - loss: 0.3928 - accuracy: 0.8171\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 315us/step - loss: 0.4227 - accuracy: 0.8074\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4304 - accuracy: 0.7996\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4328 - accuracy: 0.7860\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.4034 - accuracy: 0.8054\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.4058 - accuracy: 0.8074\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.4076 - accuracy: 0.8016\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.3962 - accuracy: 0.8210\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.4171 - accuracy: 0.8035\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.4211 - accuracy: 0.8132\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4864 - accuracy: 0.7704\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4498 - accuracy: 0.7879\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.5807 - accuracy: 0.7393\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4897 - accuracy: 0.7490\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4405 - accuracy: 0.7938\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4124 - accuracy: 0.7957\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4042 - accuracy: 0.8035\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4048 - accuracy: 0.8152\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.4135 - accuracy: 0.8035\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.4072 - accuracy: 0.8054\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4214 - accuracy: 0.8054\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3974 - accuracy: 0.8074\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3883 - accuracy: 0.8268\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.3960 - accuracy: 0.7957\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3960 - accuracy: 0.8152\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 421us/step - loss: 0.3918 - accuracy: 0.8288\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3913 - accuracy: 0.8230\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4164 - accuracy: 0.8191\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4021 - accuracy: 0.8074\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3944 - accuracy: 0.8210\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4077 - accuracy: 0.8074\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4180 - accuracy: 0.8054\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.3915 - accuracy: 0.8249\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4035 - accuracy: 0.7938\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4068 - accuracy: 0.8035\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 315us/step - loss: 0.3889 - accuracy: 0.8288\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4086 - accuracy: 0.8191\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3997 - accuracy: 0.8171\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.4078 - accuracy: 0.8152\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4123 - accuracy: 0.8113\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4597 - accuracy: 0.7782\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 318us/step - loss: 0.4358 - accuracy: 0.7743\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.4375 - accuracy: 0.7899\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 315us/step - loss: 0.3949 - accuracy: 0.8152\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3925 - accuracy: 0.8230\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.5028 - accuracy: 0.7607\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4148 - accuracy: 0.7899\n",
      "17/17 [==============================] - 0s 310us/step - loss: 0.4016 - accuracy: 0.8035\n",
      "8/8 [==============================] - 0s 374us/step - loss: 0.9862 - accuracy: 0.7165\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4055 - accuracy: 0.8191\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 424us/step - loss: 0.4130 - accuracy: 0.8093\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4049 - accuracy: 0.8113\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4768 - accuracy: 0.7802\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4087 - accuracy: 0.8152\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4011 - accuracy: 0.8171\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4088 - accuracy: 0.7996\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4459 - accuracy: 0.7763\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.4060 - accuracy: 0.8249\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4527 - accuracy: 0.7685\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.4128 - accuracy: 0.8132\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4356 - accuracy: 0.7996\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.3993 - accuracy: 0.8249\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4643 - accuracy: 0.7860\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 416us/step - loss: 0.4009 - accuracy: 0.8230\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3951 - accuracy: 0.8288\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4186 - accuracy: 0.8035\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4030 - accuracy: 0.8210\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4010 - accuracy: 0.8171\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3932 - accuracy: 0.8152\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3857 - accuracy: 0.8327\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.4028 - accuracy: 0.8191\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3869 - accuracy: 0.8249\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3989 - accuracy: 0.8132\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4926 - accuracy: 0.7996\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4312 - accuracy: 0.8093\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3985 - accuracy: 0.8288\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.4074 - accuracy: 0.8132\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4147 - accuracy: 0.8016\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4020 - accuracy: 0.8268\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3951 - accuracy: 0.8230\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4141 - accuracy: 0.8074\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.4079 - accuracy: 0.8132\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 482us/step - loss: 0.4305 - accuracy: 0.7782\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.4046 - accuracy: 0.8035\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3980 - accuracy: 0.8016\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3934 - accuracy: 0.8171\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4019 - accuracy: 0.8230\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4013 - accuracy: 0.8074\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4285 - accuracy: 0.7918\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3853 - accuracy: 0.8327\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.3884 - accuracy: 0.8346\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3973 - accuracy: 0.8230\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.3908 - accuracy: 0.8132\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.5110 - accuracy: 0.7665\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4200 - accuracy: 0.8054\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4022 - accuracy: 0.8113\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 458us/step - loss: 0.3996 - accuracy: 0.8268\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4377 - accuracy: 0.7996\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.5614 - accuracy: 0.7704\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4900 - accuracy: 0.7510\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4627 - accuracy: 0.7607\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4216 - accuracy: 0.7957\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4083 - accuracy: 0.7977\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 421us/step - loss: 0.3964 - accuracy: 0.8171\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4250 - accuracy: 0.8132\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4161 - accuracy: 0.7782\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3956 - accuracy: 0.8327\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3842 - accuracy: 0.8346\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3921 - accuracy: 0.8249\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3982 - accuracy: 0.8288\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3966 - accuracy: 0.8132\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4097 - accuracy: 0.7957\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3967 - accuracy: 0.8230\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4007 - accuracy: 0.7957\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4317 - accuracy: 0.8035\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4997 - accuracy: 0.7607\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.4483 - accuracy: 0.8054\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4251 - accuracy: 0.8016\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4002 - accuracy: 0.8171\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3989 - accuracy: 0.8346\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.4076 - accuracy: 0.8016\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4052 - accuracy: 0.8074\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3884 - accuracy: 0.8327\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3944 - accuracy: 0.8268\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4088 - accuracy: 0.8113\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.4019 - accuracy: 0.8132\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3931 - accuracy: 0.8327\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.4168 - accuracy: 0.8249\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4664 - accuracy: 0.7763\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.4192 - accuracy: 0.8035\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4051 - accuracy: 0.8191\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3908 - accuracy: 0.8405\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4121 - accuracy: 0.8132\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4001 - accuracy: 0.8113\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.4096 - accuracy: 0.7957\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4333 - accuracy: 0.7899\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.3983 - accuracy: 0.8191\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3999 - accuracy: 0.8230\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3913 - accuracy: 0.8288\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.4405 - accuracy: 0.7957\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4017 - accuracy: 0.7918\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.3939 - accuracy: 0.8249\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3860 - accuracy: 0.8366\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.3928 - accuracy: 0.8230\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4190 - accuracy: 0.7938\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3918 - accuracy: 0.8191\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4485 - accuracy: 0.7840\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.5227 - accuracy: 0.7568\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4333 - accuracy: 0.7938\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4203 - accuracy: 0.7879\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 427us/step - loss: 0.4175 - accuracy: 0.7860\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4250 - accuracy: 0.8054\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4217 - accuracy: 0.7840\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4378 - accuracy: 0.7996\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.4029 - accuracy: 0.8268\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4387 - accuracy: 0.7840\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4044 - accuracy: 0.8171\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.4153 - accuracy: 0.7938\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4101 - accuracy: 0.8113\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4097 - accuracy: 0.7938\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4222 - accuracy: 0.7977\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.4010 - accuracy: 0.8152\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4265 - accuracy: 0.7957\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.4165 - accuracy: 0.7938\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3970 - accuracy: 0.8152\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3979 - accuracy: 0.8093\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4241 - accuracy: 0.7860\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3946 - accuracy: 0.8230\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.4200 - accuracy: 0.7977\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3949 - accuracy: 0.8191\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3889 - accuracy: 0.8268\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3929 - accuracy: 0.8016\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3900 - accuracy: 0.8249\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.3971 - accuracy: 0.8132\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.3880 - accuracy: 0.8366\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3838 - accuracy: 0.8210\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4149 - accuracy: 0.8016\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.4415 - accuracy: 0.7879\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4073 - accuracy: 0.7938\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.4201 - accuracy: 0.8035\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4372 - accuracy: 0.7957\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.4727 - accuracy: 0.7743\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4181 - accuracy: 0.7840\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4038 - accuracy: 0.8035\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 405us/step - loss: 0.3958 - accuracy: 0.8210\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4072 - accuracy: 0.7977\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.4108 - accuracy: 0.8016\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4041 - accuracy: 0.8016\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.4782 - accuracy: 0.8074\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.6088 - accuracy: 0.7510\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.5106 - accuracy: 0.7724\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.4308 - accuracy: 0.7996\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.4724 - accuracy: 0.7685\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4480 - accuracy: 0.7938\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 317us/step - loss: 0.4197 - accuracy: 0.7802\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4081 - accuracy: 0.8093\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.3986 - accuracy: 0.8288\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3915 - accuracy: 0.8230\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.4029 - accuracy: 0.8093\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.4014 - accuracy: 0.8210\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4383 - accuracy: 0.7899\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3940 - accuracy: 0.8288\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3875 - accuracy: 0.8249\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4017 - accuracy: 0.8093\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3940 - accuracy: 0.8132\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.3910 - accuracy: 0.8249\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3867 - accuracy: 0.8327\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3936 - accuracy: 0.8132\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3941 - accuracy: 0.8093\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4347 - accuracy: 0.7996\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4991 - accuracy: 0.7626\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4415 - accuracy: 0.8054\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 413us/step - loss: 0.4129 - accuracy: 0.8074\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4431 - accuracy: 0.7840\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4126 - accuracy: 0.8074\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4131 - accuracy: 0.8307\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4068 - accuracy: 0.8035\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4949 - accuracy: 0.7802\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.4441 - accuracy: 0.7918\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4096 - accuracy: 0.8054\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4460 - accuracy: 0.8016\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4291 - accuracy: 0.8016\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4532 - accuracy: 0.7724\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4109 - accuracy: 0.8093\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4016 - accuracy: 0.8074\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4076 - accuracy: 0.7977\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.3915 - accuracy: 0.8230\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3911 - accuracy: 0.8249\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 315us/step - loss: 0.3898 - accuracy: 0.8268\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.4028 - accuracy: 0.8016\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 535us/step - loss: 0.4117 - accuracy: 0.8093\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 524us/step - loss: 0.3906 - accuracy: 0.8171\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 585us/step - loss: 0.4286 - accuracy: 0.7957\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 416us/step - loss: 0.4062 - accuracy: 0.8113\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.4179 - accuracy: 0.8035\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.4039 - accuracy: 0.8171\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 509us/step - loss: 0.6185 - accuracy: 0.7743\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 650us/step - loss: 0.8446 - accuracy: 0.7218\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 609us/step - loss: 0.5412 - accuracy: 0.7665\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.4447 - accuracy: 0.7957\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 506us/step - loss: 0.7304 - accuracy: 0.7510\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7374\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 525us/step - loss: 0.4613 - accuracy: 0.7821\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 475us/step - loss: 0.4340 - accuracy: 0.7977\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 582us/step - loss: 0.4417 - accuracy: 0.7899\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 522us/step - loss: 0.4255 - accuracy: 0.7996\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 456us/step - loss: 0.4193 - accuracy: 0.8016\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.4086 - accuracy: 0.8132\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.4017 - accuracy: 0.8327\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 551us/step - loss: 0.4101 - accuracy: 0.8171\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 777us/step - loss: 0.4030 - accuracy: 0.7977\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 451us/step - loss: 0.4075 - accuracy: 0.8132\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4033 - accuracy: 0.8210\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4004 - accuracy: 0.8249\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.4126 - accuracy: 0.8132\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 402us/step - loss: 0.4040 - accuracy: 0.8093\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4324 - accuracy: 0.7957\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4262 - accuracy: 0.8093\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4103 - accuracy: 0.8113\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4005 - accuracy: 0.8210\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4135 - accuracy: 0.7938\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 370us/step - loss: 0.4522 - accuracy: 0.7860\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.5634 - accuracy: 0.7451\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4758 - accuracy: 0.7821\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4417 - accuracy: 0.7802\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4051 - accuracy: 0.8035\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.3997 - accuracy: 0.8210\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3961 - accuracy: 0.8113\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.3981 - accuracy: 0.7879\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3871 - accuracy: 0.8230\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3924 - accuracy: 0.8074\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3897 - accuracy: 0.8191\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.4448 - accuracy: 0.7626\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4003 - accuracy: 0.8132\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.4009 - accuracy: 0.8054\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 410us/step - loss: 0.4123 - accuracy: 0.8035\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4621 - accuracy: 0.7626\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4788 - accuracy: 0.7704\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.4222 - accuracy: 0.7957\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4681 - accuracy: 0.7918\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.4711 - accuracy: 0.7568\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4635 - accuracy: 0.7607\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.4344 - accuracy: 0.7977\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.4114 - accuracy: 0.8035\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3929 - accuracy: 0.8171\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3875 - accuracy: 0.8152\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3983 - accuracy: 0.8307\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3881 - accuracy: 0.8191\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3846 - accuracy: 0.8307\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 411us/step - loss: 0.4051 - accuracy: 0.8152\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4177 - accuracy: 0.8016\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.4319 - accuracy: 0.8035\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4111 - accuracy: 0.7840\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3952 - accuracy: 0.8113\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4049 - accuracy: 0.8093\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.4110 - accuracy: 0.8113\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.4102 - accuracy: 0.8268\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3982 - accuracy: 0.7977\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3984 - accuracy: 0.8132\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.4190 - accuracy: 0.8132\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.4039 - accuracy: 0.7977\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4195 - accuracy: 0.8093\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 439us/step - loss: 0.4087 - accuracy: 0.7899\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 437us/step - loss: 0.3941 - accuracy: 0.8268\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3946 - accuracy: 0.8054\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.4123 - accuracy: 0.8054\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3861 - accuracy: 0.8230\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3840 - accuracy: 0.8307\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.5357 - accuracy: 0.7685\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4313 - accuracy: 0.7918\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.4496 - accuracy: 0.7607\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3831 - accuracy: 0.8307\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.4405 - accuracy: 0.8113\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4104 - accuracy: 0.7996\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.4599 - accuracy: 0.7607\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4457 - accuracy: 0.7743\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4150 - accuracy: 0.8074\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 415us/step - loss: 0.3905 - accuracy: 0.8346\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3835 - accuracy: 0.8268\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3869 - accuracy: 0.8288\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4079 - accuracy: 0.7802\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3895 - accuracy: 0.8132\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3847 - accuracy: 0.8230\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3782 - accuracy: 0.8152\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.3793 - accuracy: 0.8385\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3862 - accuracy: 0.8424\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3784 - accuracy: 0.8210\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4069 - accuracy: 0.8152\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3920 - accuracy: 0.8171\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3918 - accuracy: 0.8152\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 458us/step - loss: 0.3872 - accuracy: 0.8113\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.4154 - accuracy: 0.7879\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4579 - accuracy: 0.7879\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3995 - accuracy: 0.7918\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4053 - accuracy: 0.7996\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.3813 - accuracy: 0.8268\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.4416 - accuracy: 0.7957\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4525 - accuracy: 0.7665\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.4122 - accuracy: 0.8152\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3967 - accuracy: 0.8171\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4005 - accuracy: 0.8074\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3866 - accuracy: 0.8268\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3969 - accuracy: 0.8054\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.3919 - accuracy: 0.8113\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3906 - accuracy: 0.8210\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 411us/step - loss: 0.3868 - accuracy: 0.8191\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3808 - accuracy: 0.8307\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3819 - accuracy: 0.8132\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 317us/step - loss: 0.3785 - accuracy: 0.8385\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3671 - accuracy: 0.8385\n",
      "8/8 [==============================] - 0s 365us/step - loss: 0.9926 - accuracy: 0.7087\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.3811 - accuracy: 0.8230\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.4685 - accuracy: 0.7918\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4888 - accuracy: 0.7646\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4217 - accuracy: 0.8035\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4193 - accuracy: 0.7977\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3876 - accuracy: 0.8191\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.4199 - accuracy: 0.8074\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3973 - accuracy: 0.8171\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3845 - accuracy: 0.8191\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.4047 - accuracy: 0.8152\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4444 - accuracy: 0.7840\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3919 - accuracy: 0.8132\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4986 - accuracy: 0.7704\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 400us/step - loss: 0.4100 - accuracy: 0.8074\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4016 - accuracy: 0.8035\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4141 - accuracy: 0.8152\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3963 - accuracy: 0.8210\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3841 - accuracy: 0.8210\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3807 - accuracy: 0.8327\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3806 - accuracy: 0.8346\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.3784 - accuracy: 0.8288\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3827 - accuracy: 0.8288\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3734 - accuracy: 0.8249\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3858 - accuracy: 0.8268\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3950 - accuracy: 0.8152\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3920 - accuracy: 0.8268\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3803 - accuracy: 0.8327\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 413us/step - loss: 0.3783 - accuracy: 0.8268\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3844 - accuracy: 0.8152\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3779 - accuracy: 0.8366\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3805 - accuracy: 0.8249\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4034 - accuracy: 0.8054\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.5265 - accuracy: 0.7510\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4324 - accuracy: 0.7977\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.4234 - accuracy: 0.8113\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4048 - accuracy: 0.8035\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.5089 - accuracy: 0.7451\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4035 - accuracy: 0.8074\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.4185 - accuracy: 0.7743\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3829 - accuracy: 0.8230\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3764 - accuracy: 0.8463\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.4152 - accuracy: 0.7821\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4369 - accuracy: 0.7879\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4055 - accuracy: 0.8113\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3803 - accuracy: 0.8327\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3867 - accuracy: 0.8210\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3879 - accuracy: 0.8230\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3803 - accuracy: 0.8152\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3898 - accuracy: 0.8132\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 363us/step - loss: 0.3860 - accuracy: 0.8249\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3950 - accuracy: 0.8191\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.4047 - accuracy: 0.8093\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3947 - accuracy: 0.8249\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3819 - accuracy: 0.8152\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3811 - accuracy: 0.8171\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 423us/step - loss: 0.3873 - accuracy: 0.8210\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 359us/step - loss: 0.4075 - accuracy: 0.8113\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3868 - accuracy: 0.8074\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4345 - accuracy: 0.7899\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4180 - accuracy: 0.7918\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3939 - accuracy: 0.8249\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.5097 - accuracy: 0.7549\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.4009 - accuracy: 0.8191\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3901 - accuracy: 0.8249\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3878 - accuracy: 0.8230\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3751 - accuracy: 0.8288\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3878 - accuracy: 0.8307\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3966 - accuracy: 0.8191\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4175 - accuracy: 0.7782\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 419us/step - loss: 0.4446 - accuracy: 0.7996\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4488 - accuracy: 0.7763\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3969 - accuracy: 0.8210\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3795 - accuracy: 0.8327\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3879 - accuracy: 0.8152\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3852 - accuracy: 0.8210\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3733 - accuracy: 0.8424\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 406us/step - loss: 0.3717 - accuracy: 0.8405\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3787 - accuracy: 0.8230\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3879 - accuracy: 0.8268\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3912 - accuracy: 0.8113\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3818 - accuracy: 0.8307\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.3793 - accuracy: 0.8327\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3753 - accuracy: 0.8463\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4065 - accuracy: 0.8113\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3934 - accuracy: 0.8113\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4278 - accuracy: 0.7918\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4072 - accuracy: 0.7996\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3865 - accuracy: 0.8230\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.4064 - accuracy: 0.8210\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3902 - accuracy: 0.8152\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.4280 - accuracy: 0.7977\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3920 - accuracy: 0.8366\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3895 - accuracy: 0.8093\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3815 - accuracy: 0.8288\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3727 - accuracy: 0.8463\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4170 - accuracy: 0.7996\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.7206 - accuracy: 0.7646\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 1.4069 - accuracy: 0.6751\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 1.3310 - accuracy: 0.7315\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 1.0467 - accuracy: 0.7588\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.8877 - accuracy: 0.7549\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.7660 - accuracy: 0.7957\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.6756 - accuracy: 0.8016\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.6304 - accuracy: 0.7743\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 405us/step - loss: 0.5732 - accuracy: 0.7724\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.4995 - accuracy: 0.7724\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.4514 - accuracy: 0.7977\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4254 - accuracy: 0.8016\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.4444 - accuracy: 0.7957\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4272 - accuracy: 0.7821\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.4207 - accuracy: 0.7957\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.4071 - accuracy: 0.8210\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4080 - accuracy: 0.8132\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 377us/step - loss: 0.4003 - accuracy: 0.8249\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4052 - accuracy: 0.8016\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3999 - accuracy: 0.8191\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.3964 - accuracy: 0.8152\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3910 - accuracy: 0.8249\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.4100 - accuracy: 0.8152\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.4131 - accuracy: 0.8074\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3938 - accuracy: 0.8054\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3938 - accuracy: 0.8152\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3958 - accuracy: 0.8113\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3917 - accuracy: 0.8210\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4241 - accuracy: 0.7899\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3912 - accuracy: 0.8191\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3911 - accuracy: 0.8093\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3819 - accuracy: 0.8268\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3932 - accuracy: 0.8113\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3973 - accuracy: 0.8113\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3958 - accuracy: 0.8074\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3888 - accuracy: 0.8191\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.4062 - accuracy: 0.8113\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.3899 - accuracy: 0.8230\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3895 - accuracy: 0.8074\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3768 - accuracy: 0.8424\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.4233 - accuracy: 0.7957\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3916 - accuracy: 0.8054\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.3782 - accuracy: 0.8288\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.4241 - accuracy: 0.7977\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3977 - accuracy: 0.8035\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4047 - accuracy: 0.8210\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4314 - accuracy: 0.7899\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4230 - accuracy: 0.7996\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3763 - accuracy: 0.8230\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3807 - accuracy: 0.8210\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 411us/step - loss: 0.3996 - accuracy: 0.8171\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3814 - accuracy: 0.8288\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3882 - accuracy: 0.8132\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3779 - accuracy: 0.8210\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.5204 - accuracy: 0.7704\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.4419 - accuracy: 0.8054\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.4418 - accuracy: 0.7957\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 395us/step - loss: 0.3903 - accuracy: 0.8113\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3726 - accuracy: 0.8288\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 356us/step - loss: 0.4228 - accuracy: 0.7899\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4097 - accuracy: 0.8054\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4022 - accuracy: 0.8035\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3978 - accuracy: 0.8113\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3821 - accuracy: 0.8288\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 417us/step - loss: 0.3737 - accuracy: 0.8249\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.4430 - accuracy: 0.8171\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3959 - accuracy: 0.8074\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4028 - accuracy: 0.8035\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 320us/step - loss: 0.4050 - accuracy: 0.8210\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.4449 - accuracy: 0.7821\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4572 - accuracy: 0.7685\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.4235 - accuracy: 0.7879\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3864 - accuracy: 0.8249\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4002 - accuracy: 0.8093\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3724 - accuracy: 0.8288\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3826 - accuracy: 0.8249\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 314us/step - loss: 0.3890 - accuracy: 0.8191\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4062 - accuracy: 0.8152\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3754 - accuracy: 0.8424\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3791 - accuracy: 0.8366\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3691 - accuracy: 0.8230\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4076 - accuracy: 0.8035\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.3917 - accuracy: 0.8288\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3697 - accuracy: 0.8288\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3760 - accuracy: 0.8288\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.3897 - accuracy: 0.8054\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4075 - accuracy: 0.7957\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3685 - accuracy: 0.8307\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3760 - accuracy: 0.8385\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3668 - accuracy: 0.8346\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3679 - accuracy: 0.8268\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4279 - accuracy: 0.7957\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3940 - accuracy: 0.8268\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3833 - accuracy: 0.8327\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3711 - accuracy: 0.8327\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3950 - accuracy: 0.8074\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.3702 - accuracy: 0.8424\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.3698 - accuracy: 0.8307\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3646 - accuracy: 0.8230\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 372us/step - loss: 0.3757 - accuracy: 0.8152\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3688 - accuracy: 0.8346\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3809 - accuracy: 0.8093\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3850 - accuracy: 0.8307\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 543us/step - loss: 0.3839 - accuracy: 0.8268\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 518us/step - loss: 0.3662 - accuracy: 0.8249\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 622us/step - loss: 0.3846 - accuracy: 0.8288\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 459us/step - loss: 0.3715 - accuracy: 0.8191\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 463us/step - loss: 0.3646 - accuracy: 0.8288\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 468us/step - loss: 0.3637 - accuracy: 0.8327\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 530us/step - loss: 0.3729 - accuracy: 0.8366\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 549us/step - loss: 0.4272 - accuracy: 0.7899\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 575us/step - loss: 0.3944 - accuracy: 0.8113\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 536us/step - loss: 0.3661 - accuracy: 0.8327\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.3695 - accuracy: 0.8327\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 558us/step - loss: 0.3674 - accuracy: 0.8327\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3807 - accuracy: 0.8171\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 623us/step - loss: 0.3678 - accuracy: 0.8463\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 505us/step - loss: 0.3739 - accuracy: 0.8171\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 491us/step - loss: 0.3879 - accuracy: 0.8385\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.3756 - accuracy: 0.8132\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 504us/step - loss: 0.3693 - accuracy: 0.8405\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 576us/step - loss: 0.3802 - accuracy: 0.8132\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 524us/step - loss: 0.3679 - accuracy: 0.8405\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 480us/step - loss: 0.4023 - accuracy: 0.8113\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 458us/step - loss: 0.4045 - accuracy: 0.8074\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 466us/step - loss: 0.3941 - accuracy: 0.8132\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 412us/step - loss: 0.3835 - accuracy: 0.8035\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3651 - accuracy: 0.8268\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.4521 - accuracy: 0.7977\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3962 - accuracy: 0.8113\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.3795 - accuracy: 0.8307\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 316us/step - loss: 0.3779 - accuracy: 0.8288\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3953 - accuracy: 0.8093\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3853 - accuracy: 0.8366\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3693 - accuracy: 0.8405\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 371us/step - loss: 0.3628 - accuracy: 0.8424\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3729 - accuracy: 0.8405\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3707 - accuracy: 0.8444\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3633 - accuracy: 0.8268\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3675 - accuracy: 0.8288\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3637 - accuracy: 0.8346\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3629 - accuracy: 0.8385\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.4640 - accuracy: 0.8016\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.4538 - accuracy: 0.7918\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.4087 - accuracy: 0.8191\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3870 - accuracy: 0.8171\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3958 - accuracy: 0.8249\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.3812 - accuracy: 0.8307\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3918 - accuracy: 0.8132\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3854 - accuracy: 0.8249\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3766 - accuracy: 0.8249\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3737 - accuracy: 0.8171\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3777 - accuracy: 0.8288\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3699 - accuracy: 0.8268\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3824 - accuracy: 0.8171\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.3849 - accuracy: 0.8210\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3792 - accuracy: 0.8191\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3660 - accuracy: 0.8424\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3768 - accuracy: 0.8171\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3699 - accuracy: 0.8346\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3695 - accuracy: 0.8327\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.3678 - accuracy: 0.8210\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3581 - accuracy: 0.8424\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3681 - accuracy: 0.8327\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3672 - accuracy: 0.8366\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3813 - accuracy: 0.8152\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3770 - accuracy: 0.8054\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3777 - accuracy: 0.8268\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3716 - accuracy: 0.8288\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3694 - accuracy: 0.8268\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3953 - accuracy: 0.8113\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3812 - accuracy: 0.8230\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3799 - accuracy: 0.8230\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3882 - accuracy: 0.8268\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3806 - accuracy: 0.8132\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3591 - accuracy: 0.8307\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.4592 - accuracy: 0.7996\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4535 - accuracy: 0.7957\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4419 - accuracy: 0.7938\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 586us/step - loss: 0.3690 - accuracy: 0.8424\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 502us/step - loss: 0.3719 - accuracy: 0.8366\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 602us/step - loss: 0.3655 - accuracy: 0.8366\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 473us/step - loss: 0.4039 - accuracy: 0.8307\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 526us/step - loss: 0.4236 - accuracy: 0.7977\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 514us/step - loss: 0.4032 - accuracy: 0.8113\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 496us/step - loss: 0.3775 - accuracy: 0.8230\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 599us/step - loss: 0.3731 - accuracy: 0.8191\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 462us/step - loss: 0.3753 - accuracy: 0.8288\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 420us/step - loss: 0.3638 - accuracy: 0.8444\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 475us/step - loss: 0.3643 - accuracy: 0.8366\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 494us/step - loss: 0.3590 - accuracy: 0.8268\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8288\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 524us/step - loss: 0.3776 - accuracy: 0.8132\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 450us/step - loss: 0.4129 - accuracy: 0.7899\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.3611 - accuracy: 0.8482\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 454us/step - loss: 0.3636 - accuracy: 0.8385\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 675us/step - loss: 0.4350 - accuracy: 0.7860\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 836us/step - loss: 0.3781 - accuracy: 0.8132\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 948us/step - loss: 0.3920 - accuracy: 0.8171\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 837us/step - loss: 0.3648 - accuracy: 0.8327\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 481us/step - loss: 0.3691 - accuracy: 0.8307\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 422us/step - loss: 0.3703 - accuracy: 0.8249\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.3811 - accuracy: 0.8210\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3862 - accuracy: 0.8230\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3743 - accuracy: 0.8327\n",
      "8/8 [==============================] - 0s 398us/step - loss: 1.0765 - accuracy: 0.7283\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.4758 - accuracy: 0.7860\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 447us/step - loss: 0.4118 - accuracy: 0.8132\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3801 - accuracy: 0.8307\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3837 - accuracy: 0.8152\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3757 - accuracy: 0.8268\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3809 - accuracy: 0.8268\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 533us/step - loss: 0.3767 - accuracy: 0.8346\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3663 - accuracy: 0.8249\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 414us/step - loss: 0.3594 - accuracy: 0.8405\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 943us/step - loss: 0.3673 - accuracy: 0.8521\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 979us/step - loss: 0.3762 - accuracy: 0.8268\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 806us/step - loss: 0.3768 - accuracy: 0.8230\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 990us/step - loss: 0.3696 - accuracy: 0.8327\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 876us/step - loss: 0.3645 - accuracy: 0.8424\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 859us/step - loss: 0.3811 - accuracy: 0.8054\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8268\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8230\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 665us/step - loss: 0.3721 - accuracy: 0.8444\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8249\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 866us/step - loss: 0.3568 - accuracy: 0.8424\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 707us/step - loss: 0.4266 - accuracy: 0.7957\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 964us/step - loss: 0.4073 - accuracy: 0.8074\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 469us/step - loss: 0.4108 - accuracy: 0.8230\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 466us/step - loss: 0.3736 - accuracy: 0.8366\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3685 - accuracy: 0.8268\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.3662 - accuracy: 0.8288\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3701 - accuracy: 0.8405\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 989us/step - loss: 0.3658 - accuracy: 0.8385\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 894us/step - loss: 0.3771 - accuracy: 0.8385\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 593us/step - loss: 0.3749 - accuracy: 0.8113\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 880us/step - loss: 0.3755 - accuracy: 0.7977\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8346\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 684us/step - loss: 0.3800 - accuracy: 0.8230\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 934us/step - loss: 0.4134 - accuracy: 0.8093\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.8210\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 801us/step - loss: 0.3595 - accuracy: 0.8444\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3725 - accuracy: 0.8288\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3715 - accuracy: 0.8385\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 703us/step - loss: 0.3924 - accuracy: 0.8074\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 619us/step - loss: 0.3791 - accuracy: 0.8230\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.3761 - accuracy: 0.8113\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.3709 - accuracy: 0.8268\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3705 - accuracy: 0.8307\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3736 - accuracy: 0.8288\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.3832 - accuracy: 0.8113\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3957 - accuracy: 0.8191\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 526us/step - loss: 0.3805 - accuracy: 0.8171\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 538us/step - loss: 0.4237 - accuracy: 0.8035\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 549us/step - loss: 0.4191 - accuracy: 0.8113\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 512us/step - loss: 0.3809 - accuracy: 0.8210\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 466us/step - loss: 0.3757 - accuracy: 0.8210\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 482us/step - loss: 0.3686 - accuracy: 0.8249\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 481us/step - loss: 0.3771 - accuracy: 0.8230\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.4072 - accuracy: 0.8113\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 623us/step - loss: 0.3785 - accuracy: 0.8132\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 451us/step - loss: 0.3606 - accuracy: 0.8307\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 482us/step - loss: 0.3733 - accuracy: 0.8288\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.3824 - accuracy: 0.8210\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3585 - accuracy: 0.8385\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 610us/step - loss: 0.3731 - accuracy: 0.8366\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 554us/step - loss: 0.3661 - accuracy: 0.8268\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 523us/step - loss: 0.3606 - accuracy: 0.8424\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 509us/step - loss: 0.3685 - accuracy: 0.8288\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 513us/step - loss: 0.3674 - accuracy: 0.8288\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 664us/step - loss: 0.3582 - accuracy: 0.8385\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 558us/step - loss: 0.3873 - accuracy: 0.8054\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 502us/step - loss: 0.4006 - accuracy: 0.8152\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.4056 - accuracy: 0.8016\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 469us/step - loss: 0.3673 - accuracy: 0.8288\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3993 - accuracy: 0.8113\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.4364 - accuracy: 0.7743\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4077 - accuracy: 0.8230\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.3836 - accuracy: 0.8249\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 479us/step - loss: 0.4438 - accuracy: 0.8035\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 904us/step - loss: 0.6022 - accuracy: 0.7432\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 642us/step - loss: 0.4221 - accuracy: 0.7782\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 535us/step - loss: 0.3855 - accuracy: 0.8016\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 519us/step - loss: 0.3744 - accuracy: 0.8346\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.3888 - accuracy: 0.8171\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 504us/step - loss: 0.3725 - accuracy: 0.8016\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 590us/step - loss: 0.4166 - accuracy: 0.8035\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 483us/step - loss: 0.3810 - accuracy: 0.8152\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 528us/step - loss: 0.4054 - accuracy: 0.8035\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 487us/step - loss: 0.3879 - accuracy: 0.7957\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7763\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 522us/step - loss: 0.4396 - accuracy: 0.7724\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 541us/step - loss: 0.4123 - accuracy: 0.7977\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 458us/step - loss: 0.5580 - accuracy: 0.7782\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.4587 - accuracy: 0.7840\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 513us/step - loss: 0.4089 - accuracy: 0.8288\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.3878 - accuracy: 0.8171\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 551us/step - loss: 0.3859 - accuracy: 0.8268\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 438us/step - loss: 0.4086 - accuracy: 0.8074\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.3960 - accuracy: 0.8171\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 685us/step - loss: 0.3820 - accuracy: 0.8307\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 490us/step - loss: 0.3813 - accuracy: 0.8171\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3999 - accuracy: 0.7977\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.3838 - accuracy: 0.8307\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3737 - accuracy: 0.8307\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3800 - accuracy: 0.8171\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 576us/step - loss: 0.3782 - accuracy: 0.8307\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 516us/step - loss: 0.3692 - accuracy: 0.8346\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 600us/step - loss: 0.3915 - accuracy: 0.8074\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 563us/step - loss: 0.4021 - accuracy: 0.7977\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3931 - accuracy: 0.8191\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 561us/step - loss: 0.3658 - accuracy: 0.8327\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 666us/step - loss: 0.3995 - accuracy: 0.8054\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 463us/step - loss: 0.3769 - accuracy: 0.8191\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 579us/step - loss: 0.4824 - accuracy: 0.7782\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 500us/step - loss: 0.3961 - accuracy: 0.8230\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8327\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 610us/step - loss: 0.3810 - accuracy: 0.8210\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 515us/step - loss: 0.4437 - accuracy: 0.8016\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 398us/step - loss: 0.3889 - accuracy: 0.8074\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 496us/step - loss: 0.3904 - accuracy: 0.8132\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 522us/step - loss: 0.3746 - accuracy: 0.8074\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3685 - accuracy: 0.8385\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 537us/step - loss: 0.3753 - accuracy: 0.8268\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.3753 - accuracy: 0.8405\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 448us/step - loss: 0.3729 - accuracy: 0.8268\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 491us/step - loss: 0.3735 - accuracy: 0.8210\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 494us/step - loss: 0.3802 - accuracy: 0.8346\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3784 - accuracy: 0.8288\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3749 - accuracy: 0.8113\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3710 - accuracy: 0.8327\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 562us/step - loss: 0.3821 - accuracy: 0.8113\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 500us/step - loss: 0.4087 - accuracy: 0.8035\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 549us/step - loss: 0.3868 - accuracy: 0.8016\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 518us/step - loss: 0.3674 - accuracy: 0.8366\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 507us/step - loss: 0.4206 - accuracy: 0.7957\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 486us/step - loss: 0.3952 - accuracy: 0.8093\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 483us/step - loss: 0.5310 - accuracy: 0.7860\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 574us/step - loss: 0.3992 - accuracy: 0.7977\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 502us/step - loss: 0.4025 - accuracy: 0.8035\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 586us/step - loss: 0.3795 - accuracy: 0.8249\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 473us/step - loss: 0.3690 - accuracy: 0.8444\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.3590 - accuracy: 0.8385\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3666 - accuracy: 0.8230\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 603us/step - loss: 0.3641 - accuracy: 0.8346\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 506us/step - loss: 0.3654 - accuracy: 0.8288\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 510us/step - loss: 0.3628 - accuracy: 0.8268\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 514us/step - loss: 0.3633 - accuracy: 0.8463\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 456us/step - loss: 0.3846 - accuracy: 0.8249\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 591us/step - loss: 0.3829 - accuracy: 0.8113\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.3963 - accuracy: 0.8210\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 466us/step - loss: 0.3989 - accuracy: 0.8152\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 499us/step - loss: 0.4716 - accuracy: 0.7704\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 475us/step - loss: 0.3971 - accuracy: 0.8268\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3850 - accuracy: 0.8171\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 431us/step - loss: 0.3728 - accuracy: 0.8113\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3761 - accuracy: 0.8230\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.4046 - accuracy: 0.8268\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.4022 - accuracy: 0.8132\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 544us/step - loss: 0.4310 - accuracy: 0.7860\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 490us/step - loss: 0.4215 - accuracy: 0.7996\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 596us/step - loss: 0.3750 - accuracy: 0.8249\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 502us/step - loss: 0.3825 - accuracy: 0.8268\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.3874 - accuracy: 0.8230\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 510us/step - loss: 0.3784 - accuracy: 0.8230\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 502us/step - loss: 0.3737 - accuracy: 0.8366\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 571us/step - loss: 0.3777 - accuracy: 0.8035\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 499us/step - loss: 0.3596 - accuracy: 0.8327\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 487us/step - loss: 0.3740 - accuracy: 0.8346\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 505us/step - loss: 0.3713 - accuracy: 0.8230\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 574us/step - loss: 0.3632 - accuracy: 0.8268\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3822 - accuracy: 0.8210\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 602us/step - loss: 0.3645 - accuracy: 0.8463\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.3691 - accuracy: 0.8132\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.3895 - accuracy: 0.8346\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 502us/step - loss: 0.3632 - accuracy: 0.8307\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 508us/step - loss: 0.4879 - accuracy: 0.7743\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 529us/step - loss: 0.3843 - accuracy: 0.8230\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 568us/step - loss: 0.3793 - accuracy: 0.8132\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 444us/step - loss: 0.8195 - accuracy: 0.7879\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 523us/step - loss: 0.4771 - accuracy: 0.7821\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.4348 - accuracy: 0.7821\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3970 - accuracy: 0.8288\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.4784 - accuracy: 0.7957\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.4670 - accuracy: 0.7821\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4113 - accuracy: 0.8035\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4084 - accuracy: 0.8035\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 520us/step - loss: 0.3868 - accuracy: 0.8230\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 511us/step - loss: 0.3824 - accuracy: 0.8132\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 526us/step - loss: 0.4662 - accuracy: 0.7821\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 563us/step - loss: 0.4232 - accuracy: 0.7918\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 519us/step - loss: 0.3998 - accuracy: 0.8171\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.4329 - accuracy: 0.8132\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 494us/step - loss: 0.3923 - accuracy: 0.8327\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 513us/step - loss: 0.4071 - accuracy: 0.8035\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 607us/step - loss: 0.3808 - accuracy: 0.8191\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 463us/step - loss: 0.3830 - accuracy: 0.8171\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 528us/step - loss: 0.3857 - accuracy: 0.8152\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.3894 - accuracy: 0.8210\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7977\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 515us/step - loss: 0.3951 - accuracy: 0.7996\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 577us/step - loss: 0.3855 - accuracy: 0.8093\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 470us/step - loss: 0.3891 - accuracy: 0.8230\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 495us/step - loss: 0.3822 - accuracy: 0.8230\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 486us/step - loss: 0.3990 - accuracy: 0.8132\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 487us/step - loss: 0.4105 - accuracy: 0.7996\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 619us/step - loss: 0.4111 - accuracy: 0.8074\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.4093 - accuracy: 0.7977\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 470us/step - loss: 0.4021 - accuracy: 0.8249\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 554us/step - loss: 0.3758 - accuracy: 0.8327\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.3776 - accuracy: 0.8444\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 365us/step - loss: 0.4065 - accuracy: 0.8016\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.3877 - accuracy: 0.8191\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 352us/step - loss: 0.3722 - accuracy: 0.8249\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 353us/step - loss: 0.3838 - accuracy: 0.8210\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 569us/step - loss: 0.3848 - accuracy: 0.8171\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 484us/step - loss: 0.4341 - accuracy: 0.7860\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 517us/step - loss: 0.3917 - accuracy: 0.8132\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 551us/step - loss: 0.4121 - accuracy: 0.8171\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.3843 - accuracy: 0.8230\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 501us/step - loss: 0.3717 - accuracy: 0.8268\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 490us/step - loss: 0.3922 - accuracy: 0.8171\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 505us/step - loss: 0.3750 - accuracy: 0.8366\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 655us/step - loss: 0.4070 - accuracy: 0.8016\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 540us/step - loss: 0.3916 - accuracy: 0.8230\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 465us/step - loss: 0.3673 - accuracy: 0.8307\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 491us/step - loss: 0.3883 - accuracy: 0.8016\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8230\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 582us/step - loss: 0.3714 - accuracy: 0.8307\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 510us/step - loss: 0.4505 - accuracy: 0.7724\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 591us/step - loss: 0.4201 - accuracy: 0.8035\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.4093 - accuracy: 0.7957\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 463us/step - loss: 0.3802 - accuracy: 0.8307\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 607us/step - loss: 0.3896 - accuracy: 0.8191\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 481us/step - loss: 0.3887 - accuracy: 0.8016\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 527us/step - loss: 0.3666 - accuracy: 0.8405\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 533us/step - loss: 0.3718 - accuracy: 0.8405\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 451us/step - loss: 0.3772 - accuracy: 0.8405\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3895 - accuracy: 0.8054\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.3726 - accuracy: 0.8346\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4971 - accuracy: 0.7743\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4247 - accuracy: 0.7938\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3957 - accuracy: 0.8171\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 511us/step - loss: 0.3924 - accuracy: 0.8249\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.5118 - accuracy: 0.7704\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 599us/step - loss: 0.4446 - accuracy: 0.8016\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 480us/step - loss: 0.3796 - accuracy: 0.8346\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 512us/step - loss: 0.3946 - accuracy: 0.8171\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 526us/step - loss: 0.3741 - accuracy: 0.8327\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.3733 - accuracy: 0.8366\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 878us/step - loss: 0.3756 - accuracy: 0.8327\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.4588 - accuracy: 0.8035\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 529us/step - loss: 0.4290 - accuracy: 0.7899\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 508us/step - loss: 0.4071 - accuracy: 0.7996\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7840\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 526us/step - loss: 0.4100 - accuracy: 0.7957\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 624us/step - loss: 0.3918 - accuracy: 0.8210\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.4358 - accuracy: 0.8016\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 493us/step - loss: 0.4229 - accuracy: 0.7957\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.3977 - accuracy: 0.8230\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 454us/step - loss: 0.4067 - accuracy: 0.8249\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 520us/step - loss: 0.3976 - accuracy: 0.8035\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 493us/step - loss: 0.3927 - accuracy: 0.8132\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 460us/step - loss: 0.3889 - accuracy: 0.8366\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.3902 - accuracy: 0.8132\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.3814 - accuracy: 0.8249\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3839 - accuracy: 0.8405\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.3875 - accuracy: 0.8210\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3941 - accuracy: 0.8113\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4115 - accuracy: 0.8093\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 518us/step - loss: 0.3971 - accuracy: 0.8152\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 541us/step - loss: 0.3889 - accuracy: 0.8327\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 508us/step - loss: 0.4953 - accuracy: 0.7724\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 537us/step - loss: 0.4738 - accuracy: 0.7763\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 397us/step - loss: 0.4274 - accuracy: 0.8054\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 593us/step - loss: 0.4179 - accuracy: 0.8152\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 509us/step - loss: 0.4199 - accuracy: 0.7977\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 496us/step - loss: 0.4008 - accuracy: 0.8230\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 598us/step - loss: 0.4195 - accuracy: 0.7918\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 558us/step - loss: 0.3952 - accuracy: 0.8307\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 543us/step - loss: 0.4093 - accuracy: 0.8093\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 512us/step - loss: 0.3965 - accuracy: 0.8230\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8191\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 527us/step - loss: 0.4043 - accuracy: 0.8035\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 648us/step - loss: 0.4547 - accuracy: 0.8054\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 492us/step - loss: 0.4141 - accuracy: 0.8016\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 514us/step - loss: 0.4340 - accuracy: 0.7782\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.3962 - accuracy: 0.8307\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 552us/step - loss: 0.3907 - accuracy: 0.8074\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 578us/step - loss: 0.5866 - accuracy: 0.7412\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 461us/step - loss: 0.4788 - accuracy: 0.7607\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 479us/step - loss: 0.4207 - accuracy: 0.7918\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 505us/step - loss: 0.4211 - accuracy: 0.8054\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4010 - accuracy: 0.8132\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4301 - accuracy: 0.7879\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3941 - accuracy: 0.8093\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3855 - accuracy: 0.8249\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3844 - accuracy: 0.8210\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 532us/step - loss: 0.3811 - accuracy: 0.8444\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 511us/step - loss: 0.3997 - accuracy: 0.8054\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 513us/step - loss: 0.6861 - accuracy: 0.7529\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 672us/step - loss: 0.4470 - accuracy: 0.8054\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 451us/step - loss: 0.4838 - accuracy: 0.7568\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 462us/step - loss: 0.4225 - accuracy: 0.8132\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.4001 - accuracy: 0.8054\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 557us/step - loss: 0.4619 - accuracy: 0.7957\n",
      "17/17 [==============================] - 0s 436us/step - loss: 0.5078 - accuracy: 0.7685\n",
      "8/8 [==============================] - 0s 627us/step - loss: 1.2298 - accuracy: 0.6772\n",
      "Epoch 1/300\n",
      "17/17 [==============================] - 0s 447us/step - loss: 0.4711 - accuracy: 0.7840\n",
      "Epoch 2/300\n",
      "17/17 [==============================] - 0s 502us/step - loss: 0.4139 - accuracy: 0.8191\n",
      "Epoch 3/300\n",
      "17/17 [==============================] - 0s 479us/step - loss: 0.4174 - accuracy: 0.7879\n",
      "Epoch 4/300\n",
      "17/17 [==============================] - 0s 563us/step - loss: 0.4030 - accuracy: 0.8230\n",
      "Epoch 5/300\n",
      "17/17 [==============================] - 0s 576us/step - loss: 0.5100 - accuracy: 0.7763\n",
      "Epoch 6/300\n",
      "17/17 [==============================] - 0s 546us/step - loss: 0.4248 - accuracy: 0.8093\n",
      "Epoch 7/300\n",
      "17/17 [==============================] - 0s 450us/step - loss: 0.4078 - accuracy: 0.8191\n",
      "Epoch 8/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.4097 - accuracy: 0.8074\n",
      "Epoch 9/300\n",
      "17/17 [==============================] - 0s 325us/step - loss: 0.3876 - accuracy: 0.8191\n",
      "Epoch 10/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.3988 - accuracy: 0.8035\n",
      "Epoch 11/300\n",
      "17/17 [==============================] - 0s 409us/step - loss: 0.4512 - accuracy: 0.7782\n",
      "Epoch 12/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.4016 - accuracy: 0.8016\n",
      "Epoch 13/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3889 - accuracy: 0.8424\n",
      "Epoch 14/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4020 - accuracy: 0.8093\n",
      "Epoch 15/300\n",
      "17/17 [==============================] - 0s 601us/step - loss: 0.3840 - accuracy: 0.8230\n",
      "Epoch 16/300\n",
      "17/17 [==============================] - 0s 510us/step - loss: 0.3831 - accuracy: 0.8093\n",
      "Epoch 17/300\n",
      "17/17 [==============================] - 0s 551us/step - loss: 0.4092 - accuracy: 0.8093\n",
      "Epoch 18/300\n",
      "17/17 [==============================] - 0s 629us/step - loss: 0.4623 - accuracy: 0.7977\n",
      "Epoch 19/300\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.4449 - accuracy: 0.7860\n",
      "Epoch 20/300\n",
      "17/17 [==============================] - 0s 508us/step - loss: 0.4115 - accuracy: 0.8016\n",
      "Epoch 21/300\n",
      "17/17 [==============================] - 0s 484us/step - loss: 0.3930 - accuracy: 0.8132\n",
      "Epoch 22/300\n",
      "17/17 [==============================] - 0s 579us/step - loss: 0.3873 - accuracy: 0.8327\n",
      "Epoch 23/300\n",
      "17/17 [==============================] - 0s 605us/step - loss: 0.3765 - accuracy: 0.8288\n",
      "Epoch 24/300\n",
      "17/17 [==============================] - 0s 539us/step - loss: 0.4028 - accuracy: 0.8035\n",
      "Epoch 25/300\n",
      "17/17 [==============================] - 0s 475us/step - loss: 0.4395 - accuracy: 0.7899\n",
      "Epoch 26/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4240 - accuracy: 0.8016\n",
      "Epoch 27/300\n",
      "17/17 [==============================] - 0s 514us/step - loss: 0.4103 - accuracy: 0.7899\n",
      "Epoch 28/300\n",
      "17/17 [==============================] - 0s 675us/step - loss: 0.4059 - accuracy: 0.8113\n",
      "Epoch 29/300\n",
      "17/17 [==============================] - 0s 426us/step - loss: 0.3987 - accuracy: 0.8132\n",
      "Epoch 30/300\n",
      "17/17 [==============================] - 0s 522us/step - loss: 0.4107 - accuracy: 0.8074\n",
      "Epoch 31/300\n",
      "17/17 [==============================] - 0s 508us/step - loss: 0.3919 - accuracy: 0.8093\n",
      "Epoch 32/300\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.3952 - accuracy: 0.7996\n",
      "Epoch 33/300\n",
      "17/17 [==============================] - 0s 728us/step - loss: 0.5040 - accuracy: 0.7471\n",
      "Epoch 34/300\n",
      "17/17 [==============================] - 0s 544us/step - loss: 0.4116 - accuracy: 0.7899\n",
      "Epoch 35/300\n",
      "17/17 [==============================] - 0s 466us/step - loss: 0.3895 - accuracy: 0.8191\n",
      "Epoch 36/300\n",
      "17/17 [==============================] - 0s 503us/step - loss: 0.3916 - accuracy: 0.8346\n",
      "Epoch 37/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4680 - accuracy: 0.7665\n",
      "Epoch 38/300\n",
      "17/17 [==============================] - 0s 354us/step - loss: 0.4081 - accuracy: 0.8113\n",
      "Epoch 39/300\n",
      "17/17 [==============================] - 0s 373us/step - loss: 0.3961 - accuracy: 0.8132\n",
      "Epoch 40/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3796 - accuracy: 0.8327\n",
      "Epoch 41/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3744 - accuracy: 0.8327\n",
      "Epoch 42/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.4626 - accuracy: 0.7879\n",
      "Epoch 43/300\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.5256 - accuracy: 0.7588\n",
      "Epoch 44/300\n",
      "17/17 [==============================] - 0s 520us/step - loss: 0.4219 - accuracy: 0.8152\n",
      "Epoch 45/300\n",
      "17/17 [==============================] - 0s 663us/step - loss: 0.4226 - accuracy: 0.8230\n",
      "Epoch 46/300\n",
      "17/17 [==============================] - 0s 515us/step - loss: 0.4139 - accuracy: 0.8113\n",
      "Epoch 47/300\n",
      "17/17 [==============================] - 0s 577us/step - loss: 0.4896 - accuracy: 0.7529\n",
      "Epoch 48/300\n",
      "17/17 [==============================] - 0s 505us/step - loss: 0.4152 - accuracy: 0.8074\n",
      "Epoch 49/300\n",
      "17/17 [==============================] - 0s 497us/step - loss: 0.4084 - accuracy: 0.8093\n",
      "Epoch 50/300\n",
      "17/17 [==============================] - 0s 569us/step - loss: 0.4460 - accuracy: 0.7918\n",
      "Epoch 51/300\n",
      "17/17 [==============================] - 0s 594us/step - loss: 0.3985 - accuracy: 0.8171\n",
      "Epoch 52/300\n",
      "17/17 [==============================] - 0s 565us/step - loss: 0.3964 - accuracy: 0.7996\n",
      "Epoch 53/300\n",
      "17/17 [==============================] - 0s 583us/step - loss: 0.4111 - accuracy: 0.7996\n",
      "Epoch 54/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.7840\n",
      "Epoch 55/300\n",
      "17/17 [==============================] - 0s 484us/step - loss: 0.4734 - accuracy: 0.7899\n",
      "Epoch 56/300\n",
      "17/17 [==============================] - 0s 608us/step - loss: 0.3995 - accuracy: 0.8210\n",
      "Epoch 57/300\n",
      "17/17 [==============================] - 0s 474us/step - loss: 0.3985 - accuracy: 0.8463\n",
      "Epoch 58/300\n",
      "17/17 [==============================] - 0s 533us/step - loss: 0.3901 - accuracy: 0.8132\n",
      "Epoch 59/300\n",
      "17/17 [==============================] - 0s 511us/step - loss: 0.3797 - accuracy: 0.8444\n",
      "Epoch 60/300\n",
      "17/17 [==============================] - 0s 482us/step - loss: 0.3740 - accuracy: 0.8230\n",
      "Epoch 61/300\n",
      "17/17 [==============================] - 0s 632us/step - loss: 0.4181 - accuracy: 0.7860\n",
      "Epoch 62/300\n",
      "17/17 [==============================] - 0s 552us/step - loss: 0.3836 - accuracy: 0.8093\n",
      "Epoch 63/300\n",
      "17/17 [==============================] - 0s 568us/step - loss: 0.3946 - accuracy: 0.8171\n",
      "Epoch 64/300\n",
      "17/17 [==============================] - 0s 770us/step - loss: 0.3961 - accuracy: 0.7977\n",
      "Epoch 65/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3762 - accuracy: 0.8327\n",
      "Epoch 66/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.4233 - accuracy: 0.7860\n",
      "Epoch 67/300\n",
      "17/17 [==============================] - 0s 413us/step - loss: 0.3885 - accuracy: 0.8249\n",
      "Epoch 68/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3909 - accuracy: 0.8288\n",
      "Epoch 69/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3848 - accuracy: 0.8268\n",
      "Epoch 70/300\n",
      "17/17 [==============================] - 0s 614us/step - loss: 0.3735 - accuracy: 0.8327\n",
      "Epoch 71/300\n",
      "17/17 [==============================] - 0s 509us/step - loss: 0.3749 - accuracy: 0.8249\n",
      "Epoch 72/300\n",
      "17/17 [==============================] - 0s 583us/step - loss: 0.3735 - accuracy: 0.8366\n",
      "Epoch 73/300\n",
      "17/17 [==============================] - 0s 612us/step - loss: 0.3850 - accuracy: 0.8132\n",
      "Epoch 74/300\n",
      "17/17 [==============================] - 0s 543us/step - loss: 0.3736 - accuracy: 0.8366\n",
      "Epoch 75/300\n",
      "17/17 [==============================] - 0s 543us/step - loss: 0.4115 - accuracy: 0.8035\n",
      "Epoch 76/300\n",
      "17/17 [==============================] - 0s 513us/step - loss: 0.4192 - accuracy: 0.7918\n",
      "Epoch 77/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4886 - accuracy: 0.7821\n",
      "Epoch 78/300\n",
      "17/17 [==============================] - 0s 499us/step - loss: 0.3876 - accuracy: 0.8054\n",
      "Epoch 79/300\n",
      "17/17 [==============================] - 0s 623us/step - loss: 0.3859 - accuracy: 0.8191\n",
      "Epoch 80/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.8054\n",
      "Epoch 81/300\n",
      "17/17 [==============================] - 0s 507us/step - loss: 0.4120 - accuracy: 0.7938\n",
      "Epoch 82/300\n",
      "17/17 [==============================] - 0s 599us/step - loss: 0.4001 - accuracy: 0.8171\n",
      "Epoch 83/300\n",
      "17/17 [==============================] - 0s 510us/step - loss: 0.3846 - accuracy: 0.8307\n",
      "Epoch 84/300\n",
      "17/17 [==============================] - 0s 511us/step - loss: 0.3766 - accuracy: 0.8307\n",
      "Epoch 85/300\n",
      "17/17 [==============================] - 0s 476us/step - loss: 0.3760 - accuracy: 0.8191\n",
      "Epoch 86/300\n",
      "17/17 [==============================] - 0s 477us/step - loss: 0.3809 - accuracy: 0.8210\n",
      "Epoch 87/300\n",
      "17/17 [==============================] - 0s 438us/step - loss: 0.3841 - accuracy: 0.8268\n",
      "Epoch 88/300\n",
      "17/17 [==============================] - 0s 488us/step - loss: 0.3878 - accuracy: 0.8191\n",
      "Epoch 89/300\n",
      "17/17 [==============================] - 0s 447us/step - loss: 0.3732 - accuracy: 0.8288\n",
      "Epoch 90/300\n",
      "17/17 [==============================] - 0s 527us/step - loss: 0.4598 - accuracy: 0.7977\n",
      "Epoch 91/300\n",
      "17/17 [==============================] - 0s 522us/step - loss: 0.3948 - accuracy: 0.8171\n",
      "Epoch 92/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.4140 - accuracy: 0.7918\n",
      "Epoch 93/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3990 - accuracy: 0.8093\n",
      "Epoch 94/300\n",
      "17/17 [==============================] - 0s 410us/step - loss: 0.3861 - accuracy: 0.8093\n",
      "Epoch 95/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3974 - accuracy: 0.8016\n",
      "Epoch 96/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3708 - accuracy: 0.8385\n",
      "Epoch 97/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3904 - accuracy: 0.8171\n",
      "Epoch 98/300\n",
      "17/17 [==============================] - 0s 615us/step - loss: 0.4291 - accuracy: 0.8016\n",
      "Epoch 99/300\n",
      "17/17 [==============================] - 0s 496us/step - loss: 0.4211 - accuracy: 0.7840\n",
      "Epoch 100/300\n",
      "17/17 [==============================] - 0s 692us/step - loss: 0.3880 - accuracy: 0.8288\n",
      "Epoch 101/300\n",
      "17/17 [==============================] - 0s 535us/step - loss: 0.3750 - accuracy: 0.8230\n",
      "Epoch 102/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3732 - accuracy: 0.8288\n",
      "Epoch 103/300\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3695 - accuracy: 0.8307\n",
      "Epoch 104/300\n",
      "17/17 [==============================] - 0s 661us/step - loss: 0.3709 - accuracy: 0.8288\n",
      "Epoch 105/300\n",
      "17/17 [==============================] - 0s 485us/step - loss: 0.4075 - accuracy: 0.8268\n",
      "Epoch 106/300\n",
      "17/17 [==============================] - 0s 537us/step - loss: 0.3845 - accuracy: 0.8288\n",
      "Epoch 107/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.8268\n",
      "Epoch 108/300\n",
      "17/17 [==============================] - 0s 536us/step - loss: 0.4065 - accuracy: 0.7996\n",
      "Epoch 109/300\n",
      "17/17 [==============================] - 0s 633us/step - loss: 0.3836 - accuracy: 0.8366\n",
      "Epoch 110/300\n",
      "17/17 [==============================] - 0s 553us/step - loss: 0.3704 - accuracy: 0.8307\n",
      "Epoch 111/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3781 - accuracy: 0.8152\n",
      "Epoch 112/300\n",
      "17/17 [==============================] - 0s 515us/step - loss: 0.3715 - accuracy: 0.8346\n",
      "Epoch 113/300\n",
      "17/17 [==============================] - 0s 494us/step - loss: 0.3810 - accuracy: 0.8346\n",
      "Epoch 114/300\n",
      "17/17 [==============================] - 0s 500us/step - loss: 0.3756 - accuracy: 0.8191\n",
      "Epoch 115/300\n",
      "17/17 [==============================] - 0s 692us/step - loss: 0.5375 - accuracy: 0.7198\n",
      "Epoch 116/300\n",
      "17/17 [==============================] - 0s 561us/step - loss: 0.4463 - accuracy: 0.7860\n",
      "Epoch 117/300\n",
      "17/17 [==============================] - 0s 585us/step - loss: 0.3842 - accuracy: 0.8230\n",
      "Epoch 118/300\n",
      "17/17 [==============================] - 0s 452us/step - loss: 0.5263 - accuracy: 0.7821\n",
      "Epoch 119/300\n",
      "17/17 [==============================] - 0s 812us/step - loss: 0.4263 - accuracy: 0.7860\n",
      "Epoch 120/300\n",
      "17/17 [==============================] - 0s 636us/step - loss: 0.4099 - accuracy: 0.8268\n",
      "Epoch 121/300\n",
      "17/17 [==============================] - 0s 544us/step - loss: 0.3892 - accuracy: 0.8230\n",
      "Epoch 122/300\n",
      "17/17 [==============================] - 0s 543us/step - loss: 0.3824 - accuracy: 0.8268\n",
      "Epoch 123/300\n",
      "17/17 [==============================] - 0s 489us/step - loss: 0.3700 - accuracy: 0.8327\n",
      "Epoch 124/300\n",
      "17/17 [==============================] - 0s 522us/step - loss: 0.3763 - accuracy: 0.8230\n",
      "Epoch 125/300\n",
      "17/17 [==============================] - 0s 664us/step - loss: 0.5604 - accuracy: 0.7412\n",
      "Epoch 126/300\n",
      "17/17 [==============================] - 0s 568us/step - loss: 0.4051 - accuracy: 0.8054\n",
      "Epoch 127/300\n",
      "17/17 [==============================] - 0s 508us/step - loss: 0.3918 - accuracy: 0.8113\n",
      "Epoch 128/300\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.8230\n",
      "Epoch 129/300\n",
      "17/17 [==============================] - 0s 499us/step - loss: 0.3798 - accuracy: 0.8171\n",
      "Epoch 130/300\n",
      "17/17 [==============================] - 0s 562us/step - loss: 0.3967 - accuracy: 0.8171\n",
      "Epoch 131/300\n",
      "17/17 [==============================] - 0s 576us/step - loss: 0.3970 - accuracy: 0.8152\n",
      "Epoch 132/300\n",
      "17/17 [==============================] - 0s 596us/step - loss: 0.3921 - accuracy: 0.8113\n",
      "Epoch 133/300\n",
      "17/17 [==============================] - 0s 528us/step - loss: 0.3910 - accuracy: 0.8152\n",
      "Epoch 134/300\n",
      "17/17 [==============================] - 0s 482us/step - loss: 0.3811 - accuracy: 0.8171\n",
      "Epoch 135/300\n",
      "17/17 [==============================] - 0s 541us/step - loss: 0.4027 - accuracy: 0.8268\n",
      "Epoch 136/300\n",
      "17/17 [==============================] - 0s 630us/step - loss: 0.3824 - accuracy: 0.8152\n",
      "Epoch 137/300\n",
      "17/17 [==============================] - 0s 527us/step - loss: 0.3754 - accuracy: 0.8268\n",
      "Epoch 138/300\n",
      "17/17 [==============================] - 0s 443us/step - loss: 0.3820 - accuracy: 0.8327\n",
      "Epoch 139/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3909 - accuracy: 0.8230\n",
      "Epoch 140/300\n",
      "17/17 [==============================] - 0s 322us/step - loss: 0.3866 - accuracy: 0.8191\n",
      "Epoch 141/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3931 - accuracy: 0.8074\n",
      "Epoch 142/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3862 - accuracy: 0.8288\n",
      "Epoch 143/300\n",
      "17/17 [==============================] - 0s 418us/step - loss: 0.4108 - accuracy: 0.8016\n",
      "Epoch 144/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3917 - accuracy: 0.8093\n",
      "Epoch 145/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3904 - accuracy: 0.8132\n",
      "Epoch 146/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.4006 - accuracy: 0.8191\n",
      "Epoch 147/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3756 - accuracy: 0.8327\n",
      "Epoch 148/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3821 - accuracy: 0.8307\n",
      "Epoch 149/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3846 - accuracy: 0.8327\n",
      "Epoch 150/300\n",
      "17/17 [==============================] - 0s 394us/step - loss: 0.3902 - accuracy: 0.8191\n",
      "Epoch 151/300\n",
      "17/17 [==============================] - 0s 357us/step - loss: 0.5369 - accuracy: 0.7490\n",
      "Epoch 152/300\n",
      "17/17 [==============================] - 0s 361us/step - loss: 0.4019 - accuracy: 0.8132\n",
      "Epoch 153/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4097 - accuracy: 0.8074\n",
      "Epoch 154/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4299 - accuracy: 0.7977\n",
      "Epoch 155/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3927 - accuracy: 0.8366\n",
      "Epoch 156/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4238 - accuracy: 0.7957\n",
      "Epoch 157/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3937 - accuracy: 0.8093\n",
      "Epoch 158/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3838 - accuracy: 0.8346\n",
      "Epoch 159/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3941 - accuracy: 0.8093\n",
      "Epoch 160/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3973 - accuracy: 0.8191\n",
      "Epoch 161/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3878 - accuracy: 0.8268\n",
      "Epoch 162/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3730 - accuracy: 0.8327\n",
      "Epoch 163/300\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.4310 - accuracy: 0.7996\n",
      "Epoch 164/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3821 - accuracy: 0.8230\n",
      "Epoch 165/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3757 - accuracy: 0.8288\n",
      "Epoch 166/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3706 - accuracy: 0.8249\n",
      "Epoch 167/300\n",
      "17/17 [==============================] - 0s 328us/step - loss: 0.3931 - accuracy: 0.8171\n",
      "Epoch 168/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3835 - accuracy: 0.8327\n",
      "Epoch 169/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3840 - accuracy: 0.8249\n",
      "Epoch 170/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.4799 - accuracy: 0.7763\n",
      "Epoch 171/300\n",
      "17/17 [==============================] - 0s 317us/step - loss: 0.6087 - accuracy: 0.7004\n",
      "Epoch 172/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4315 - accuracy: 0.7879\n",
      "Epoch 173/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.4285 - accuracy: 0.7899\n",
      "Epoch 174/300\n",
      "17/17 [==============================] - 0s 389us/step - loss: 0.4005 - accuracy: 0.8035\n",
      "Epoch 175/300\n",
      "17/17 [==============================] - 0s 380us/step - loss: 0.3878 - accuracy: 0.8191\n",
      "Epoch 176/300\n",
      "17/17 [==============================] - 0s 369us/step - loss: 0.3896 - accuracy: 0.8113\n",
      "Epoch 177/300\n",
      "17/17 [==============================] - 0s 337us/step - loss: 0.3936 - accuracy: 0.8152\n",
      "Epoch 178/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3839 - accuracy: 0.8171\n",
      "Epoch 179/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.3855 - accuracy: 0.8113\n",
      "Epoch 180/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.4607 - accuracy: 0.7743\n",
      "Epoch 181/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3909 - accuracy: 0.8152\n",
      "Epoch 182/300\n",
      "17/17 [==============================] - 0s 392us/step - loss: 0.3962 - accuracy: 0.8132\n",
      "Epoch 183/300\n",
      "17/17 [==============================] - 0s 374us/step - loss: 0.3913 - accuracy: 0.8132\n",
      "Epoch 184/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.3920 - accuracy: 0.8093\n",
      "Epoch 185/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3825 - accuracy: 0.8268\n",
      "Epoch 186/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.3830 - accuracy: 0.8191\n",
      "Epoch 187/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3896 - accuracy: 0.8268\n",
      "Epoch 188/300\n",
      "17/17 [==============================] - 0s 336us/step - loss: 0.4114 - accuracy: 0.8035\n",
      "Epoch 189/300\n",
      "17/17 [==============================] - 0s 404us/step - loss: 0.4352 - accuracy: 0.7918\n",
      "Epoch 190/300\n",
      "17/17 [==============================] - 0s 368us/step - loss: 0.4045 - accuracy: 0.8113\n",
      "Epoch 191/300\n",
      "17/17 [==============================] - 0s 347us/step - loss: 0.4166 - accuracy: 0.8016\n",
      "Epoch 192/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4144 - accuracy: 0.8074\n",
      "Epoch 193/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.5328 - accuracy: 0.7802\n",
      "Epoch 194/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.4546 - accuracy: 0.7802\n",
      "Epoch 195/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4114 - accuracy: 0.8210\n",
      "Epoch 196/300\n",
      "17/17 [==============================] - 0s 386us/step - loss: 0.3866 - accuracy: 0.8307\n",
      "Epoch 197/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3771 - accuracy: 0.8307\n",
      "Epoch 198/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3899 - accuracy: 0.8191\n",
      "Epoch 199/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3780 - accuracy: 0.8268\n",
      "Epoch 200/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3746 - accuracy: 0.8385\n",
      "Epoch 201/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.3841 - accuracy: 0.8230\n",
      "Epoch 202/300\n",
      "17/17 [==============================] - 0s 324us/step - loss: 0.3755 - accuracy: 0.8268\n",
      "Epoch 203/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3830 - accuracy: 0.8268\n",
      "Epoch 204/300\n",
      "17/17 [==============================] - 0s 393us/step - loss: 0.3731 - accuracy: 0.8230\n",
      "Epoch 205/300\n",
      "17/17 [==============================] - 0s 366us/step - loss: 0.3745 - accuracy: 0.8346\n",
      "Epoch 206/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.4062 - accuracy: 0.8113\n",
      "Epoch 207/300\n",
      "17/17 [==============================] - 0s 338us/step - loss: 0.3820 - accuracy: 0.8307\n",
      "Epoch 208/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4238 - accuracy: 0.7763\n",
      "Epoch 209/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3806 - accuracy: 0.8152\n",
      "Epoch 210/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3784 - accuracy: 0.8249\n",
      "Epoch 211/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4018 - accuracy: 0.8054\n",
      "Epoch 212/300\n",
      "17/17 [==============================] - 0s 382us/step - loss: 0.3736 - accuracy: 0.8268\n",
      "Epoch 213/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3681 - accuracy: 0.8424\n",
      "Epoch 214/300\n",
      "17/17 [==============================] - 0s 341us/step - loss: 0.3704 - accuracy: 0.8424\n",
      "Epoch 215/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3813 - accuracy: 0.8346\n",
      "Epoch 216/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3750 - accuracy: 0.8268\n",
      "Epoch 217/300\n",
      "17/17 [==============================] - 0s 316us/step - loss: 0.3737 - accuracy: 0.8249\n",
      "Epoch 218/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3824 - accuracy: 0.8132\n",
      "Epoch 219/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.3843 - accuracy: 0.8171\n",
      "Epoch 220/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3952 - accuracy: 0.8249\n",
      "Epoch 221/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3887 - accuracy: 0.8132\n",
      "Epoch 222/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3690 - accuracy: 0.8405\n",
      "Epoch 223/300\n",
      "17/17 [==============================] - 0s 321us/step - loss: 0.3695 - accuracy: 0.8405\n",
      "Epoch 224/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3812 - accuracy: 0.8230\n",
      "Epoch 225/300\n",
      "17/17 [==============================] - 0s 331us/step - loss: 0.4459 - accuracy: 0.7879\n",
      "Epoch 226/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.4235 - accuracy: 0.8016\n",
      "Epoch 227/300\n",
      "17/17 [==============================] - 0s 351us/step - loss: 0.4245 - accuracy: 0.8035\n",
      "Epoch 228/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3922 - accuracy: 0.8191\n",
      "Epoch 229/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3835 - accuracy: 0.8171\n",
      "Epoch 230/300\n",
      "17/17 [==============================] - 0s 367us/step - loss: 0.3714 - accuracy: 0.8366\n",
      "Epoch 231/300\n",
      "17/17 [==============================] - 0s 340us/step - loss: 0.3821 - accuracy: 0.8113\n",
      "Epoch 232/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.3988 - accuracy: 0.8016\n",
      "Epoch 233/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3794 - accuracy: 0.8093\n",
      "Epoch 234/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3683 - accuracy: 0.8385\n",
      "Epoch 235/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3889 - accuracy: 0.8054\n",
      "Epoch 236/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3877 - accuracy: 0.8074\n",
      "Epoch 237/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.3737 - accuracy: 0.8346\n",
      "Epoch 238/300\n",
      "17/17 [==============================] - 0s 358us/step - loss: 0.4214 - accuracy: 0.8035\n",
      "Epoch 239/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3964 - accuracy: 0.8132\n",
      "Epoch 240/300\n",
      "17/17 [==============================] - 0s 339us/step - loss: 0.4035 - accuracy: 0.8132\n",
      "Epoch 241/300\n",
      "17/17 [==============================] - 0s 327us/step - loss: 0.3776 - accuracy: 0.8268\n",
      "Epoch 242/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.5236 - accuracy: 0.7588\n",
      "Epoch 243/300\n",
      "17/17 [==============================] - 0s 349us/step - loss: 0.4217 - accuracy: 0.7977\n",
      "Epoch 244/300\n",
      "17/17 [==============================] - 0s 407us/step - loss: 0.3805 - accuracy: 0.8288\n",
      "Epoch 245/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3874 - accuracy: 0.8268\n",
      "Epoch 246/300\n",
      "17/17 [==============================] - 0s 323us/step - loss: 0.3888 - accuracy: 0.8268\n",
      "Epoch 247/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3748 - accuracy: 0.8230\n",
      "Epoch 248/300\n",
      "17/17 [==============================] - 0s 332us/step - loss: 0.3935 - accuracy: 0.8268\n",
      "Epoch 249/300\n",
      "17/17 [==============================] - 0s 344us/step - loss: 0.3838 - accuracy: 0.8268\n",
      "Epoch 250/300\n",
      "17/17 [==============================] - 0s 333us/step - loss: 0.3743 - accuracy: 0.8327\n",
      "Epoch 251/300\n",
      "17/17 [==============================] - 0s 572us/step - loss: 0.3788 - accuracy: 0.8093\n",
      "Epoch 252/300\n",
      "17/17 [==============================] - 0s 385us/step - loss: 0.3865 - accuracy: 0.8016\n",
      "Epoch 253/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3986 - accuracy: 0.8113\n",
      "Epoch 254/300\n",
      "17/17 [==============================] - 0s 345us/step - loss: 0.3798 - accuracy: 0.8191\n",
      "Epoch 255/300\n",
      "17/17 [==============================] - 0s 335us/step - loss: 0.4084 - accuracy: 0.7724\n",
      "Epoch 256/300\n",
      "17/17 [==============================] - 0s 312us/step - loss: 0.3841 - accuracy: 0.8171\n",
      "Epoch 257/300\n",
      "17/17 [==============================] - 0s 329us/step - loss: 0.3803 - accuracy: 0.8249\n",
      "Epoch 258/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.3889 - accuracy: 0.8132\n",
      "Epoch 259/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3854 - accuracy: 0.8268\n",
      "Epoch 260/300\n",
      "17/17 [==============================] - 0s 411us/step - loss: 0.3982 - accuracy: 0.8054\n",
      "Epoch 261/300\n",
      "17/17 [==============================] - 0s 360us/step - loss: 0.4129 - accuracy: 0.8152\n",
      "Epoch 262/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.4355 - accuracy: 0.7918\n",
      "Epoch 263/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3871 - accuracy: 0.8249\n",
      "Epoch 264/300\n",
      "17/17 [==============================] - 0s 319us/step - loss: 0.3699 - accuracy: 0.8249\n",
      "Epoch 265/300\n",
      "17/17 [==============================] - 0s 437us/step - loss: 0.3967 - accuracy: 0.8054\n",
      "Epoch 266/300\n",
      "17/17 [==============================] - 0s 375us/step - loss: 0.3703 - accuracy: 0.8249\n",
      "Epoch 267/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3804 - accuracy: 0.8307\n",
      "Epoch 268/300\n",
      "17/17 [==============================] - 0s 348us/step - loss: 0.3782 - accuracy: 0.8268\n",
      "Epoch 269/300\n",
      "17/17 [==============================] - 0s 342us/step - loss: 0.3927 - accuracy: 0.8113\n",
      "Epoch 270/300\n",
      "17/17 [==============================] - 0s 326us/step - loss: 0.3969 - accuracy: 0.8035\n",
      "Epoch 271/300\n",
      "17/17 [==============================] - 0s 334us/step - loss: 0.3780 - accuracy: 0.8230\n",
      "Epoch 272/300\n",
      "17/17 [==============================] - 0s 378us/step - loss: 0.3876 - accuracy: 0.8132\n",
      "Epoch 273/300\n",
      "17/17 [==============================] - 0s 396us/step - loss: 0.3732 - accuracy: 0.8152\n",
      "Epoch 274/300\n",
      "17/17 [==============================] - 0s 429us/step - loss: 0.3841 - accuracy: 0.8230\n",
      "Epoch 275/300\n",
      "17/17 [==============================] - 0s 457us/step - loss: 0.4135 - accuracy: 0.8054\n",
      "Epoch 276/300\n",
      "17/17 [==============================] - 0s 364us/step - loss: 0.3799 - accuracy: 0.8152\n",
      "Epoch 277/300\n",
      "17/17 [==============================] - 0s 387us/step - loss: 0.4579 - accuracy: 0.7938\n",
      "Epoch 278/300\n",
      "17/17 [==============================] - 0s 346us/step - loss: 0.4138 - accuracy: 0.8035\n",
      "Epoch 279/300\n",
      "17/17 [==============================] - 0s 384us/step - loss: 0.3764 - accuracy: 0.8366\n",
      "Epoch 280/300\n",
      "17/17 [==============================] - 0s 423us/step - loss: 0.3929 - accuracy: 0.7996\n",
      "Epoch 281/300\n",
      "17/17 [==============================] - 0s 505us/step - loss: 0.3903 - accuracy: 0.8210\n",
      "Epoch 282/300\n",
      "17/17 [==============================] - 0s 405us/step - loss: 0.3897 - accuracy: 0.8152\n",
      "Epoch 283/300\n",
      "17/17 [==============================] - 0s 391us/step - loss: 0.3707 - accuracy: 0.8385\n",
      "Epoch 284/300\n",
      "17/17 [==============================] - 0s 355us/step - loss: 0.3684 - accuracy: 0.8307\n",
      "Epoch 285/300\n",
      "17/17 [==============================] - 0s 350us/step - loss: 0.3743 - accuracy: 0.8366\n",
      "Epoch 286/300\n",
      "17/17 [==============================] - 0s 343us/step - loss: 0.3701 - accuracy: 0.8210\n",
      "Epoch 287/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.3803 - accuracy: 0.8288\n",
      "Epoch 288/300\n",
      "17/17 [==============================] - 0s 443us/step - loss: 0.4235 - accuracy: 0.8016\n",
      "Epoch 289/300\n",
      "17/17 [==============================] - 0s 403us/step - loss: 0.4331 - accuracy: 0.7840\n",
      "Epoch 290/300\n",
      "17/17 [==============================] - 0s 381us/step - loss: 0.3812 - accuracy: 0.8152\n",
      "Epoch 291/300\n",
      "17/17 [==============================] - 0s 362us/step - loss: 0.3711 - accuracy: 0.8288\n",
      "Epoch 292/300\n",
      "17/17 [==============================] - 0s 376us/step - loss: 0.3860 - accuracy: 0.8249\n",
      "Epoch 293/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3756 - accuracy: 0.8346\n",
      "Epoch 294/300\n",
      "17/17 [==============================] - 0s 383us/step - loss: 0.3701 - accuracy: 0.8171\n",
      "Epoch 295/300\n",
      "17/17 [==============================] - 0s 693us/step - loss: 0.4108 - accuracy: 0.8249\n",
      "Epoch 296/300\n",
      "17/17 [==============================] - 0s 408us/step - loss: 0.3931 - accuracy: 0.8093\n",
      "Epoch 297/300\n",
      "17/17 [==============================] - 0s 399us/step - loss: 0.3766 - accuracy: 0.8366\n",
      "Epoch 298/300\n",
      "17/17 [==============================] - 0s 379us/step - loss: 0.3744 - accuracy: 0.8307\n",
      "Epoch 299/300\n",
      "17/17 [==============================] - 0s 388us/step - loss: 0.3669 - accuracy: 0.8385\n",
      "Epoch 300/300\n",
      "17/17 [==============================] - 0s 390us/step - loss: 0.3821 - accuracy: 0.8307\n",
      "17/17 [==============================] - 0s 330us/step - loss: 0.3641 - accuracy: 0.8366\n",
      "8/8 [==============================] - 0s 881us/step - loss: 1.0712 - accuracy: 0.7323\n",
      "    # layers  train_acc  test_acc  train_loss  test_loss\n",
      "0       -1.0   0.782101  0.681102    0.485151   1.050159\n",
      "1        0.0   0.832685  0.700787    0.358338   0.950084\n",
      "2        1.0   0.844358  0.712598    0.354946   0.965446\n",
      "3        2.0   0.824903  0.700787    0.383218   1.029264\n",
      "4        3.0   0.819066  0.728346    0.362280   1.039111\n",
      "5        4.0   0.826848  0.712598    0.399056   0.984811\n",
      "6        5.0   0.793774  0.720472    0.415263   0.997072\n",
      "7        6.0   0.842412  0.728346    0.359469   1.119080\n",
      "8        7.0   0.762646  0.720472    0.446490   1.198509\n",
      "9        8.0   0.817121  0.728346    0.389843   0.937046\n",
      "10       9.0   0.803502  0.716535    0.401572   0.986217\n",
      "11      10.0   0.838521  0.708661    0.367064   0.992557\n",
      "12      11.0   0.832685  0.728346    0.374251   1.076546\n",
      "13      12.0   0.768483  0.677165    0.507810   1.229773\n",
      "14      13.0   0.836576  0.732283    0.364128   1.071152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets   import make_blobs\n",
    "from keras.layers       import Dense\n",
    "from keras.models       import Sequential\n",
    "from tensorflow.keras.optimizers   import SGD\n",
    "from tensorflow.keras.utils        import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate the data.\n",
    "import tensorflow as tf\n",
    "from    sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "def prepare_data():\n",
    "    PATH = \"../datasets/\"\n",
    "    # load the dataset\n",
    "    df = pd.read_csv(PATH + 'diabetes.csv', sep=',')\n",
    "\n",
    "    # split into input (X) and output (y) variables\n",
    "    X = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n",
    "            'DiabetesPedigreeFunction', 'Age']]\n",
    "    y = df[['Outcome']]\n",
    "\n",
    "    # Split into train and test data sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Build the base model.\n",
    "def get_base_model(trainX, trainy):\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(230, input_dim=8, activation='relu',\n",
    "                    kernel_initializer='he_normal'))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    opitimizer = tf.keras.optimizers.SGD(\n",
    "        learning_rate=0.0005, momentum=0.9, name=\"SGD\",\n",
    "    )\n",
    "\n",
    "    # Compile the keras model.\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opitimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Fit the keras model on the dataset.\n",
    "    model.fit(trainX, trainy, epochs=200, batch_size=10)\n",
    "\n",
    "    return model\n",
    "\n",
    "stats = []\n",
    "# Evaluate the model.\n",
    "def evaluate_model(numLayers, model, trainX, testX, trainy, testy):\n",
    "    train_loss, train_acc = model.evaluate(trainX, trainy, verbose=1)\n",
    "    test_loss, test_acc = model.evaluate(testX, testy, verbose=1)\n",
    "    stats.append({ '# layers':numLayers, 'train_acc':train_acc, 'test_acc':test_acc,\n",
    "                   'train_loss':train_loss, 'test_loss':test_loss })\n",
    "\n",
    "# Add one new layer and re-train only the new layer.\n",
    "def add_layer(model, trainX, trainy):\n",
    "    # Store the output layer.\n",
    "    output_layer = model.layers[-1]\n",
    "\n",
    "    # Remove the output layer.\n",
    "    model.pop()\n",
    "\n",
    "    # Mark all remaining layers as non-trainable.\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add a new hidden layer.\n",
    "    model.add(Dense(230, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "    # Add the output layer back.\n",
    "    model.add(output_layer)\n",
    "\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=300, verbose=1)\n",
    "    return model\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # Get the data and build the base model.\n",
    "    trainX, testX, trainy, testy = prepare_data()\n",
    "    model = get_base_model(trainX, trainy)\n",
    "\n",
    "    # Evaluate the base model\n",
    "    scores = dict()\n",
    "    evaluate_model(-1, model, trainX, testX, trainy, testy)\n",
    "\n",
    "    # add layers and evaluate the updated model\n",
    "    n_layers = 14\n",
    "    for i in range(n_layers):\n",
    "        model = add_layer(model, trainX, trainy)\n",
    "        evaluate_model(i, model, trainX, testX, trainy, testy)\n",
    "\n",
    "    columns = ['# layers', 'train_acc', 'test_acc', 'train_loss', 'test_loss']\n",
    "\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    for i in range(0, len(stats)):\n",
    "        df = df.append(stats[i], ignore_index=True)\n",
    "    print(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}