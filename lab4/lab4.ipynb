{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 8.7081 - accuracy: 0.5794 - val_loss: 0.8242 - val_accuracy: 0.6102\n",
      "Epoch 2/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7519 - accuracy: 0.6198 - val_loss: 0.6915 - val_accuracy: 0.6378\n",
      "Epoch 3/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.6406 - val_loss: 0.6725 - val_accuracy: 0.6063\n",
      "Epoch 4/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6797 - val_loss: 0.6348 - val_accuracy: 0.6457\n",
      "Epoch 5/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6602 - val_loss: 0.7033 - val_accuracy: 0.6260\n",
      "Epoch 6/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6641 - val_loss: 0.6055 - val_accuracy: 0.6772\n",
      "Epoch 7/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.6615 - val_loss: 0.6253 - val_accuracy: 0.6654\n",
      "Epoch 8/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.6549 - val_loss: 0.5943 - val_accuracy: 0.6654\n",
      "Epoch 9/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5981 - accuracy: 0.6901 - val_loss: 0.6132 - val_accuracy: 0.6732\n",
      "Epoch 10/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.6797 - val_loss: 0.5840 - val_accuracy: 0.6890\n",
      "Epoch 11/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.7201 - val_loss: 0.6130 - val_accuracy: 0.6772\n",
      "Epoch 12/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6953 - val_loss: 0.6303 - val_accuracy: 0.6457\n",
      "Epoch 13/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5936 - accuracy: 0.6732 - val_loss: 0.6075 - val_accuracy: 0.6693\n",
      "Epoch 14/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5986 - accuracy: 0.6784 - val_loss: 0.6369 - val_accuracy: 0.6457\n",
      "Epoch 15/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6008 - accuracy: 0.6888 - val_loss: 0.6012 - val_accuracy: 0.6732\n",
      "Epoch 16/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5914 - accuracy: 0.7018 - val_loss: 0.6186 - val_accuracy: 0.6929\n",
      "Epoch 17/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6953 - val_loss: 0.6084 - val_accuracy: 0.6772\n",
      "Epoch 18/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6888 - val_loss: 0.5928 - val_accuracy: 0.6614\n",
      "Epoch 19/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.6927 - val_loss: 0.5810 - val_accuracy: 0.6811\n",
      "Epoch 20/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7018 - val_loss: 0.6009 - val_accuracy: 0.6772\n",
      "Epoch 21/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.7031 - val_loss: 0.5644 - val_accuracy: 0.7087\n",
      "Epoch 22/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7240 - val_loss: 0.6322 - val_accuracy: 0.6457\n",
      "Epoch 23/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5763 - accuracy: 0.6888 - val_loss: 0.5696 - val_accuracy: 0.7283\n",
      "Epoch 24/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.7031 - val_loss: 0.5969 - val_accuracy: 0.6732\n",
      "Epoch 25/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.7083 - val_loss: 0.6210 - val_accuracy: 0.6693\n",
      "Epoch 26/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7044 - val_loss: 0.5788 - val_accuracy: 0.6811\n",
      "Epoch 27/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5630 - accuracy: 0.7305 - val_loss: 0.5574 - val_accuracy: 0.7244\n",
      "Epoch 28/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5615 - accuracy: 0.7031 - val_loss: 0.5625 - val_accuracy: 0.6929\n",
      "Epoch 29/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.7201 - val_loss: 0.5661 - val_accuracy: 0.6811\n",
      "Epoch 30/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.7279 - val_loss: 0.5602 - val_accuracy: 0.6850\n",
      "Epoch 31/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5834 - accuracy: 0.6914 - val_loss: 0.5803 - val_accuracy: 0.6811\n",
      "Epoch 32/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7096 - val_loss: 0.5748 - val_accuracy: 0.6575\n",
      "Epoch 33/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5537 - accuracy: 0.7161 - val_loss: 0.5727 - val_accuracy: 0.7008\n",
      "Epoch 34/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5460 - accuracy: 0.7188 - val_loss: 0.5837 - val_accuracy: 0.6575\n",
      "Epoch 35/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.7070 - val_loss: 0.5527 - val_accuracy: 0.7165\n",
      "Epoch 36/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.7409 - val_loss: 0.5459 - val_accuracy: 0.7126\n",
      "Epoch 37/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7305 - val_loss: 0.5654 - val_accuracy: 0.7087\n",
      "Epoch 38/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7122 - val_loss: 0.6502 - val_accuracy: 0.6614\n",
      "Epoch 39/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7305 - val_loss: 0.5384 - val_accuracy: 0.7402\n",
      "Epoch 40/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7240 - val_loss: 0.5711 - val_accuracy: 0.7126\n",
      "Epoch 41/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7214 - val_loss: 0.5309 - val_accuracy: 0.7165\n",
      "Epoch 42/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5242 - accuracy: 0.7344 - val_loss: 0.5380 - val_accuracy: 0.7480\n",
      "Epoch 43/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5333 - accuracy: 0.7435 - val_loss: 0.5315 - val_accuracy: 0.7283\n",
      "Epoch 44/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5242 - accuracy: 0.7318 - val_loss: 0.5601 - val_accuracy: 0.7047\n",
      "Epoch 45/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.7135 - val_loss: 0.5418 - val_accuracy: 0.6969\n",
      "Epoch 46/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.7370 - val_loss: 0.5393 - val_accuracy: 0.7205\n",
      "Epoch 47/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.7070 - val_loss: 0.5301 - val_accuracy: 0.7441\n",
      "Epoch 48/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5285 - accuracy: 0.7318 - val_loss: 0.5577 - val_accuracy: 0.6929\n",
      "Epoch 49/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5400 - accuracy: 0.7279 - val_loss: 0.5337 - val_accuracy: 0.7047\n",
      "Epoch 50/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7201 - val_loss: 0.5406 - val_accuracy: 0.6929\n",
      "Epoch 51/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5203 - accuracy: 0.7539 - val_loss: 0.5225 - val_accuracy: 0.7480\n",
      "Epoch 52/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7539 - val_loss: 0.4913 - val_accuracy: 0.7598\n",
      "Epoch 53/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5194 - accuracy: 0.7370 - val_loss: 0.5485 - val_accuracy: 0.6811\n",
      "Epoch 54/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7396 - val_loss: 0.5279 - val_accuracy: 0.7283\n",
      "Epoch 55/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5009 - accuracy: 0.7435 - val_loss: 0.5114 - val_accuracy: 0.7480\n",
      "Epoch 56/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5222 - accuracy: 0.7370 - val_loss: 0.5030 - val_accuracy: 0.7323\n",
      "Epoch 57/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7604 - val_loss: 0.5082 - val_accuracy: 0.7165\n",
      "Epoch 58/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4936 - accuracy: 0.7526 - val_loss: 0.5205 - val_accuracy: 0.7638\n",
      "Epoch 59/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4992 - accuracy: 0.7552 - val_loss: 0.5104 - val_accuracy: 0.7402\n",
      "Epoch 60/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4968 - accuracy: 0.7630 - val_loss: 0.5907 - val_accuracy: 0.6732\n",
      "Epoch 61/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7422 - val_loss: 0.4972 - val_accuracy: 0.7441\n",
      "Epoch 62/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4791 - accuracy: 0.7591 - val_loss: 0.5081 - val_accuracy: 0.7480\n",
      "Epoch 63/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7500 - val_loss: 0.5366 - val_accuracy: 0.7165\n",
      "Epoch 64/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4977 - accuracy: 0.7513 - val_loss: 0.4995 - val_accuracy: 0.7402\n",
      "Epoch 65/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7617 - val_loss: 0.4759 - val_accuracy: 0.7677\n",
      "Epoch 66/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4904 - accuracy: 0.7344 - val_loss: 0.5180 - val_accuracy: 0.7047\n",
      "Epoch 67/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7552 - val_loss: 0.4853 - val_accuracy: 0.7402\n",
      "Epoch 68/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.7565 - val_loss: 0.4624 - val_accuracy: 0.7520\n",
      "Epoch 69/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7487 - val_loss: 0.5211 - val_accuracy: 0.7283\n",
      "Epoch 70/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4985 - accuracy: 0.7422 - val_loss: 0.5212 - val_accuracy: 0.7205\n",
      "Epoch 71/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7500 - val_loss: 0.4981 - val_accuracy: 0.7480\n",
      "Epoch 72/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7461 - val_loss: 0.4760 - val_accuracy: 0.7953\n",
      "Epoch 73/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4907 - accuracy: 0.7539 - val_loss: 0.4889 - val_accuracy: 0.7638\n",
      "Epoch 74/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7461 - val_loss: 0.4613 - val_accuracy: 0.7480\n",
      "Epoch 75/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4948 - accuracy: 0.7643 - val_loss: 0.5052 - val_accuracy: 0.7559\n",
      "Epoch 76/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7721 - val_loss: 0.4903 - val_accuracy: 0.7677\n",
      "Epoch 77/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7799 - val_loss: 0.4849 - val_accuracy: 0.7677\n",
      "Epoch 78/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7591 - val_loss: 0.4705 - val_accuracy: 0.7598\n",
      "Epoch 79/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7565 - val_loss: 0.4523 - val_accuracy: 0.7559\n",
      "Epoch 80/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7435 - val_loss: 0.4682 - val_accuracy: 0.7717\n",
      "Epoch 81/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7839 - val_loss: 0.4605 - val_accuracy: 0.7480\n",
      "Epoch 82/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7760 - val_loss: 0.4766 - val_accuracy: 0.7638\n",
      "Epoch 83/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7630 - val_loss: 0.4488 - val_accuracy: 0.7756\n",
      "Epoch 84/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7708 - val_loss: 0.5434 - val_accuracy: 0.7126\n",
      "Epoch 85/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7747 - val_loss: 0.4531 - val_accuracy: 0.7638\n",
      "Epoch 86/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4309 - accuracy: 0.7995 - val_loss: 0.4685 - val_accuracy: 0.7598\n",
      "Epoch 87/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.7799 - val_loss: 0.4881 - val_accuracy: 0.7441\n",
      "Epoch 88/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7760 - val_loss: 0.4590 - val_accuracy: 0.7638\n",
      "Epoch 89/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7721 - val_loss: 0.5094 - val_accuracy: 0.7480\n",
      "Epoch 90/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7617 - val_loss: 0.4604 - val_accuracy: 0.7913\n",
      "Epoch 91/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.7747 - val_loss: 0.4546 - val_accuracy: 0.7559\n",
      "Epoch 92/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7513 - val_loss: 0.4497 - val_accuracy: 0.7913\n",
      "Epoch 93/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7695 - val_loss: 0.5046 - val_accuracy: 0.7323\n",
      "Epoch 94/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4822 - accuracy: 0.7617 - val_loss: 0.4374 - val_accuracy: 0.7795\n",
      "Epoch 95/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4393 - accuracy: 0.7826 - val_loss: 0.4596 - val_accuracy: 0.7598\n",
      "Epoch 96/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7956 - val_loss: 0.4544 - val_accuracy: 0.7362\n",
      "Epoch 97/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7943 - val_loss: 0.4621 - val_accuracy: 0.7520\n",
      "Epoch 98/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4402 - accuracy: 0.7930 - val_loss: 0.4571 - val_accuracy: 0.7835\n",
      "Epoch 99/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7786 - val_loss: 0.4341 - val_accuracy: 0.7953\n",
      "Epoch 100/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4278 - accuracy: 0.7826 - val_loss: 0.4536 - val_accuracy: 0.7638\n",
      "Epoch 101/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.7878 - val_loss: 0.4351 - val_accuracy: 0.7953\n",
      "Epoch 102/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.7982 - val_loss: 0.4425 - val_accuracy: 0.7992\n",
      "Epoch 103/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.7786 - val_loss: 0.4849 - val_accuracy: 0.7480\n",
      "Epoch 104/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4303 - accuracy: 0.7734 - val_loss: 0.4765 - val_accuracy: 0.7520\n",
      "Epoch 105/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7773 - val_loss: 0.4296 - val_accuracy: 0.7874\n",
      "Epoch 106/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4255 - accuracy: 0.7891 - val_loss: 0.4305 - val_accuracy: 0.7913\n",
      "Epoch 107/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.7891 - val_loss: 0.4108 - val_accuracy: 0.7913\n",
      "Epoch 108/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4239 - accuracy: 0.7826 - val_loss: 0.4285 - val_accuracy: 0.7992\n",
      "Epoch 109/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.7930 - val_loss: 0.4003 - val_accuracy: 0.7992\n",
      "Epoch 110/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3994 - accuracy: 0.7995 - val_loss: 0.3934 - val_accuracy: 0.8228\n",
      "Epoch 111/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8021 - val_loss: 0.4160 - val_accuracy: 0.7795\n",
      "Epoch 112/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3927 - accuracy: 0.8151 - val_loss: 0.3984 - val_accuracy: 0.8031\n",
      "Epoch 113/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.8034 - val_loss: 0.4102 - val_accuracy: 0.7835\n",
      "Epoch 114/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3884 - accuracy: 0.8060 - val_loss: 0.3946 - val_accuracy: 0.8071\n",
      "Epoch 115/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8008 - val_loss: 0.4286 - val_accuracy: 0.7795\n",
      "Epoch 116/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4321 - accuracy: 0.7995 - val_loss: 0.3816 - val_accuracy: 0.8189\n",
      "Epoch 117/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4116 - accuracy: 0.7982 - val_loss: 0.4207 - val_accuracy: 0.7835\n",
      "Epoch 118/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4030 - accuracy: 0.7995 - val_loss: 0.4570 - val_accuracy: 0.7480\n",
      "Epoch 119/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3975 - accuracy: 0.7995 - val_loss: 0.3697 - val_accuracy: 0.8504\n",
      "Epoch 120/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8203 - val_loss: 0.3833 - val_accuracy: 0.8268\n",
      "Epoch 121/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8073 - val_loss: 0.3927 - val_accuracy: 0.8150\n",
      "Epoch 122/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3676 - accuracy: 0.8320 - val_loss: 0.3702 - val_accuracy: 0.8189\n",
      "Epoch 123/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3861 - accuracy: 0.8073 - val_loss: 0.3912 - val_accuracy: 0.8110\n",
      "Epoch 124/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8216 - val_loss: 0.3946 - val_accuracy: 0.8150\n",
      "Epoch 125/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3918 - accuracy: 0.7969 - val_loss: 0.3838 - val_accuracy: 0.8346\n",
      "Epoch 126/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3993 - accuracy: 0.8086 - val_loss: 0.4220 - val_accuracy: 0.7874\n",
      "Epoch 127/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3894 - accuracy: 0.8190 - val_loss: 0.4217 - val_accuracy: 0.8150\n",
      "Epoch 128/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.8125 - val_loss: 0.4303 - val_accuracy: 0.7913\n",
      "Epoch 129/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8138 - val_loss: 0.4065 - val_accuracy: 0.7913\n",
      "Epoch 130/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8060 - val_loss: 0.3916 - val_accuracy: 0.8071\n",
      "Epoch 131/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4182 - accuracy: 0.8008 - val_loss: 0.4890 - val_accuracy: 0.7520\n",
      "Epoch 132/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3976 - accuracy: 0.8177 - val_loss: 0.3870 - val_accuracy: 0.8228\n",
      "Epoch 133/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3865 - accuracy: 0.8242 - val_loss: 0.4131 - val_accuracy: 0.7992\n",
      "Epoch 134/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3928 - accuracy: 0.7982 - val_loss: 0.3789 - val_accuracy: 0.8110\n",
      "Epoch 135/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8112 - val_loss: 0.3687 - val_accuracy: 0.8228\n",
      "Epoch 136/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3704 - accuracy: 0.8255 - val_loss: 0.3529 - val_accuracy: 0.8346\n",
      "Epoch 137/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8151 - val_loss: 0.3949 - val_accuracy: 0.8189\n",
      "Epoch 138/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3664 - accuracy: 0.8242 - val_loss: 0.3383 - val_accuracy: 0.8386\n",
      "Epoch 139/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8229 - val_loss: 0.3723 - val_accuracy: 0.8189\n",
      "Epoch 140/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8099 - val_loss: 0.3340 - val_accuracy: 0.8543\n",
      "Epoch 141/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3312 - accuracy: 0.8398 - val_loss: 0.3564 - val_accuracy: 0.8071\n",
      "Epoch 142/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8268 - val_loss: 0.3841 - val_accuracy: 0.8228\n",
      "Epoch 143/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8151 - val_loss: 0.3634 - val_accuracy: 0.8268\n",
      "Epoch 144/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3630 - accuracy: 0.8190 - val_loss: 0.3578 - val_accuracy: 0.8189\n",
      "Epoch 145/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3456 - accuracy: 0.8424 - val_loss: 0.3391 - val_accuracy: 0.8583\n",
      "Epoch 146/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8385 - val_loss: 0.3410 - val_accuracy: 0.8465\n",
      "Epoch 147/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.8255 - val_loss: 0.3272 - val_accuracy: 0.8504\n",
      "Epoch 148/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8216 - val_loss: 0.3646 - val_accuracy: 0.8268\n",
      "Epoch 149/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8333 - val_loss: 0.3453 - val_accuracy: 0.8425\n",
      "Epoch 150/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3511 - accuracy: 0.8438 - val_loss: 0.3386 - val_accuracy: 0.8543\n",
      "Epoch 151/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8320 - val_loss: 0.3759 - val_accuracy: 0.8071\n",
      "Epoch 152/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8359 - val_loss: 0.3701 - val_accuracy: 0.8346\n",
      "Epoch 153/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8346 - val_loss: 0.3322 - val_accuracy: 0.8307\n",
      "Epoch 154/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3450 - accuracy: 0.8424 - val_loss: 0.3191 - val_accuracy: 0.8701\n",
      "Epoch 155/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3437 - accuracy: 0.8268 - val_loss: 0.4016 - val_accuracy: 0.7953\n",
      "Epoch 156/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3708 - accuracy: 0.8255 - val_loss: 0.3197 - val_accuracy: 0.8425\n",
      "Epoch 157/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8477 - val_loss: 0.3995 - val_accuracy: 0.7992\n",
      "Epoch 158/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8281 - val_loss: 0.4936 - val_accuracy: 0.7520\n",
      "Epoch 159/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8190 - val_loss: 0.3158 - val_accuracy: 0.8504\n",
      "Epoch 160/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8385 - val_loss: 0.3290 - val_accuracy: 0.8661\n",
      "Epoch 161/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8581 - val_loss: 0.3371 - val_accuracy: 0.8386\n",
      "Epoch 162/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3518 - accuracy: 0.8385 - val_loss: 0.4110 - val_accuracy: 0.7835\n",
      "Epoch 163/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3383 - accuracy: 0.8346 - val_loss: 0.3183 - val_accuracy: 0.8425\n",
      "Epoch 164/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3143 - accuracy: 0.8529 - val_loss: 0.2909 - val_accuracy: 0.8701\n",
      "Epoch 165/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3157 - accuracy: 0.8555 - val_loss: 0.2967 - val_accuracy: 0.8701\n",
      "Epoch 166/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2973 - accuracy: 0.8581 - val_loss: 0.3181 - val_accuracy: 0.8661\n",
      "Epoch 167/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8477 - val_loss: 0.3587 - val_accuracy: 0.8031\n",
      "Epoch 168/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3181 - accuracy: 0.8464 - val_loss: 0.3336 - val_accuracy: 0.8150\n",
      "Epoch 169/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.8542 - val_loss: 0.2882 - val_accuracy: 0.8819\n",
      "Epoch 170/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2986 - accuracy: 0.8607 - val_loss: 0.3063 - val_accuracy: 0.8465\n",
      "Epoch 171/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.8698 - val_loss: 0.2871 - val_accuracy: 0.8740\n",
      "Epoch 172/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8516 - val_loss: 0.3679 - val_accuracy: 0.8189\n",
      "Epoch 173/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3248 - accuracy: 0.8411 - val_loss: 0.3773 - val_accuracy: 0.8228\n",
      "Epoch 174/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8346 - val_loss: 0.2937 - val_accuracy: 0.8701\n",
      "Epoch 175/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3027 - accuracy: 0.8581 - val_loss: 0.2796 - val_accuracy: 0.8740\n",
      "Epoch 176/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3011 - accuracy: 0.8568 - val_loss: 0.2718 - val_accuracy: 0.8661\n",
      "Epoch 177/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2889 - accuracy: 0.8776 - val_loss: 0.2920 - val_accuracy: 0.8740\n",
      "Epoch 178/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3130 - accuracy: 0.8477 - val_loss: 0.3216 - val_accuracy: 0.8504\n",
      "Epoch 179/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3119 - accuracy: 0.8529 - val_loss: 0.3023 - val_accuracy: 0.8425\n",
      "Epoch 180/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2853 - accuracy: 0.8776 - val_loss: 0.3131 - val_accuracy: 0.8268\n",
      "Epoch 181/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2694 - accuracy: 0.8945 - val_loss: 0.2748 - val_accuracy: 0.8780\n",
      "Epoch 182/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2968 - accuracy: 0.8646 - val_loss: 0.3263 - val_accuracy: 0.8346\n",
      "Epoch 183/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2915 - accuracy: 0.8555 - val_loss: 0.3298 - val_accuracy: 0.8386\n",
      "Epoch 184/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2929 - accuracy: 0.8646 - val_loss: 0.3296 - val_accuracy: 0.8504\n",
      "Epoch 185/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.8724 - val_loss: 0.2980 - val_accuracy: 0.8583\n",
      "Epoch 186/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8281 - val_loss: 0.3295 - val_accuracy: 0.8465\n",
      "Epoch 187/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3091 - accuracy: 0.8503 - val_loss: 0.2868 - val_accuracy: 0.8661\n",
      "Epoch 188/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3087 - accuracy: 0.8542 - val_loss: 0.3083 - val_accuracy: 0.8150\n",
      "Epoch 189/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.8737 - val_loss: 0.3415 - val_accuracy: 0.8307\n",
      "Epoch 190/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8451 - val_loss: 0.3225 - val_accuracy: 0.8346\n",
      "Epoch 191/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3265 - accuracy: 0.8542 - val_loss: 0.2473 - val_accuracy: 0.9016\n",
      "Epoch 192/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.8646 - val_loss: 0.3148 - val_accuracy: 0.8583\n",
      "Epoch 193/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8620 - val_loss: 0.2541 - val_accuracy: 0.8819\n",
      "Epoch 194/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2553 - accuracy: 0.8737 - val_loss: 0.2836 - val_accuracy: 0.8701\n",
      "Epoch 195/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2772 - accuracy: 0.8685 - val_loss: 0.2273 - val_accuracy: 0.9094\n",
      "Epoch 196/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2673 - accuracy: 0.8685 - val_loss: 0.2782 - val_accuracy: 0.8583\n",
      "Epoch 197/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2546 - accuracy: 0.8815 - val_loss: 0.2824 - val_accuracy: 0.8622\n",
      "Epoch 198/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.8919 - val_loss: 0.2644 - val_accuracy: 0.8740\n",
      "Epoch 199/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2752 - accuracy: 0.8646 - val_loss: 0.2389 - val_accuracy: 0.8898\n",
      "Epoch 200/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2506 - accuracy: 0.8789 - val_loss: 0.2981 - val_accuracy: 0.8465\n",
      "Epoch 201/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2815 - accuracy: 0.8724 - val_loss: 0.2802 - val_accuracy: 0.8622\n",
      "Epoch 202/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.9010 - val_loss: 0.2358 - val_accuracy: 0.8937\n",
      "Epoch 203/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.8906 - val_loss: 0.2153 - val_accuracy: 0.9094\n",
      "Epoch 204/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.8906 - val_loss: 0.2088 - val_accuracy: 0.9173\n",
      "Epoch 205/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2578 - accuracy: 0.8841 - val_loss: 0.3428 - val_accuracy: 0.8425\n",
      "Epoch 206/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2702 - accuracy: 0.8672 - val_loss: 0.2445 - val_accuracy: 0.8898\n",
      "Epoch 207/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2634 - accuracy: 0.8776 - val_loss: 0.2506 - val_accuracy: 0.8858\n",
      "Epoch 208/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2777 - accuracy: 0.8828 - val_loss: 0.2985 - val_accuracy: 0.8622\n",
      "Epoch 209/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2587 - accuracy: 0.8893 - val_loss: 0.2928 - val_accuracy: 0.8386\n",
      "Epoch 210/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2722 - accuracy: 0.8763 - val_loss: 0.2415 - val_accuracy: 0.8819\n",
      "Epoch 211/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.8854 - val_loss: 0.2463 - val_accuracy: 0.8740\n",
      "Epoch 212/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9049 - val_loss: 0.2441 - val_accuracy: 0.8819\n",
      "Epoch 213/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2432 - accuracy: 0.8971 - val_loss: 0.2412 - val_accuracy: 0.8976\n",
      "Epoch 214/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.8867 - val_loss: 0.2975 - val_accuracy: 0.8543\n",
      "Epoch 215/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.8958 - val_loss: 0.2465 - val_accuracy: 0.8858\n",
      "Epoch 216/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9076 - val_loss: 0.2187 - val_accuracy: 0.9016\n",
      "Epoch 217/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.8997 - val_loss: 0.2066 - val_accuracy: 0.9016\n",
      "Epoch 218/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.9010 - val_loss: 0.3021 - val_accuracy: 0.8465\n",
      "Epoch 219/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2625 - accuracy: 0.8737 - val_loss: 0.2594 - val_accuracy: 0.9016\n",
      "Epoch 220/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.8919 - val_loss: 0.2228 - val_accuracy: 0.8937\n",
      "Epoch 221/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2540 - accuracy: 0.8763 - val_loss: 0.2737 - val_accuracy: 0.8858\n",
      "Epoch 222/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2330 - accuracy: 0.8880 - val_loss: 0.2243 - val_accuracy: 0.8937\n",
      "Epoch 223/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.8997 - val_loss: 0.1923 - val_accuracy: 0.9213\n",
      "Epoch 224/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.9036 - val_loss: 0.2117 - val_accuracy: 0.8976\n",
      "Epoch 225/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.8867 - val_loss: 0.1994 - val_accuracy: 0.9134\n",
      "Epoch 226/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.8997 - val_loss: 0.2281 - val_accuracy: 0.8976\n",
      "Epoch 227/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2341 - accuracy: 0.8919 - val_loss: 0.2181 - val_accuracy: 0.9016\n",
      "Epoch 228/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2095 - accuracy: 0.9167 - val_loss: 0.1994 - val_accuracy: 0.9134\n",
      "Epoch 229/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.8932 - val_loss: 0.2029 - val_accuracy: 0.8976\n",
      "Epoch 230/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2783 - accuracy: 0.8789 - val_loss: 0.2518 - val_accuracy: 0.8661\n",
      "Epoch 231/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.8958 - val_loss: 0.2233 - val_accuracy: 0.8937\n",
      "Epoch 232/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.9089 - val_loss: 0.2168 - val_accuracy: 0.9055\n",
      "Epoch 233/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.9115 - val_loss: 0.1886 - val_accuracy: 0.9134\n",
      "Epoch 234/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.8997 - val_loss: 0.2280 - val_accuracy: 0.9055\n",
      "Epoch 235/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2975 - accuracy: 0.8750 - val_loss: 0.2695 - val_accuracy: 0.8819\n",
      "Epoch 236/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2609 - accuracy: 0.8854 - val_loss: 0.2636 - val_accuracy: 0.8583\n",
      "Epoch 237/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.8971 - val_loss: 0.1792 - val_accuracy: 0.9331\n",
      "Epoch 238/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2094 - accuracy: 0.9049 - val_loss: 0.2058 - val_accuracy: 0.9291\n",
      "Epoch 239/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2076 - accuracy: 0.9049 - val_loss: 0.1633 - val_accuracy: 0.9331\n",
      "Epoch 240/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.9232 - val_loss: 0.1827 - val_accuracy: 0.9331\n",
      "Epoch 241/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2006 - accuracy: 0.9102 - val_loss: 0.2349 - val_accuracy: 0.9094\n",
      "Epoch 242/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2059 - accuracy: 0.9076 - val_loss: 0.1924 - val_accuracy: 0.9213\n",
      "Epoch 243/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.9102 - val_loss: 0.1826 - val_accuracy: 0.9213\n",
      "Epoch 244/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.8789 - val_loss: 0.3629 - val_accuracy: 0.8543\n",
      "Epoch 245/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.8802 - val_loss: 0.1611 - val_accuracy: 0.9370\n",
      "Epoch 246/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.9102 - val_loss: 0.1644 - val_accuracy: 0.9331\n",
      "Epoch 247/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.9115 - val_loss: 0.1772 - val_accuracy: 0.9252\n",
      "Epoch 248/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2109 - accuracy: 0.9154 - val_loss: 0.1906 - val_accuracy: 0.9173\n",
      "Epoch 249/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.9128 - val_loss: 0.2026 - val_accuracy: 0.8937\n",
      "Epoch 250/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.9154 - val_loss: 0.2055 - val_accuracy: 0.8937\n",
      "Epoch 251/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2079 - accuracy: 0.9049 - val_loss: 0.2452 - val_accuracy: 0.8937\n",
      "Epoch 252/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2770 - accuracy: 0.8776 - val_loss: 0.2058 - val_accuracy: 0.9094\n",
      "Epoch 253/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.9115 - val_loss: 0.1640 - val_accuracy: 0.9370\n",
      "Epoch 254/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.9232 - val_loss: 0.1542 - val_accuracy: 0.9409\n",
      "Epoch 255/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1583 - accuracy: 0.9349 - val_loss: 0.1470 - val_accuracy: 0.9449\n",
      "Epoch 256/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.9128 - val_loss: 0.2089 - val_accuracy: 0.9094\n",
      "Epoch 257/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.8958 - val_loss: 0.1555 - val_accuracy: 0.9370\n",
      "Epoch 258/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1588 - accuracy: 0.9375 - val_loss: 0.1768 - val_accuracy: 0.9213\n",
      "Epoch 259/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9271 - val_loss: 0.1833 - val_accuracy: 0.9252\n",
      "Epoch 260/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.9258 - val_loss: 0.1463 - val_accuracy: 0.9252\n",
      "Epoch 261/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1599 - accuracy: 0.9362 - val_loss: 0.1647 - val_accuracy: 0.9213\n",
      "Epoch 262/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.9206 - val_loss: 0.1413 - val_accuracy: 0.9488\n",
      "Epoch 263/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1574 - accuracy: 0.9401 - val_loss: 0.1944 - val_accuracy: 0.8976\n",
      "Epoch 264/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1669 - accuracy: 0.9271 - val_loss: 0.1639 - val_accuracy: 0.9213\n",
      "Epoch 265/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1426 - accuracy: 0.9388 - val_loss: 0.1362 - val_accuracy: 0.9488\n",
      "Epoch 266/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9479 - val_loss: 0.1194 - val_accuracy: 0.9606\n",
      "Epoch 267/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1522 - accuracy: 0.9388 - val_loss: 0.1195 - val_accuracy: 0.9488\n",
      "Epoch 268/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.9154 - val_loss: 0.1638 - val_accuracy: 0.9409\n",
      "Epoch 269/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.9271 - val_loss: 0.1806 - val_accuracy: 0.9094\n",
      "Epoch 270/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1604 - accuracy: 0.9401 - val_loss: 0.1377 - val_accuracy: 0.9488\n",
      "Epoch 271/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1536 - accuracy: 0.9362 - val_loss: 0.1431 - val_accuracy: 0.9488\n",
      "Epoch 272/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1346 - accuracy: 0.9531 - val_loss: 0.1172 - val_accuracy: 0.9488\n",
      "Epoch 273/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1474 - accuracy: 0.9388 - val_loss: 0.1292 - val_accuracy: 0.9488\n",
      "Epoch 274/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1289 - accuracy: 0.9518 - val_loss: 0.1126 - val_accuracy: 0.9685\n",
      "Epoch 275/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9596 - val_loss: 0.1134 - val_accuracy: 0.9567\n",
      "Epoch 276/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9323 - val_loss: 0.1413 - val_accuracy: 0.9409\n",
      "Epoch 277/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1508 - accuracy: 0.9375 - val_loss: 0.1360 - val_accuracy: 0.9409\n",
      "Epoch 278/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9284 - val_loss: 0.1560 - val_accuracy: 0.9409\n",
      "Epoch 279/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9349 - val_loss: 0.1372 - val_accuracy: 0.9528\n",
      "Epoch 280/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1293 - accuracy: 0.9401 - val_loss: 0.1477 - val_accuracy: 0.9370\n",
      "Epoch 281/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1364 - accuracy: 0.9466 - val_loss: 0.0995 - val_accuracy: 0.9646\n",
      "Epoch 282/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9414 - val_loss: 0.1113 - val_accuracy: 0.9606\n",
      "Epoch 283/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1358 - accuracy: 0.9427 - val_loss: 0.1156 - val_accuracy: 0.9606\n",
      "Epoch 284/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2087 - accuracy: 0.9076 - val_loss: 0.3533 - val_accuracy: 0.8701\n",
      "Epoch 285/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.9154 - val_loss: 0.1714 - val_accuracy: 0.8976\n",
      "Epoch 286/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.9219 - val_loss: 0.2402 - val_accuracy: 0.9094\n",
      "Epoch 287/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.9115 - val_loss: 0.1096 - val_accuracy: 0.9764\n",
      "Epoch 288/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1447 - accuracy: 0.9492 - val_loss: 0.1357 - val_accuracy: 0.9409\n",
      "Epoch 289/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1457 - accuracy: 0.9284 - val_loss: 0.1223 - val_accuracy: 0.9370\n",
      "Epoch 290/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1278 - accuracy: 0.9531 - val_loss: 0.1136 - val_accuracy: 0.9567\n",
      "Epoch 291/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1466 - accuracy: 0.9414 - val_loss: 0.1480 - val_accuracy: 0.9173\n",
      "Epoch 292/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9414 - val_loss: 0.1211 - val_accuracy: 0.9646\n",
      "Epoch 293/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9427 - val_loss: 0.1038 - val_accuracy: 0.9528\n",
      "Epoch 294/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9557 - val_loss: 0.1324 - val_accuracy: 0.9528\n",
      "Epoch 295/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1100 - accuracy: 0.9583 - val_loss: 0.1792 - val_accuracy: 0.9134\n",
      "Epoch 296/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9401 - val_loss: 0.1124 - val_accuracy: 0.9606\n",
      "Epoch 297/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9518 - val_loss: 0.1228 - val_accuracy: 0.9488\n",
      "Epoch 298/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1262 - accuracy: 0.9440 - val_loss: 0.1163 - val_accuracy: 0.9488\n",
      "Epoch 299/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1242 - accuracy: 0.9570 - val_loss: 0.1302 - val_accuracy: 0.9449\n",
      "Epoch 300/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9596 - val_loss: 0.1095 - val_accuracy: 0.9606\n",
      "Epoch 301/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1114 - accuracy: 0.9583 - val_loss: 0.1084 - val_accuracy: 0.9724\n",
      "Epoch 302/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1418 - accuracy: 0.9401 - val_loss: 0.1312 - val_accuracy: 0.9449\n",
      "Epoch 303/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9557 - val_loss: 0.0923 - val_accuracy: 0.9724\n",
      "Epoch 304/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0996 - accuracy: 0.9648 - val_loss: 0.1162 - val_accuracy: 0.9488\n",
      "Epoch 305/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9583 - val_loss: 0.0980 - val_accuracy: 0.9646\n",
      "Epoch 306/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1422 - accuracy: 0.9453 - val_loss: 0.1020 - val_accuracy: 0.9685\n",
      "Epoch 307/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1441 - accuracy: 0.9401 - val_loss: 0.1315 - val_accuracy: 0.9567\n",
      "Epoch 308/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1436 - accuracy: 0.9440 - val_loss: 0.1266 - val_accuracy: 0.9488\n",
      "Epoch 309/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1396 - accuracy: 0.9427 - val_loss: 0.1656 - val_accuracy: 0.9252\n",
      "Epoch 310/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9596 - val_loss: 0.1143 - val_accuracy: 0.9370\n",
      "Epoch 311/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9609 - val_loss: 0.1508 - val_accuracy: 0.9449\n",
      "Epoch 312/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2395 - accuracy: 0.8932 - val_loss: 0.2833 - val_accuracy: 0.8661\n",
      "Epoch 313/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1614 - accuracy: 0.9336 - val_loss: 0.1018 - val_accuracy: 0.9567\n",
      "Epoch 314/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.9583 - val_loss: 0.1375 - val_accuracy: 0.9331\n",
      "Epoch 315/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1261 - accuracy: 0.9570 - val_loss: 0.1125 - val_accuracy: 0.9567\n",
      "Epoch 316/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9505 - val_loss: 0.0817 - val_accuracy: 0.9803\n",
      "Epoch 317/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1054 - accuracy: 0.9557 - val_loss: 0.1069 - val_accuracy: 0.9528\n",
      "Epoch 318/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9583 - val_loss: 0.2672 - val_accuracy: 0.9094\n",
      "Epoch 319/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9180 - val_loss: 0.1690 - val_accuracy: 0.9370\n",
      "Epoch 320/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1382 - accuracy: 0.9349 - val_loss: 0.1401 - val_accuracy: 0.9291\n",
      "Epoch 321/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9531 - val_loss: 0.0744 - val_accuracy: 0.9764\n",
      "Epoch 322/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9596 - val_loss: 0.0876 - val_accuracy: 0.9685\n",
      "Epoch 323/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0929 - accuracy: 0.9701 - val_loss: 0.0865 - val_accuracy: 0.9764\n",
      "Epoch 324/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0824 - accuracy: 0.9753 - val_loss: 0.0720 - val_accuracy: 0.9764\n",
      "Epoch 325/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9740 - val_loss: 0.1134 - val_accuracy: 0.9488\n",
      "Epoch 326/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.9479 - val_loss: 0.1217 - val_accuracy: 0.9567\n",
      "Epoch 327/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0873 - accuracy: 0.9622 - val_loss: 0.0858 - val_accuracy: 0.9685\n",
      "Epoch 328/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.9349 - val_loss: 0.1793 - val_accuracy: 0.9094\n",
      "Epoch 329/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.9049 - val_loss: 0.1453 - val_accuracy: 0.9409\n",
      "Epoch 330/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1671 - accuracy: 0.9349 - val_loss: 0.1271 - val_accuracy: 0.9646\n",
      "Epoch 331/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9570 - val_loss: 0.1170 - val_accuracy: 0.9567\n",
      "Epoch 332/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9583 - val_loss: 0.1017 - val_accuracy: 0.9606\n",
      "Epoch 333/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1020 - accuracy: 0.9583 - val_loss: 0.1097 - val_accuracy: 0.9528\n",
      "Epoch 334/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1079 - accuracy: 0.9557 - val_loss: 0.0874 - val_accuracy: 0.9724\n",
      "Epoch 335/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9661 - val_loss: 0.0768 - val_accuracy: 0.9764\n",
      "Epoch 336/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.9648 - val_loss: 0.0769 - val_accuracy: 0.9764\n",
      "Epoch 337/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9674 - val_loss: 0.0819 - val_accuracy: 0.9646\n",
      "Epoch 338/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9727 - val_loss: 0.0742 - val_accuracy: 0.9803\n",
      "Epoch 339/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0883 - accuracy: 0.9648 - val_loss: 0.1876 - val_accuracy: 0.9094\n",
      "Epoch 340/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1145 - accuracy: 0.9466 - val_loss: 0.1463 - val_accuracy: 0.9449\n",
      "Epoch 341/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.8919 - val_loss: 0.2602 - val_accuracy: 0.8976\n",
      "Epoch 342/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2908 - accuracy: 0.8841 - val_loss: 0.3142 - val_accuracy: 0.8583\n",
      "Epoch 343/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8672 - val_loss: 0.2545 - val_accuracy: 0.8976\n",
      "Epoch 344/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9323 - val_loss: 0.1660 - val_accuracy: 0.9331\n",
      "Epoch 345/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9518 - val_loss: 0.1027 - val_accuracy: 0.9646\n",
      "Epoch 346/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0901 - accuracy: 0.9622 - val_loss: 0.0755 - val_accuracy: 0.9843\n",
      "Epoch 347/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.9740 - val_loss: 0.0803 - val_accuracy: 0.9764\n",
      "Epoch 348/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0839 - accuracy: 0.9753 - val_loss: 0.0962 - val_accuracy: 0.9646\n",
      "Epoch 349/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9701 - val_loss: 0.0809 - val_accuracy: 0.9724\n",
      "Epoch 350/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9753 - val_loss: 0.0834 - val_accuracy: 0.9646\n",
      "Epoch 351/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9779 - val_loss: 0.0828 - val_accuracy: 0.9685\n",
      "Epoch 352/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9427 - val_loss: 0.1330 - val_accuracy: 0.9449\n",
      "Epoch 353/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.9440 - val_loss: 0.1524 - val_accuracy: 0.9291\n",
      "Epoch 354/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9557 - val_loss: 0.0942 - val_accuracy: 0.9606\n",
      "Epoch 355/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9505 - val_loss: 0.0964 - val_accuracy: 0.9567\n",
      "Epoch 356/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1036 - accuracy: 0.9544 - val_loss: 0.1250 - val_accuracy: 0.9488\n",
      "Epoch 357/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1061 - accuracy: 0.9544 - val_loss: 0.0630 - val_accuracy: 0.9764\n",
      "Epoch 358/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9388 - val_loss: 0.1216 - val_accuracy: 0.9528\n",
      "Epoch 359/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1357 - accuracy: 0.9479 - val_loss: 0.0844 - val_accuracy: 0.9764\n",
      "Epoch 360/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1060 - accuracy: 0.9544 - val_loss: 0.0612 - val_accuracy: 0.9803\n",
      "Epoch 361/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.1044 - accuracy: 0.9518 - val_loss: 0.0983 - val_accuracy: 0.9567\n",
      "Epoch 362/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.9753 - val_loss: 0.0575 - val_accuracy: 0.9882\n",
      "Epoch 363/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9805 - val_loss: 0.0691 - val_accuracy: 0.9724\n",
      "Epoch 364/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9779 - val_loss: 0.0592 - val_accuracy: 0.9803\n",
      "Epoch 365/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9740 - val_loss: 0.0688 - val_accuracy: 0.9764\n",
      "Epoch 366/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0619 - accuracy: 0.9831 - val_loss: 0.0829 - val_accuracy: 0.9646\n",
      "Epoch 367/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9805 - val_loss: 0.0480 - val_accuracy: 0.9882\n",
      "Epoch 368/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9844 - val_loss: 0.0932 - val_accuracy: 0.9528\n",
      "Epoch 369/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0607 - accuracy: 0.9818 - val_loss: 0.0697 - val_accuracy: 0.9724\n",
      "Epoch 370/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0725 - accuracy: 0.9766 - val_loss: 0.1140 - val_accuracy: 0.9449\n",
      "Epoch 371/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 0.9674 - val_loss: 0.1056 - val_accuracy: 0.9646\n",
      "Epoch 372/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9727 - val_loss: 0.0747 - val_accuracy: 0.9606\n",
      "Epoch 373/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 0.9805 - val_loss: 0.0696 - val_accuracy: 0.9724\n",
      "Epoch 374/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9818 - val_loss: 0.0420 - val_accuracy: 0.9882\n",
      "Epoch 375/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9844 - val_loss: 0.0488 - val_accuracy: 0.9843\n",
      "Epoch 376/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9766 - val_loss: 0.0656 - val_accuracy: 0.9803\n",
      "Epoch 377/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0667 - accuracy: 0.9753 - val_loss: 0.0450 - val_accuracy: 0.9961\n",
      "Epoch 378/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9831 - val_loss: 0.0459 - val_accuracy: 0.9882\n",
      "Epoch 379/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9779 - val_loss: 0.0476 - val_accuracy: 0.9961\n",
      "Epoch 380/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9818 - val_loss: 0.0434 - val_accuracy: 0.9882\n",
      "Epoch 381/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9883 - val_loss: 0.0460 - val_accuracy: 0.9882\n",
      "Epoch 382/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0548 - accuracy: 0.9805 - val_loss: 0.0666 - val_accuracy: 0.9764\n",
      "Epoch 383/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9779 - val_loss: 0.0544 - val_accuracy: 0.9882\n",
      "Epoch 384/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9648 - val_loss: 0.0656 - val_accuracy: 0.9803\n",
      "Epoch 385/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9766 - val_loss: 0.0522 - val_accuracy: 0.9803\n",
      "Epoch 386/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0538 - accuracy: 0.9792 - val_loss: 0.0599 - val_accuracy: 0.9764\n",
      "Epoch 387/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9857 - val_loss: 0.0462 - val_accuracy: 0.9843\n",
      "Epoch 388/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9844 - val_loss: 0.0436 - val_accuracy: 0.9921\n",
      "Epoch 389/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9753 - val_loss: 0.0737 - val_accuracy: 0.9724\n",
      "Epoch 390/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9674 - val_loss: 0.0852 - val_accuracy: 0.9606\n",
      "Epoch 391/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9792 - val_loss: 0.0462 - val_accuracy: 0.9843\n",
      "Epoch 392/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9792 - val_loss: 0.0908 - val_accuracy: 0.9606\n",
      "Epoch 393/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9753 - val_loss: 0.0715 - val_accuracy: 0.9685\n",
      "Epoch 394/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9701 - val_loss: 0.0660 - val_accuracy: 0.9724\n",
      "Epoch 395/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9857 - val_loss: 0.0448 - val_accuracy: 0.9882\n",
      "Epoch 396/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9896 - val_loss: 0.0469 - val_accuracy: 0.9843\n",
      "Epoch 397/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9831 - val_loss: 0.0377 - val_accuracy: 0.9882\n",
      "Epoch 398/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0422 - accuracy: 0.9883 - val_loss: 0.0461 - val_accuracy: 0.9882\n",
      "Epoch 399/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9883 - val_loss: 0.0302 - val_accuracy: 1.0000\n",
      "Epoch 400/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.0391 - accuracy: 0.9896 - val_loss: 0.0587 - val_accuracy: 0.9724\n",
      "Test Accuracy: 0.972\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1008x504 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    decay       acc     loss\n",
      "0  0.0001  0.972441  0.05867\n"
     ]
    }
   ],
   "source": [
    "# first neural network with keras tutorial\n",
    "from    keras.models import Sequential\n",
    "from    keras.layers import Dense\n",
    "import  pandas as pd\n",
    "from    sklearn.model_selection import train_test_split\n",
    "import  matplotlib.pyplot  as plt\n",
    "PATH  = \"../datasets/\"\n",
    "import tensorflow as tf\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv(PATH + 'diabetes.csv', sep=',')\n",
    "\n",
    "# split into input (X) and output (y) variables\n",
    "X = df[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI',\n",
    "        'DiabetesPedigreeFunction',    'Age']]\n",
    "y = df[['Outcome']]\n",
    "\n",
    "# Split into train and test data sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33)\n",
    "\n",
    "resultList = []\n",
    "def buildModel(decayRate):\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(230, input_dim=8, activation='relu',\n",
    "                    kernel_initializer='he_normal'))\n",
    "\n",
    "    NUM_LAYERS = 7\n",
    "    for i in range(0, NUM_LAYERS-1):\n",
    "        model.add(Dense(230, activation='relu',\n",
    "                        kernel_initializer='he_normal'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = tf.keras.optimizers.SGD(\n",
    "        learning_rate=0.0005, momentum=0.9, name=\"SGD\", decay=decayRate\n",
    "    )\n",
    "\n",
    "    # Compile the keras model.\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Fit the keras model on the dataset.\n",
    "    history = model.fit(X, y, epochs=400, batch_size=10,\n",
    "                        validation_data=(X_test, y_test))\n",
    "\n",
    "    # Evaluate the model.\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    resultList.append({'loss':loss, 'acc':acc, 'decay':decayRate})\n",
    "    print('Test Accuracy: %.3f' % acc)\n",
    "    return history\n",
    "\n",
    "def showLoss(history, rates):\n",
    "    # Get training and test loss histories\n",
    "    training_loss       = history.history['loss']\n",
    "    validation_loss     = history.history['val_loss']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history for training data.\n",
    "    actualLabel = str(rates)\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    # View loss on unseen data.\n",
    "    plt.plot(epoch_count, validation_loss, label=actualLabel)\n",
    "    plt.legend()\n",
    "\n",
    "def showAccuracy(history, rates):\n",
    "    # Get training and test loss histories\n",
    "    training_loss       = history.history['accuracy']\n",
    "    validation_loss     = history.history['val_accuracy']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    actualLabel = str(rates)\n",
    "    # View loss on unseen data.\n",
    "    plt.plot(epoch_count, validation_loss, label=actualLabel)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    decayRates = [0.0001]\n",
    "    plt.subplots(nrows=1, ncols=2,  figsize=(14,7))\n",
    "\n",
    "    for i in range(0, len(decayRates)):\n",
    "        history = buildModel(decayRates[i])\n",
    "        showLoss(history, decayRates[i])\n",
    "        showAccuracy(history, decayRates[i])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(columns=['decay', 'acc', 'loss'])\n",
    "    for result in resultList:\n",
    "        df = df.append(result, ignore_index=True)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/16 [>.............................] - ETA: 2s - loss: 5.2030 - accuracy: 0.6250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanleung/miniforge3/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 7.4086 - accuracy: 0.5120 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 2/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 3/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 4/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 5/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 6/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 7/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 8/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 9/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 10/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 11/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 12/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 13/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 14/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 15/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 16/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 17/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 18/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 19/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 20/500\n",
      "16/16 [==============================] - 0s 999us/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 21/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 22/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 23/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 24/500\n",
      "16/16 [==============================] - 0s 991us/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 25/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 26/500\n",
      "16/16 [==============================] - 0s 998us/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 27/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 28/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 29/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 30/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 31/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 32/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 33/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 34/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 35/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 36/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 37/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 38/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 39/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 40/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 41/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 42/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 43/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 44/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 45/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 46/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 47/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 48/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 49/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 50/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 51/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 52/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 53/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 54/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 55/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 56/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 57/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 58/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 59/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 60/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 61/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 62/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 63/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 64/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 65/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 66/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 67/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 68/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 69/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 70/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 71/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 72/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 73/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 74/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 75/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 76/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 77/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 78/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 79/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 80/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 81/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 82/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 83/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 84/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 85/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 86/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 87/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 88/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 89/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 90/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 91/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 92/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 93/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 94/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 95/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 96/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 97/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 98/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 99/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 100/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 101/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 102/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 103/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 104/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 105/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 106/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 107/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 108/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 109/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 110/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 111/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 112/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 113/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 114/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 115/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 116/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 117/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 118/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 119/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 120/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 121/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 122/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 123/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 124/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 125/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 126/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 127/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 128/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 129/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 130/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 131/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 132/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 133/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 134/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 135/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 136/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 137/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 138/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 139/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 140/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 141/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 142/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 143/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 144/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 145/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 146/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 147/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 148/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 149/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 150/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 151/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 152/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 153/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 154/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 155/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 156/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 157/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 158/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 159/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 160/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 161/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 162/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 163/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 164/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 165/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 166/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 167/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 168/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 169/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 170/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 171/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 172/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 173/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 174/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 175/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 176/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 177/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 178/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 179/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 180/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 181/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 182/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 183/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 184/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 185/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 186/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 187/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 188/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 189/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 190/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 191/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 192/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 193/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 194/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 195/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 196/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 197/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 198/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 199/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 200/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 201/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 202/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 203/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 204/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 205/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 206/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 207/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 208/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 209/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 210/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 211/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 212/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 213/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 214/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 215/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 216/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 217/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 218/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 219/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 220/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 221/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 222/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 223/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 224/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 225/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 226/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 227/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 228/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 229/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 230/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 231/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 232/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 233/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 234/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 235/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 236/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 237/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 238/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 239/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 240/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 241/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 242/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 243/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 244/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 245/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 246/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 247/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 248/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 249/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 250/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 251/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 252/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 253/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 254/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 255/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 256/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 257/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 258/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 259/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 260/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 261/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 262/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 263/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 264/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 265/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 266/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 267/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 268/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 269/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 270/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 271/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 272/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 273/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 274/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 275/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 276/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 277/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 278/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 279/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 280/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 281/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 282/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 283/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 284/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 285/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 286/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 287/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 288/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 289/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 290/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 291/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 292/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 293/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 294/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 295/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 296/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 297/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 298/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 299/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 300/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 301/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 302/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 303/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 304/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 305/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 306/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 307/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 308/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 309/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 310/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 311/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 312/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 313/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 314/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 315/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 316/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 317/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 318/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 319/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 320/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 321/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 322/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 323/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 324/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 325/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 326/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 327/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 328/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 329/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 330/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 331/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 332/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 333/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 334/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 335/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 336/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 337/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 338/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 339/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 340/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 341/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 342/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 343/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 344/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 345/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 346/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 347/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 348/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 349/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 350/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 351/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 352/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 353/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 354/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 355/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 356/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 357/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 358/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 359/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 360/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 361/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 362/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 363/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 364/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 365/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 366/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 367/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 368/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 369/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 370/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 371/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 372/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 373/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 374/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 375/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 376/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 377/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 378/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 379/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 380/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 381/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 382/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 383/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 384/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 385/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 386/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 387/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 388/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 389/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 390/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 391/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 392/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 393/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 394/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 395/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 396/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 397/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 398/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 399/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 400/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 401/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 402/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 403/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 404/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 405/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 406/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 407/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 408/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 409/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 410/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 411/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 412/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 413/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 414/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 415/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 416/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 417/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 418/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 419/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 420/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 421/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 422/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 423/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 424/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 425/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 426/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 427/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 428/500\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 429/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 430/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 431/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 432/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 433/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 434/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 435/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 436/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 437/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 438/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 439/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 440/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 441/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 442/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 443/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 444/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 445/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 446/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 447/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 448/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 449/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 450/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 451/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 452/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 453/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 454/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 455/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 456/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 457/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 458/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 459/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 460/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 461/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 462/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 463/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 464/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 465/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 466/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 467/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 468/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 469/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 470/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 471/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 472/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 473/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 474/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 475/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 476/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 477/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 478/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 479/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 480/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 481/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 482/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 483/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 484/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 485/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 486/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 487/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 488/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 489/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 490/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 491/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 492/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 493/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 494/500\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 495/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 496/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 497/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 498/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 499/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Epoch 500/500\n",
      "16/16 [==============================] - 0s 1ms/step - loss: 7.6856 - accuracy: 0.4960 - val_loss: 7.5636 - val_accuracy: 0.5040\n",
      "Train Accuracy: 0.496, Test Accuracy: 0.504\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# deeper mlp with tanh for the two circles classification problem\n",
    "from sklearn.datasets       import make_circles\n",
    "from sklearn.preprocessing  import MinMaxScaler\n",
    "from keras.layers           import Dense\n",
    "from keras.models           import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "import matplotlib.pyplot    as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # Generate 2d classification dataset.\n",
    "    X, y    = make_circles(n_samples=1000, noise=0.1, random_state=1)\n",
    "    scaler  = MinMaxScaler(feature_range=(-1, 1))\n",
    "    X       = scaler.fit_transform(X)\n",
    "\n",
    "    # split into train and test\n",
    "    n_train = 500\n",
    "    trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "    trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "    # Define the model.\n",
    "    model = Sequential()\n",
    "    init = 'he_uniform'\n",
    "    activation = 'relu'\n",
    "    model.add(Dense(5, input_dim=2, activation=activation, kernel_initializer=init))\n",
    "    model.add(Dense(5, activation=activation, kernel_initializer=init))\n",
    "    model.add(Dense(5, activation=activation, kernel_initializer=init))\n",
    "    model.add(Dense(5, activation=activation, kernel_initializer=init))\n",
    "    model.add(Dense(5, activation=activation, kernel_initializer=init))\n",
    "    model.add(Dense(1, activation=activation, kernel_initializer=init))\n",
    "\n",
    "    # Compile model.\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    # fit model\n",
    "    history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=500, verbose=1)\n",
    "\n",
    "    # evaluate the model\n",
    "    _, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "    _, test_acc = model.evaluate(testX, testy, verbose=0)\n",
    "    print('Train Accuracy: %.3f, Test Accuracy: %.3f' % (train_acc, test_acc))\n",
    "\n",
    "    # Plot loss learning curves.\n",
    "    plt.subplot(211)\n",
    "    plt.title('Loss', pad=-40)\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy learning curves.\n",
    "    plt.subplot(212)\n",
    "    plt.title('Accuracy', pad=-40)\n",
    "    plt.plot(history.history['accuracy'], label='train')\n",
    "    plt.plot(history.history['val_accuracy'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 2/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 3/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6746 - val_accuracy: 0.6614\n",
      "Epoch 4/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6591 - accuracy: 0.6510 - val_loss: 0.6554 - val_accuracy: 0.6614\n",
      "Epoch 5/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6568 - accuracy: 0.6510 - val_loss: 0.6450 - val_accuracy: 0.6614\n",
      "Epoch 6/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.6510 - val_loss: 0.6506 - val_accuracy: 0.6614\n",
      "Epoch 7/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 8/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6587 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 9/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.6172 - val_loss: 0.6596 - val_accuracy: 0.6614\n",
      "Epoch 10/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6510 - val_loss: 0.6438 - val_accuracy: 0.6614\n",
      "Epoch 11/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 12/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 13/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 14/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6447 - val_accuracy: 0.6614\n",
      "Epoch 15/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6539 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 16/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 17/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 18/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 19/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6468 - val_accuracy: 0.6614\n",
      "Epoch 20/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6601 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 21/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 22/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6510 - val_loss: 0.6530 - val_accuracy: 0.6614\n",
      "Epoch 23/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6542 - val_accuracy: 0.6614\n",
      "Epoch 24/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 25/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6510 - val_loss: 0.6503 - val_accuracy: 0.6614\n",
      "Epoch 26/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6510 - val_loss: 0.6461 - val_accuracy: 0.6614\n",
      "Epoch 27/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 28/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6498 - val_accuracy: 0.6614\n",
      "Epoch 29/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 30/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6468 - val_accuracy: 0.6614\n",
      "Epoch 31/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 32/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6539 - val_accuracy: 0.6614\n",
      "Epoch 33/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6510 - val_loss: 0.6426 - val_accuracy: 0.6614\n",
      "Epoch 34/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 35/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6510 - val_loss: 0.6441 - val_accuracy: 0.6614\n",
      "Epoch 36/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 37/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6525 - val_accuracy: 0.6614\n",
      "Epoch 38/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 39/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6510 - val_loss: 0.6473 - val_accuracy: 0.6614\n",
      "Epoch 40/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 41/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 42/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 43/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6510 - val_loss: 0.6417 - val_accuracy: 0.6614\n",
      "Epoch 44/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 45/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 46/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.6510 - val_loss: 0.6552 - val_accuracy: 0.6614\n",
      "Epoch 47/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6510 - val_loss: 0.6443 - val_accuracy: 0.6614\n",
      "Epoch 48/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 49/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 50/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6510 - val_loss: 0.6624 - val_accuracy: 0.6614\n",
      "Epoch 51/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6510 - val_loss: 0.6513 - val_accuracy: 0.6614\n",
      "Epoch 52/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6570 - accuracy: 0.6510 - val_loss: 0.6597 - val_accuracy: 0.6614\n",
      "Epoch 53/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6510 - val_loss: 0.6478 - val_accuracy: 0.6614\n",
      "Epoch 54/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 55/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 56/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 57/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 58/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6510 - val_loss: 0.6485 - val_accuracy: 0.6614\n",
      "Epoch 59/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.6510 - val_loss: 0.6508 - val_accuracy: 0.6614\n",
      "Epoch 60/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6578 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 61/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6510 - val_loss: 0.6430 - val_accuracy: 0.6614\n",
      "Epoch 62/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 63/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6510 - val_loss: 0.6459 - val_accuracy: 0.6614\n",
      "Epoch 64/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 65/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 66/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6614\n",
      "Epoch 67/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6510 - val_loss: 0.6434 - val_accuracy: 0.6614\n",
      "Epoch 68/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6510 - val_loss: 0.6548 - val_accuracy: 0.6614\n",
      "Epoch 69/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 70/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6479 - val_accuracy: 0.6614\n",
      "Epoch 71/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6510 - val_loss: 0.6480 - val_accuracy: 0.6614\n",
      "Epoch 72/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6510 - val_loss: 0.6668 - val_accuracy: 0.6614\n",
      "Epoch 73/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6510 - val_loss: 0.6468 - val_accuracy: 0.6614\n",
      "Epoch 74/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6510 - val_loss: 0.6747 - val_accuracy: 0.6614\n",
      "Epoch 75/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.6510 - val_loss: 0.6453 - val_accuracy: 0.6614\n",
      "Epoch 76/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6510 - val_loss: 0.6487 - val_accuracy: 0.6614\n",
      "Epoch 77/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 78/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 79/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 80/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 81/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6637 - accuracy: 0.6510 - val_loss: 0.6457 - val_accuracy: 0.6614\n",
      "Epoch 82/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.6510 - val_loss: 0.6440 - val_accuracy: 0.6614\n",
      "Epoch 83/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 84/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 85/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6510 - val_loss: 0.6627 - val_accuracy: 0.6614\n",
      "Epoch 86/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.6510 - val_loss: 0.6417 - val_accuracy: 0.6614\n",
      "Epoch 87/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6614\n",
      "Epoch 88/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 89/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 90/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 91/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6328 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 92/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6451 - val_accuracy: 0.6614\n",
      "Epoch 93/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 94/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6428 - val_accuracy: 0.6614\n",
      "Epoch 95/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6614\n",
      "Epoch 96/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6510 - val_loss: 0.6459 - val_accuracy: 0.6614\n",
      "Epoch 97/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6421 - val_accuracy: 0.6614\n",
      "Epoch 98/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6510 - val_loss: 0.6489 - val_accuracy: 0.6614\n",
      "Epoch 99/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6406 - val_loss: 0.6444 - val_accuracy: 0.6614\n",
      "Epoch 100/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 101/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6510 - val_loss: 0.6699 - val_accuracy: 0.6614\n",
      "Epoch 102/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6688 - accuracy: 0.6250 - val_loss: 0.6495 - val_accuracy: 0.6614\n",
      "Epoch 103/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6510 - val_loss: 0.6424 - val_accuracy: 0.6614\n",
      "Epoch 104/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.6510 - val_loss: 0.6524 - val_accuracy: 0.6614\n",
      "Epoch 105/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6510 - val_loss: 0.6498 - val_accuracy: 0.6614\n",
      "Epoch 106/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6510 - val_loss: 0.6467 - val_accuracy: 0.6614\n",
      "Epoch 107/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510 - val_loss: 0.6708 - val_accuracy: 0.6614\n",
      "Epoch 108/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 109/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6433 - val_accuracy: 0.6614\n",
      "Epoch 110/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6510 - val_loss: 0.6570 - val_accuracy: 0.6614\n",
      "Epoch 111/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6510 - val_loss: 0.6495 - val_accuracy: 0.6614\n",
      "Epoch 112/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.6354 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 113/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6442 - val_accuracy: 0.6614\n",
      "Epoch 114/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 115/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6497 - val_accuracy: 0.6614\n",
      "Epoch 116/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6510 - val_loss: 0.6440 - val_accuracy: 0.6614\n",
      "Epoch 117/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6510 - val_loss: 0.6424 - val_accuracy: 0.6614\n",
      "Epoch 118/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 119/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6510 - val_loss: 0.6495 - val_accuracy: 0.6614\n",
      "Epoch 120/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.6510 - val_loss: 0.6518 - val_accuracy: 0.6614\n",
      "Epoch 121/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6510 - val_loss: 0.6442 - val_accuracy: 0.6614\n",
      "Epoch 122/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 123/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6510 - val_loss: 0.6442 - val_accuracy: 0.6614\n",
      "Epoch 124/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 125/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6510 - val_loss: 0.6489 - val_accuracy: 0.6614\n",
      "Epoch 126/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6510 - val_loss: 0.6631 - val_accuracy: 0.6614\n",
      "Epoch 127/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6510 - val_loss: 0.6484 - val_accuracy: 0.6614\n",
      "Epoch 128/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6510 - val_loss: 0.6443 - val_accuracy: 0.6614\n",
      "Epoch 129/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 130/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 131/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 132/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 133/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 134/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6614\n",
      "Epoch 135/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 136/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 137/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6614\n",
      "Epoch 138/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6447 - val_accuracy: 0.6614\n",
      "Epoch 139/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6510 - val_loss: 0.6446 - val_accuracy: 0.6614\n",
      "Epoch 140/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6510 - val_loss: 0.6417 - val_accuracy: 0.6614\n",
      "Epoch 141/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6510 - val_loss: 0.6619 - val_accuracy: 0.6614\n",
      "Epoch 142/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6510 - val_loss: 0.6435 - val_accuracy: 0.6614\n",
      "Epoch 143/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 144/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 145/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6510 - val_loss: 0.6746 - val_accuracy: 0.6614\n",
      "Epoch 146/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 147/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6510 - val_loss: 0.6438 - val_accuracy: 0.6614\n",
      "Epoch 148/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 149/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 150/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6510 - val_loss: 0.6605 - val_accuracy: 0.6614\n",
      "Epoch 151/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 152/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6510 - val_loss: 0.6433 - val_accuracy: 0.6614\n",
      "Epoch 153/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6448 - val_accuracy: 0.6614\n",
      "Epoch 154/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6510 - val_loss: 0.6571 - val_accuracy: 0.6614\n",
      "Epoch 155/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6548 - accuracy: 0.6510 - val_loss: 0.6542 - val_accuracy: 0.6614\n",
      "Epoch 156/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.6510 - val_loss: 0.6490 - val_accuracy: 0.6614\n",
      "Epoch 157/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.6510 - val_loss: 0.6454 - val_accuracy: 0.6614\n",
      "Epoch 158/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6510 - val_loss: 0.6541 - val_accuracy: 0.6614\n",
      "Epoch 159/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6518 - accuracy: 0.6510 - val_loss: 0.6602 - val_accuracy: 0.6614\n",
      "Epoch 160/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6601 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 161/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6510 - val_loss: 0.6532 - val_accuracy: 0.6614\n",
      "Epoch 162/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6590 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 163/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6636 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 164/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6510 - val_loss: 0.6473 - val_accuracy: 0.6614\n",
      "Epoch 165/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 166/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6510 - val_loss: 0.6439 - val_accuracy: 0.6614\n",
      "Epoch 167/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 168/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6510 - val_loss: 0.6436 - val_accuracy: 0.6614\n",
      "Epoch 169/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6510 - val_loss: 0.6612 - val_accuracy: 0.6614\n",
      "Epoch 170/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6354 - val_loss: 0.6658 - val_accuracy: 0.6614\n",
      "Epoch 171/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.6510 - val_loss: 0.6556 - val_accuracy: 0.6614\n",
      "Epoch 172/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6487 - val_accuracy: 0.6614\n",
      "Epoch 173/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 174/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 175/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6510 - val_loss: 0.6451 - val_accuracy: 0.6614\n",
      "Epoch 176/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 177/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6621 - val_accuracy: 0.6614\n",
      "Epoch 178/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 179/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 180/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6510 - val_loss: 0.6442 - val_accuracy: 0.6614\n",
      "Epoch 181/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6510 - val_loss: 0.6706 - val_accuracy: 0.6614\n",
      "Epoch 182/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6569 - val_accuracy: 0.6614\n",
      "Epoch 183/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.6042 - val_loss: 0.6571 - val_accuracy: 0.6614\n",
      "Epoch 184/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 185/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 186/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6510 - val_loss: 0.6499 - val_accuracy: 0.6614\n",
      "Epoch 187/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6510 - val_loss: 0.6507 - val_accuracy: 0.6614\n",
      "Epoch 188/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 189/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 190/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 191/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 192/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 193/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 194/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6510 - val_loss: 0.6437 - val_accuracy: 0.6614\n",
      "Epoch 195/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 196/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6670 - val_accuracy: 0.6614\n",
      "Epoch 197/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 198/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 199/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 200/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6510 - val_accuracy: 0.6614\n",
      "Epoch 201/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6510 - val_loss: 0.6436 - val_accuracy: 0.6614\n",
      "Epoch 202/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 203/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 204/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 205/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6621 - accuracy: 0.6510 - val_loss: 0.6475 - val_accuracy: 0.6614\n",
      "Epoch 206/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6510 - val_loss: 0.6545 - val_accuracy: 0.6614\n",
      "Epoch 207/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6521 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6614\n",
      "Epoch 208/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6525 - val_accuracy: 0.6614\n",
      "Epoch 209/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 210/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6510 - val_loss: 0.6499 - val_accuracy: 0.6614\n",
      "Epoch 211/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6510 - val_loss: 0.6526 - val_accuracy: 0.6614\n",
      "Epoch 212/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6510 - val_loss: 0.6415 - val_accuracy: 0.6614\n",
      "Epoch 213/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.6510 - val_loss: 0.6848 - val_accuracy: 0.6614\n",
      "Epoch 214/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6614\n",
      "Epoch 215/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6510 - val_loss: 0.6469 - val_accuracy: 0.6614\n",
      "Epoch 216/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 217/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6510 - val_loss: 0.6431 - val_accuracy: 0.6614\n",
      "Epoch 218/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6510 - val_loss: 0.6608 - val_accuracy: 0.6614\n",
      "Epoch 219/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6510 - val_loss: 0.6417 - val_accuracy: 0.6614\n",
      "Epoch 220/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6445 - val_accuracy: 0.6614\n",
      "Epoch 221/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 222/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 223/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6499 - val_accuracy: 0.6614\n",
      "Epoch 224/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6510 - val_loss: 0.6907 - val_accuracy: 0.6614\n",
      "Epoch 225/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.6510 - val_loss: 0.6533 - val_accuracy: 0.6614\n",
      "Epoch 226/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6510 - val_loss: 0.6616 - val_accuracy: 0.6614\n",
      "Epoch 227/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6647 - accuracy: 0.6510 - val_loss: 0.6454 - val_accuracy: 0.6614\n",
      "Epoch 228/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 229/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 230/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 231/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 232/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6510 - val_loss: 0.6460 - val_accuracy: 0.6614\n",
      "Epoch 233/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6579 - accuracy: 0.6510 - val_loss: 0.6415 - val_accuracy: 0.6614\n",
      "Epoch 234/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6250 - val_loss: 0.6443 - val_accuracy: 0.6614\n",
      "Epoch 235/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6582 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 236/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6484 - val_accuracy: 0.6614\n",
      "Epoch 237/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6510 - val_accuracy: 0.6614\n",
      "Epoch 238/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6510 - val_loss: 0.6440 - val_accuracy: 0.6614\n",
      "Epoch 239/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 240/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6614\n",
      "Epoch 241/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6510 - val_loss: 0.6454 - val_accuracy: 0.6614\n",
      "Epoch 242/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6614\n",
      "Epoch 243/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 244/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6510 - val_loss: 0.6568 - val_accuracy: 0.6614\n",
      "Epoch 245/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6510 - val_loss: 0.6592 - val_accuracy: 0.6614\n",
      "Epoch 246/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.6510 - val_loss: 0.6423 - val_accuracy: 0.6614\n",
      "Epoch 247/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 248/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.6510 - val_loss: 0.6583 - val_accuracy: 0.6614\n",
      "Epoch 249/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6458 - val_loss: 0.7087 - val_accuracy: 0.3386\n",
      "Epoch 250/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6432 - val_loss: 0.6494 - val_accuracy: 0.6614\n",
      "Epoch 251/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 252/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6614\n",
      "Epoch 253/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.6302 - val_loss: 0.6435 - val_accuracy: 0.6614\n",
      "Epoch 254/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6510 - val_loss: 0.6446 - val_accuracy: 0.6614\n",
      "Epoch 255/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6510 - val_loss: 0.6487 - val_accuracy: 0.6614\n",
      "Epoch 256/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6510 - val_loss: 0.6494 - val_accuracy: 0.6614\n",
      "Epoch 257/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 258/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 259/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6510 - val_loss: 0.6423 - val_accuracy: 0.6614\n",
      "Epoch 260/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 261/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6591 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 262/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 263/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6510 - val_loss: 0.6428 - val_accuracy: 0.6614\n",
      "Epoch 264/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 265/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6558 - accuracy: 0.6510 - val_loss: 0.6458 - val_accuracy: 0.6614\n",
      "Epoch 266/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 267/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 268/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6427 - val_accuracy: 0.6614\n",
      "Epoch 269/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6510 - val_loss: 0.6595 - val_accuracy: 0.6614\n",
      "Epoch 270/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6510 - val_loss: 0.6435 - val_accuracy: 0.6614\n",
      "Epoch 271/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 272/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 273/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6510 - val_loss: 0.6779 - val_accuracy: 0.6614\n",
      "Epoch 274/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6566 - val_accuracy: 0.6614\n",
      "Epoch 275/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6510 - val_loss: 0.6415 - val_accuracy: 0.6614\n",
      "Epoch 276/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.6510 - val_loss: 0.6459 - val_accuracy: 0.6614\n",
      "Epoch 277/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6510 - val_loss: 0.6430 - val_accuracy: 0.6614\n",
      "Epoch 278/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 279/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6632 - val_accuracy: 0.6614\n",
      "Epoch 280/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6406 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 281/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6510 - val_loss: 0.6454 - val_accuracy: 0.6614\n",
      "Epoch 282/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6510 - val_loss: 0.6508 - val_accuracy: 0.6614\n",
      "Epoch 283/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6502 - val_accuracy: 0.6614\n",
      "Epoch 284/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 285/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.6406 - val_loss: 0.7019 - val_accuracy: 0.3386\n",
      "Epoch 286/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6432 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 287/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6426 - val_accuracy: 0.6614\n",
      "Epoch 288/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6510 - val_loss: 0.6548 - val_accuracy: 0.6614\n",
      "Epoch 289/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.6328 - val_loss: 0.6842 - val_accuracy: 0.6614\n",
      "Epoch 290/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6618 - accuracy: 0.6510 - val_loss: 0.6457 - val_accuracy: 0.6614\n",
      "Epoch 291/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6510 - val_loss: 0.6456 - val_accuracy: 0.6614\n",
      "Epoch 292/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6423 - val_accuracy: 0.6614\n",
      "Epoch 293/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6614\n",
      "Epoch 294/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.6510 - val_loss: 0.6439 - val_accuracy: 0.6614\n",
      "Epoch 295/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.6510 - val_loss: 0.6417 - val_accuracy: 0.6614\n",
      "Epoch 296/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6434 - val_accuracy: 0.6614\n",
      "Epoch 297/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 298/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6510 - val_loss: 0.6426 - val_accuracy: 0.6614\n",
      "Epoch 299/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6499 - val_accuracy: 0.6614\n",
      "Epoch 300/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 301/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6474 - val_accuracy: 0.6614\n",
      "Epoch 302/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6427 - val_accuracy: 0.6614\n",
      "Epoch 303/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 304/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6510 - val_loss: 0.6543 - val_accuracy: 0.6614\n",
      "Epoch 305/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6584 - accuracy: 0.6328 - val_loss: 0.6466 - val_accuracy: 0.6614\n",
      "Epoch 306/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6510 - val_loss: 0.6730 - val_accuracy: 0.6614\n",
      "Epoch 307/400\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 308/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 309/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6525 - accuracy: 0.6510 - val_loss: 0.6454 - val_accuracy: 0.6614\n",
      "Epoch 310/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6441 - val_accuracy: 0.6614\n",
      "Epoch 311/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6510 - val_loss: 0.6727 - val_accuracy: 0.6614\n",
      "Epoch 312/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6510 - val_loss: 0.6415 - val_accuracy: 0.6614\n",
      "Epoch 313/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 314/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 315/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6466 - val_accuracy: 0.6614\n",
      "Epoch 316/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6589 - accuracy: 0.6510 - val_loss: 0.6449 - val_accuracy: 0.6614\n",
      "Epoch 317/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 318/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6510 - val_loss: 0.6457 - val_accuracy: 0.6614\n",
      "Epoch 319/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6510 - val_loss: 0.6501 - val_accuracy: 0.6614\n",
      "Epoch 320/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 321/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 322/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 323/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6510 - val_loss: 0.6829 - val_accuracy: 0.6614\n",
      "Epoch 324/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6510 - val_loss: 0.6482 - val_accuracy: 0.6614\n",
      "Epoch 325/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6510 - val_loss: 0.6435 - val_accuracy: 0.6614\n",
      "Epoch 326/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 327/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6510 - val_loss: 0.6488 - val_accuracy: 0.6614\n",
      "Epoch 328/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6510 - val_loss: 0.6517 - val_accuracy: 0.6614\n",
      "Epoch 329/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 330/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6510 - val_loss: 0.6417 - val_accuracy: 0.6614\n",
      "Epoch 331/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 332/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6581 - accuracy: 0.6510 - val_loss: 0.6419 - val_accuracy: 0.6614\n",
      "Epoch 333/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 334/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 335/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6541 - accuracy: 0.6510 - val_loss: 0.6442 - val_accuracy: 0.6614\n",
      "Epoch 336/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6434 - val_accuracy: 0.6614\n",
      "Epoch 337/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 338/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6510 - val_loss: 0.6434 - val_accuracy: 0.6614\n",
      "Epoch 339/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6510 - val_loss: 0.6443 - val_accuracy: 0.6614\n",
      "Epoch 340/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6510 - val_loss: 0.6524 - val_accuracy: 0.6614\n",
      "Epoch 341/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6437 - val_accuracy: 0.6614\n",
      "Epoch 342/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 343/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.6510 - val_loss: 0.6613 - val_accuracy: 0.6614\n",
      "Epoch 344/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6510 - val_loss: 0.6423 - val_accuracy: 0.6614\n",
      "Epoch 345/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6302 - val_loss: 0.6512 - val_accuracy: 0.6614\n",
      "Epoch 346/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.6510 - val_loss: 0.6419 - val_accuracy: 0.6614\n",
      "Epoch 347/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 348/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6510 - val_loss: 0.6515 - val_accuracy: 0.6614\n",
      "Epoch 349/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 350/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6552 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 351/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6533 - accuracy: 0.6510 - val_loss: 0.6464 - val_accuracy: 0.6614\n",
      "Epoch 352/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6510 - val_loss: 0.6446 - val_accuracy: 0.6614\n",
      "Epoch 353/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 354/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6549 - accuracy: 0.6380 - val_loss: 0.6497 - val_accuracy: 0.6614\n",
      "Epoch 355/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6434 - val_accuracy: 0.6614\n",
      "Epoch 356/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 357/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6510 - val_loss: 0.6461 - val_accuracy: 0.6614\n",
      "Epoch 358/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.6510 - val_loss: 0.6458 - val_accuracy: 0.6614\n",
      "Epoch 359/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6510 - val_loss: 0.6423 - val_accuracy: 0.6614\n",
      "Epoch 360/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6489 - val_accuracy: 0.6614\n",
      "Epoch 361/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6602 - accuracy: 0.6510 - val_loss: 0.6484 - val_accuracy: 0.6614\n",
      "Epoch 362/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 363/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6510 - val_loss: 0.6428 - val_accuracy: 0.6614\n",
      "Epoch 364/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6510 - val_loss: 0.6473 - val_accuracy: 0.6614\n",
      "Epoch 365/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.6250 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 366/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6633 - val_accuracy: 0.6614\n",
      "Epoch 367/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6510 - val_loss: 0.6446 - val_accuracy: 0.6614\n",
      "Epoch 368/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 369/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 370/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6442 - val_accuracy: 0.6614\n",
      "Epoch 371/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6440 - val_accuracy: 0.6614\n",
      "Epoch 372/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6458 - val_loss: 0.6871 - val_accuracy: 0.6614\n",
      "Epoch 373/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6560 - accuracy: 0.6510 - val_loss: 0.6498 - val_accuracy: 0.6614\n",
      "Epoch 374/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6600 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 375/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 376/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6510 - val_loss: 0.6437 - val_accuracy: 0.6614\n",
      "Epoch 377/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 378/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6510 - val_loss: 0.6430 - val_accuracy: 0.6614\n",
      "Epoch 379/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6578 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 380/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 381/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6566 - val_accuracy: 0.6614\n",
      "Epoch 382/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 383/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6510 - val_loss: 0.6439 - val_accuracy: 0.6614\n",
      "Epoch 384/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.6510 - val_loss: 0.6643 - val_accuracy: 0.6614\n",
      "Epoch 385/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.6510 - val_loss: 0.6462 - val_accuracy: 0.6614\n",
      "Epoch 386/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 387/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.6510 - val_loss: 0.6452 - val_accuracy: 0.6614\n",
      "Epoch 388/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6510 - val_loss: 0.6438 - val_accuracy: 0.6614\n",
      "Epoch 389/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6480 - val_accuracy: 0.6614\n",
      "Epoch 390/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6565 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6614\n",
      "Epoch 391/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6510 - val_loss: 0.6510 - val_accuracy: 0.6614\n",
      "Epoch 392/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6510 - val_loss: 0.6898 - val_accuracy: 0.6614\n",
      "Epoch 393/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6630 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 394/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6427 - val_accuracy: 0.6614\n",
      "Epoch 395/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 396/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6276 - val_loss: 0.6487 - val_accuracy: 0.6614\n",
      "Epoch 397/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 398/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6489 - val_accuracy: 0.6614\n",
      "Epoch 399/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 400/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6607 - accuracy: 0.6354 - val_loss: 0.6445 - val_accuracy: 0.6614\n",
      "Test Accuracy: 0.661\n",
      "Epoch 1/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 2/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 3/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.6510 - val_loss: 0.6465 - val_accuracy: 0.6614\n",
      "Epoch 4/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6510 - val_loss: 0.6421 - val_accuracy: 0.6614\n",
      "Epoch 5/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 6/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 7/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 8/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6433 - val_accuracy: 0.6614\n",
      "Epoch 9/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 10/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 11/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6510 - val_loss: 0.6428 - val_accuracy: 0.6614\n",
      "Epoch 12/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6594 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 13/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 14/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 15/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6510 - val_loss: 0.6415 - val_accuracy: 0.6614\n",
      "Epoch 16/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 17/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 18/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 19/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 20/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 21/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6447 - val_accuracy: 0.6614\n",
      "Epoch 22/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 23/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 24/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6569 - val_accuracy: 0.6614\n",
      "Epoch 25/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6538 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 26/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6539 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 27/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6425 - val_accuracy: 0.6614\n",
      "Epoch 28/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 29/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6466 - val_accuracy: 0.6614\n",
      "Epoch 30/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 31/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 32/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 33/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6614\n",
      "Epoch 34/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 35/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6444 - val_accuracy: 0.6614\n",
      "Epoch 36/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 37/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 38/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 39/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 40/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 41/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 42/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 43/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 44/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 45/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 46/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 47/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 48/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 49/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 50/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 51/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 52/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 53/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 54/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 55/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 56/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 57/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 58/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6424 - val_accuracy: 0.6614\n",
      "Epoch 59/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 60/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6424 - val_accuracy: 0.6614\n",
      "Epoch 61/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 62/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 63/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 64/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 65/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 66/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 67/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 68/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 69/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 70/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 71/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 72/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 73/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 74/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 75/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 76/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 77/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6467 - accuracy: 0.6510 - val_loss: 0.6443 - val_accuracy: 0.6614\n",
      "Epoch 78/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 79/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 80/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 81/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 82/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 83/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 84/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 85/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 86/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 87/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 88/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 89/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 90/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 91/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 92/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 93/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 94/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 95/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 96/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 97/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 98/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 99/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 100/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 101/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 102/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 103/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 104/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 105/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 106/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 107/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 108/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 109/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 110/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 111/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 112/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 113/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 114/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 115/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 116/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 117/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 118/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 119/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 120/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 121/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 122/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 123/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 124/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 125/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 126/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 127/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 128/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 129/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 130/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 131/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 132/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 133/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 134/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 135/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 136/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 137/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 138/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 139/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 140/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 141/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 142/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 143/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 144/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 145/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 146/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 147/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 148/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 149/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 150/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 151/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 152/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 153/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 154/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 155/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 156/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 157/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 158/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 159/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 160/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 161/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 162/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 163/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 164/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 165/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 166/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 167/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 168/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 169/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 170/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 171/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 172/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 173/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 174/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 175/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 176/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 177/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 178/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 179/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 180/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 181/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 182/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 183/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 184/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 185/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 186/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 187/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 188/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 189/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 190/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 191/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 192/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 193/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 194/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 195/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 196/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 197/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 198/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 199/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 200/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 201/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 202/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 203/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 204/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 205/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 206/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 207/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 208/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 209/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 210/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 211/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 212/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 213/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 214/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 215/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 216/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 217/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 218/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 219/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 220/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 221/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 222/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 223/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 224/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 225/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 226/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 227/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 228/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 229/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 230/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 231/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 232/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 233/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 234/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 235/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 236/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 237/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 238/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 239/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 240/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 241/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 242/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 243/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 244/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 245/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 246/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 247/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 248/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 249/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 250/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 251/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 252/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 253/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 254/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 255/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 256/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 257/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 258/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 259/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 260/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 261/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 262/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 263/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 264/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 265/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 266/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 267/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 268/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 269/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 270/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 271/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 272/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 273/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 274/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 275/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 276/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 277/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 278/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 279/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 280/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 281/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 282/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 283/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 284/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 285/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 286/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 287/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 288/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 289/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 290/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 291/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 292/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 293/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 294/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 295/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 296/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 297/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 298/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 299/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 300/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 301/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 302/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 303/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 304/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 305/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 306/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 307/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 308/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 309/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 310/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 311/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 312/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 313/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 314/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 315/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 316/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 317/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 318/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 319/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 320/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 321/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 322/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 323/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 324/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 325/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 326/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 327/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 328/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 329/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 330/400\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 331/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 332/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 333/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 334/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 335/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 336/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 337/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 338/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 339/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 340/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 341/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 342/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 343/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 344/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 345/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 346/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 347/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 348/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 349/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 350/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 351/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 352/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 353/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 354/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 355/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 356/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 357/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 358/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 359/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 360/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 361/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 362/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 363/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 364/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 365/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 366/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 367/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 368/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 369/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 370/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 371/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 372/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 373/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 374/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 375/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 376/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 377/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 378/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 379/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 380/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 381/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 382/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 383/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 384/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 385/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 386/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 387/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 388/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 389/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 390/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 391/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 392/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 393/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 394/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 395/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 396/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 397/400\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 398/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 399/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 400/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Test Accuracy: 0.661\n",
      "Epoch 1/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.6146 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 2/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6510 - val_loss: 0.6446 - val_accuracy: 0.6614\n",
      "Epoch 3/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6510 - val_loss: 0.6470 - val_accuracy: 0.6614\n",
      "Epoch 4/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6449 - val_accuracy: 0.6614\n",
      "Epoch 5/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6586 - accuracy: 0.6510 - val_loss: 0.6606 - val_accuracy: 0.6614\n",
      "Epoch 6/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 7/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 8/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 9/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6591 - accuracy: 0.6510 - val_loss: 0.6549 - val_accuracy: 0.6614\n",
      "Epoch 10/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6510 - val_loss: 0.6455 - val_accuracy: 0.6614\n",
      "Epoch 11/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 12/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 13/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6476 - val_accuracy: 0.6614\n",
      "Epoch 14/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6510 - val_loss: 0.6614 - val_accuracy: 0.6614\n",
      "Epoch 15/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 16/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6453 - val_accuracy: 0.6614\n",
      "Epoch 17/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6549 - val_accuracy: 0.6614\n",
      "Epoch 18/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6510 - val_loss: 0.6424 - val_accuracy: 0.6614\n",
      "Epoch 19/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 20/400\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6540 - val_accuracy: 0.6614\n",
      "Epoch 21/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6510 - val_loss: 0.6458 - val_accuracy: 0.6614\n",
      "Epoch 22/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 23/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 24/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 25/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 26/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6510 - val_loss: 0.6426 - val_accuracy: 0.6614\n",
      "Epoch 27/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6510 - val_loss: 0.6430 - val_accuracy: 0.6614\n",
      "Epoch 28/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 29/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 30/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 31/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 32/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6524 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 33/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 34/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 35/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6466 - val_accuracy: 0.6614\n",
      "Epoch 36/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 37/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 38/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6510 - val_loss: 0.6434 - val_accuracy: 0.6614\n",
      "Epoch 39/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 40/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6516 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 41/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6462 - accuracy: 0.6510 - val_loss: 0.6438 - val_accuracy: 0.6614\n",
      "Epoch 42/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6543 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 43/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 44/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6534 - accuracy: 0.6510 - val_loss: 0.6522 - val_accuracy: 0.6614\n",
      "Epoch 45/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6510 - val_loss: 0.6426 - val_accuracy: 0.6614\n",
      "Epoch 46/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6442 - val_accuracy: 0.6614\n",
      "Epoch 47/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 48/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 49/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 50/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 51/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 52/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 53/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 54/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 55/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 56/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 57/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6443 - val_accuracy: 0.6614\n",
      "Epoch 58/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6458 - val_accuracy: 0.6614\n",
      "Epoch 59/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 60/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6510 - val_loss: 0.6430 - val_accuracy: 0.6614\n",
      "Epoch 61/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 62/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 63/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 64/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 65/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 66/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 67/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 68/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 69/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 70/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6427 - val_accuracy: 0.6614\n",
      "Epoch 71/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 72/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6415 - val_accuracy: 0.6614\n",
      "Epoch 73/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6463 - val_accuracy: 0.6614\n",
      "Epoch 74/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 75/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 76/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6415 - val_accuracy: 0.6614\n",
      "Epoch 77/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6423 - val_accuracy: 0.6614\n",
      "Epoch 78/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 79/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 80/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 81/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 82/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 83/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 84/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 85/400\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 86/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6433 - val_accuracy: 0.6614\n",
      "Epoch 87/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 88/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 89/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 90/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 91/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 92/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 93/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 94/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6464 - accuracy: 0.6510 - val_loss: 0.6465 - val_accuracy: 0.6614\n",
      "Epoch 95/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 96/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 97/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6415 - val_accuracy: 0.6614\n",
      "Epoch 98/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 99/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 100/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 101/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 102/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6433 - val_accuracy: 0.6614\n",
      "Epoch 103/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6421 - val_accuracy: 0.6614\n",
      "Epoch 104/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6433 - val_accuracy: 0.6614\n",
      "Epoch 105/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 106/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 107/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 108/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 109/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 110/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 111/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 112/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6426 - val_accuracy: 0.6614\n",
      "Epoch 113/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 114/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 115/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 116/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 117/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 118/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 119/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 120/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 121/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 122/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 123/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 124/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 125/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 126/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 127/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 128/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 129/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 130/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 131/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 132/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 133/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 134/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 135/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 136/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 137/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 138/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 139/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 140/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 141/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 142/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 143/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 144/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 145/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 146/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 147/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 148/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 149/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 150/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 151/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 152/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 153/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 154/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 155/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 156/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 157/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 158/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 159/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6419 - val_accuracy: 0.6614\n",
      "Epoch 160/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 161/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 162/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 163/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 164/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6424 - val_accuracy: 0.6614\n",
      "Epoch 165/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 166/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 167/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 168/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 169/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 170/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 171/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 172/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 173/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 174/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 175/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 176/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 177/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 178/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 179/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 180/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 181/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 182/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 183/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 184/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 185/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 186/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 187/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 188/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 189/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 190/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 191/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 192/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 193/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 194/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 195/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 196/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 197/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 198/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 199/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 200/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 201/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 202/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 203/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 204/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 205/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 206/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 207/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 208/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 209/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 210/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 211/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 212/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 213/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 214/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 215/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 216/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 217/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 218/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 219/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 220/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 221/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 222/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6417 - val_accuracy: 0.6614\n",
      "Epoch 223/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 224/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 225/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 226/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 227/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 228/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 229/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 230/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 231/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 232/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 233/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 234/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 235/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 236/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 237/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 238/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 239/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 240/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 241/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 242/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 243/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 244/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 245/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 246/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6421 - val_accuracy: 0.6614\n",
      "Epoch 247/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 248/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 249/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 250/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 251/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 252/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 253/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 254/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 255/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 256/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 257/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 258/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 259/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 260/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 261/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 262/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 263/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 264/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 265/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 266/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 267/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 268/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 269/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 270/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 271/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 272/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 273/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 274/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 275/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 276/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 277/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 278/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 279/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 280/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 281/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 282/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 283/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 284/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 285/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 286/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 287/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 288/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 289/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 290/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 291/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 292/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 293/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 294/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 295/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 296/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 297/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 298/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 299/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 300/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 301/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 302/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 303/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 304/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 305/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 306/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 307/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 308/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 309/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 310/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 311/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 312/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 313/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 314/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 315/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 316/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 317/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 318/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 319/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 320/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 321/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 322/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 323/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 324/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 325/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 326/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 327/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 328/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 329/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 330/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 331/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 332/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 333/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 334/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 335/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 336/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 337/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 338/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 339/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 340/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 341/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 342/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 343/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 344/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 345/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 346/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 347/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 348/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 349/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 350/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 351/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 352/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 353/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 354/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 355/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 356/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 357/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 358/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 359/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 360/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 361/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 362/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 363/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 364/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 365/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 366/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 367/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 368/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 369/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 370/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 371/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 372/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 373/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 374/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 375/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 376/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 377/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 378/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 379/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 380/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 381/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 382/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 383/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 384/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 385/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 386/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 387/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 388/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 389/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 390/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 391/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 392/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 393/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 394/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 395/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 396/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 397/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 398/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 399/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 400/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Test Accuracy: 0.661\n",
      "Epoch 1/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6458 - val_loss: 0.6476 - val_accuracy: 0.6614\n",
      "Epoch 2/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 3/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.6510 - val_loss: 0.6464 - val_accuracy: 0.6614\n",
      "Epoch 4/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6443 - val_accuracy: 0.6614\n",
      "Epoch 5/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 6/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6707 - val_accuracy: 0.6614\n",
      "Epoch 7/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.6510 - val_loss: 0.6665 - val_accuracy: 0.6614\n",
      "Epoch 8/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6528 - accuracy: 0.6510 - val_loss: 0.6489 - val_accuracy: 0.6614\n",
      "Epoch 9/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 10/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6593 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 11/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 12/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6530 - accuracy: 0.6510 - val_loss: 0.6469 - val_accuracy: 0.6614\n",
      "Epoch 13/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6471 - val_accuracy: 0.6614\n",
      "Epoch 14/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6510 - val_loss: 0.6600 - val_accuracy: 0.6614\n",
      "Epoch 15/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 16/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 17/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6510 - val_loss: 0.6445 - val_accuracy: 0.6614\n",
      "Epoch 18/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6517 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 19/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6459 - val_accuracy: 0.6614\n",
      "Epoch 20/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 21/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6546 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6614\n",
      "Epoch 22/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 23/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 24/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6494 - val_accuracy: 0.6614\n",
      "Epoch 25/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6510 - val_loss: 0.6551 - val_accuracy: 0.6614\n",
      "Epoch 26/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6510 - val_loss: 0.6466 - val_accuracy: 0.6614\n",
      "Epoch 27/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6510 - val_loss: 0.6553 - val_accuracy: 0.6614\n",
      "Epoch 28/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6510 - val_loss: 0.6448 - val_accuracy: 0.6614\n",
      "Epoch 29/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6510 - val_loss: 0.6441 - val_accuracy: 0.6614\n",
      "Epoch 30/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6434 - val_accuracy: 0.6614\n",
      "Epoch 31/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 32/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6479 - val_accuracy: 0.6614\n",
      "Epoch 33/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 34/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6510 - val_loss: 0.6539 - val_accuracy: 0.6614\n",
      "Epoch 35/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 36/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6419 - val_accuracy: 0.6614\n",
      "Epoch 37/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6653 - val_accuracy: 0.6614\n",
      "Epoch 38/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6651 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 39/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 40/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 41/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.6510 - val_loss: 0.6442 - val_accuracy: 0.6614\n",
      "Epoch 42/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 43/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6510 - val_loss: 0.6459 - val_accuracy: 0.6614\n",
      "Epoch 44/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 45/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 46/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6510 - val_loss: 0.6423 - val_accuracy: 0.6614\n",
      "Epoch 47/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6508 - val_accuracy: 0.6614\n",
      "Epoch 48/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 49/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6536 - val_accuracy: 0.6614\n",
      "Epoch 50/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 51/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6510 - val_loss: 0.6431 - val_accuracy: 0.6614\n",
      "Epoch 52/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6510 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 53/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 54/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6510 - val_loss: 0.6445 - val_accuracy: 0.6614\n",
      "Epoch 55/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6470 - val_accuracy: 0.6614\n",
      "Epoch 56/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6510 - val_loss: 0.6551 - val_accuracy: 0.6614\n",
      "Epoch 57/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 58/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6467 - val_accuracy: 0.6614\n",
      "Epoch 59/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6614\n",
      "Epoch 60/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 61/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 62/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6510 - val_loss: 0.6424 - val_accuracy: 0.6614\n",
      "Epoch 63/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6441 - val_accuracy: 0.6614\n",
      "Epoch 64/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6510 - val_loss: 0.6470 - val_accuracy: 0.6614\n",
      "Epoch 65/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 66/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6537 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 67/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 68/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6504 - val_accuracy: 0.6614\n",
      "Epoch 69/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6541 - accuracy: 0.6510 - val_loss: 0.6434 - val_accuracy: 0.6614\n",
      "Epoch 70/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 71/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6440 - val_accuracy: 0.6614\n",
      "Epoch 72/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 73/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 74/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6512 - val_accuracy: 0.6614\n",
      "Epoch 75/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6614\n",
      "Epoch 76/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 77/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6510 - val_loss: 0.6444 - val_accuracy: 0.6614\n",
      "Epoch 78/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 79/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6439 - val_accuracy: 0.6614\n",
      "Epoch 80/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 81/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 82/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 83/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6452 - val_accuracy: 0.6614\n",
      "Epoch 84/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 85/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6421 - val_accuracy: 0.6614\n",
      "Epoch 86/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 87/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6548 - accuracy: 0.6510 - val_loss: 0.6480 - val_accuracy: 0.6614\n",
      "Epoch 88/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 89/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 90/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 91/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6524 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 92/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6510 - val_loss: 0.6430 - val_accuracy: 0.6614\n",
      "Epoch 93/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6510 - val_loss: 0.6614 - val_accuracy: 0.6614\n",
      "Epoch 94/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6510 - val_loss: 0.6577 - val_accuracy: 0.6614\n",
      "Epoch 95/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 96/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.6510 - val_loss: 0.6419 - val_accuracy: 0.6614\n",
      "Epoch 97/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6614\n",
      "Epoch 98/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 99/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 100/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6507 - val_accuracy: 0.6614\n",
      "Epoch 101/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6490 - val_accuracy: 0.6614\n",
      "Epoch 102/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6564 - accuracy: 0.6510 - val_loss: 0.6522 - val_accuracy: 0.6614\n",
      "Epoch 103/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 104/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6510 - val_loss: 0.6417 - val_accuracy: 0.6614\n",
      "Epoch 105/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6433 - val_accuracy: 0.6614\n",
      "Epoch 106/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 107/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 108/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 109/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 110/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 111/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 112/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 113/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6478 - val_accuracy: 0.6614\n",
      "Epoch 114/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 115/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6424 - val_accuracy: 0.6614\n",
      "Epoch 116/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6515 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 117/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6614\n",
      "Epoch 118/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6510 - val_loss: 0.6463 - val_accuracy: 0.6614\n",
      "Epoch 119/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6510 - val_loss: 0.6470 - val_accuracy: 0.6614\n",
      "Epoch 120/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 121/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6485 - val_accuracy: 0.6614\n",
      "Epoch 122/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6510 - val_loss: 0.6434 - val_accuracy: 0.6614\n",
      "Epoch 123/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6460 - val_accuracy: 0.6614\n",
      "Epoch 124/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 125/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6457 - val_accuracy: 0.6614\n",
      "Epoch 126/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 127/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6542 - accuracy: 0.6510 - val_loss: 0.6664 - val_accuracy: 0.6614\n",
      "Epoch 128/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 129/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6540 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 130/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 131/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 132/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6510 - val_loss: 0.6422 - val_accuracy: 0.6614\n",
      "Epoch 133/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6443 - val_accuracy: 0.6614\n",
      "Epoch 134/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6430 - val_accuracy: 0.6614\n",
      "Epoch 135/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 136/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 137/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6531 - accuracy: 0.6510 - val_loss: 0.6445 - val_accuracy: 0.6614\n",
      "Epoch 138/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 139/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6550 - accuracy: 0.6510 - val_loss: 0.6495 - val_accuracy: 0.6614\n",
      "Epoch 140/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6439 - val_accuracy: 0.6614\n",
      "Epoch 141/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 142/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 143/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 144/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6468 - val_accuracy: 0.6614\n",
      "Epoch 145/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 146/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 147/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6438 - val_accuracy: 0.6614\n",
      "Epoch 148/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6614\n",
      "Epoch 149/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6513 - val_accuracy: 0.6614\n",
      "Epoch 150/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6648 - val_accuracy: 0.6614\n",
      "Epoch 151/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6490 - val_accuracy: 0.6614\n",
      "Epoch 152/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6510 - val_loss: 0.6507 - val_accuracy: 0.6614\n",
      "Epoch 153/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 154/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6461 - val_accuracy: 0.6614\n",
      "Epoch 155/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6452 - val_accuracy: 0.6614\n",
      "Epoch 156/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 157/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 158/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6450 - val_accuracy: 0.6614\n",
      "Epoch 159/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 160/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6429 - val_accuracy: 0.6614\n",
      "Epoch 161/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6439 - val_accuracy: 0.6614\n",
      "Epoch 162/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 163/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 164/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 165/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6437 - val_accuracy: 0.6614\n",
      "Epoch 166/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 167/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6522 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 168/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 169/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 170/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6462 - val_accuracy: 0.6614\n",
      "Epoch 171/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 172/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 173/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6423 - val_accuracy: 0.6614\n",
      "Epoch 174/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.6510 - val_loss: 0.6424 - val_accuracy: 0.6614\n",
      "Epoch 175/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 176/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6464 - val_accuracy: 0.6614\n",
      "Epoch 177/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6478 - val_accuracy: 0.6614\n",
      "Epoch 178/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6510 - val_loss: 0.6430 - val_accuracy: 0.6614\n",
      "Epoch 179/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6419 - val_accuracy: 0.6614\n",
      "Epoch 180/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 181/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 182/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6430 - val_accuracy: 0.6614\n",
      "Epoch 183/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6510 - val_loss: 0.6496 - val_accuracy: 0.6614\n",
      "Epoch 184/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 185/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 186/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 187/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6486 - val_accuracy: 0.6614\n",
      "Epoch 188/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 189/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 190/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 191/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 192/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 193/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 194/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 195/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 196/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 197/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 198/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 199/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 200/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6454 - val_accuracy: 0.6614\n",
      "Epoch 201/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 202/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 203/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 204/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6512 - val_accuracy: 0.6614\n",
      "Epoch 205/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.6510 - val_loss: 0.6446 - val_accuracy: 0.6614\n",
      "Epoch 206/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 207/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6452 - val_accuracy: 0.6614\n",
      "Epoch 208/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6425 - val_accuracy: 0.6614\n",
      "Epoch 209/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6434 - val_accuracy: 0.6614\n",
      "Epoch 210/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 211/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 212/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 213/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6461 - val_accuracy: 0.6614\n",
      "Epoch 214/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6544 - val_accuracy: 0.6614\n",
      "Epoch 215/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 216/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6508 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 217/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 218/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 219/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 220/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6428 - val_accuracy: 0.6614\n",
      "Epoch 221/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 222/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 223/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6510 - val_loss: 0.6454 - val_accuracy: 0.6614\n",
      "Epoch 224/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 225/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 226/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6451 - accuracy: 0.6510 - val_loss: 0.6527 - val_accuracy: 0.6614\n",
      "Epoch 227/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 228/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 229/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 230/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6446 - val_accuracy: 0.6614\n",
      "Epoch 231/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 232/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6546 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 233/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 234/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 235/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 236/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 237/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 238/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 239/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6421 - val_accuracy: 0.6614\n",
      "Epoch 240/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6423 - val_accuracy: 0.6614\n",
      "Epoch 241/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 242/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 243/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 244/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 245/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6439 - val_accuracy: 0.6614\n",
      "Epoch 246/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 247/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6510 - val_loss: 0.6417 - val_accuracy: 0.6614\n",
      "Epoch 248/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 249/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6516 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 250/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 251/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 252/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 253/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 254/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 255/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6467 - accuracy: 0.6510 - val_loss: 0.6424 - val_accuracy: 0.6614\n",
      "Epoch 256/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 257/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 258/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 259/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6428 - val_accuracy: 0.6614\n",
      "Epoch 260/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6504 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 261/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 262/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 263/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6420 - val_accuracy: 0.6614\n",
      "Epoch 264/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 265/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 266/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 267/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 268/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 269/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6510 - val_loss: 0.6451 - val_accuracy: 0.6614\n",
      "Epoch 270/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6417 - val_accuracy: 0.6614\n",
      "Epoch 271/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.6510 - val_loss: 0.6457 - val_accuracy: 0.6614\n",
      "Epoch 272/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6446 - val_accuracy: 0.6614\n",
      "Epoch 273/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 274/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 275/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 276/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 277/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6416 - val_accuracy: 0.6614\n",
      "Epoch 278/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 279/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6411 - val_accuracy: 0.6614\n",
      "Epoch 280/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 281/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 282/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 283/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 284/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6412 - val_accuracy: 0.6614\n",
      "Epoch 285/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 286/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6465 - accuracy: 0.6510 - val_loss: 0.6468 - val_accuracy: 0.6614\n",
      "Epoch 287/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 288/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6467 - val_accuracy: 0.6614\n",
      "Epoch 289/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6525 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 290/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 291/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 292/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 293/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 294/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 295/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 296/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6425 - val_accuracy: 0.6614\n",
      "Epoch 297/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 298/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6436 - val_accuracy: 0.6614\n",
      "Epoch 299/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 300/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 301/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6458 - val_accuracy: 0.6614\n",
      "Epoch 302/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 303/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 304/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6415 - val_accuracy: 0.6614\n",
      "Epoch 305/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 306/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 307/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6510 - val_loss: 0.6449 - val_accuracy: 0.6614\n",
      "Epoch 308/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6433 - val_accuracy: 0.6614\n",
      "Epoch 309/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6441 - val_accuracy: 0.6614\n",
      "Epoch 310/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6461 - accuracy: 0.6510 - val_loss: 0.6442 - val_accuracy: 0.6614\n",
      "Epoch 311/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 312/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6415 - val_accuracy: 0.6614\n",
      "Epoch 313/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 314/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 315/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 316/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6469 - accuracy: 0.6510 - val_loss: 0.6449 - val_accuracy: 0.6614\n",
      "Epoch 317/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 318/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 319/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 320/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6453 - val_accuracy: 0.6614\n",
      "Epoch 321/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 322/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 323/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 324/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 325/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 326/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6445 - val_accuracy: 0.6614\n",
      "Epoch 327/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6488 - val_accuracy: 0.6614\n",
      "Epoch 328/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6464 - accuracy: 0.6510 - val_loss: 0.6426 - val_accuracy: 0.6614\n",
      "Epoch 329/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6478 - val_accuracy: 0.6614\n",
      "Epoch 330/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 331/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 332/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6439 - val_accuracy: 0.6614\n",
      "Epoch 333/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 334/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6441 - val_accuracy: 0.6614\n",
      "Epoch 335/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 336/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6510 - val_loss: 0.6494 - val_accuracy: 0.6614\n",
      "Epoch 337/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 338/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 339/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 340/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6436 - val_accuracy: 0.6614\n",
      "Epoch 341/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6510 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 342/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 343/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 344/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 345/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 346/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6475 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 347/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6426 - val_accuracy: 0.6614\n",
      "Epoch 348/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 349/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 350/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6502 - accuracy: 0.6510 - val_loss: 0.6455 - val_accuracy: 0.6614\n",
      "Epoch 351/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6507 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 352/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 353/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 354/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 355/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 356/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 357/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 358/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 359/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 360/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6432 - val_accuracy: 0.6614\n",
      "Epoch 361/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6510 - val_loss: 0.6427 - val_accuracy: 0.6614\n",
      "Epoch 362/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6510 - val_loss: 0.6426 - val_accuracy: 0.6614\n",
      "Epoch 363/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 364/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 365/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 366/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 367/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6477 - accuracy: 0.6510 - val_loss: 0.6409 - val_accuracy: 0.6614\n",
      "Epoch 368/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 369/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 370/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6510 - val_loss: 0.6426 - val_accuracy: 0.6614\n",
      "Epoch 371/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 372/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 373/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6510 - val_loss: 0.6439 - val_accuracy: 0.6614\n",
      "Epoch 374/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 375/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 376/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 377/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 378/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 379/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6510 - val_loss: 0.6410 - val_accuracy: 0.6614\n",
      "Epoch 380/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 381/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.6510 - val_loss: 0.6481 - val_accuracy: 0.6614\n",
      "Epoch 382/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 383/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Epoch 384/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6408 - val_accuracy: 0.6614\n",
      "Epoch 385/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 386/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6510 - val_loss: 0.6407 - val_accuracy: 0.6614\n",
      "Epoch 387/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 388/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 389/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6490 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 390/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6406 - val_accuracy: 0.6614\n",
      "Epoch 391/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 392/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6510 - val_loss: 0.6414 - val_accuracy: 0.6614\n",
      "Epoch 393/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6418 - val_accuracy: 0.6614\n",
      "Epoch 394/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 395/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6488 - accuracy: 0.6510 - val_loss: 0.6413 - val_accuracy: 0.6614\n",
      "Epoch 396/400\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6489 - accuracy: 0.6510 - val_loss: 0.6403 - val_accuracy: 0.6614\n",
      "Epoch 397/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6404 - val_accuracy: 0.6614\n",
      "Epoch 398/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6614\n",
      "Epoch 399/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6401 - val_accuracy: 0.6614\n",
      "Epoch 400/400\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6510 - val_loss: 0.6405 - val_accuracy: 0.6614\n",
      "Test Accuracy: 0.661\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1008x504 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    decay       acc      loss\n",
      "0  0.0000  0.661417  0.644546\n",
      "1  0.0010  0.661417  0.640461\n",
      "2  0.0005  0.661417  0.640280\n",
      "3  0.0001  0.661417  0.640478\n"
     ]
    }
   ],
   "source": [
    "# first neural network with keras tutorial\n",
    "from    keras.models import Sequential\n",
    "from tensorflow.keras.initializers import RandomUniform\n",
    "from    keras.layers import Dense\n",
    "import  pandas as pd\n",
    "from    sklearn.model_selection import train_test_split\n",
    "import  matplotlib.pyplot  as plt\n",
    "PATH  = \"../datasets/\"\n",
    "import tensorflow as tf\n",
    "\n",
    "# load the dataset\n",
    "df = pd.read_csv(PATH + 'diabetes.csv', sep=',')\n",
    "\n",
    "# split into input (X) and output (y) variables\n",
    "X = df[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI',\n",
    "        'DiabetesPedigreeFunction',    'Age']]\n",
    "y = df[['Outcome']]\n",
    "\n",
    "# Split into train and test data sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33)\n",
    "\n",
    "resultList = []\n",
    "def buildModel(decayRate):\n",
    "    # define the keras model\n",
    "    model = Sequential()\n",
    "    init = RandomUniform(minval=0, maxval=1)\n",
    "    activation = 'tanh'\n",
    "    model.add(Dense(230, input_dim=8, activation=activation,\n",
    "                    kernel_initializer=init))\n",
    "\n",
    "    NUM_LAYERS = 7\n",
    "    for i in range(0, NUM_LAYERS-1):\n",
    "        model.add(Dense(230, activation=activation,\n",
    "                        kernel_initializer=init))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = tf.keras.optimizers.SGD(\n",
    "        learning_rate=0.0005, momentum=0.9, name=\"SGD\", decay=decayRate\n",
    "    )\n",
    "\n",
    "    # Compile the keras model.\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Fit the keras model on the dataset.\n",
    "    history = model.fit(X, y, epochs=400, batch_size=10,\n",
    "                        validation_data=(X_test, y_test))\n",
    "\n",
    "    # Evaluate the model.\n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    resultList.append({'loss':loss, 'acc':acc, 'decay':decayRate})\n",
    "    print('Test Accuracy: %.3f' % acc)\n",
    "    return history\n",
    "\n",
    "def showLoss(history, rates):\n",
    "    # Get training and test loss histories\n",
    "    training_loss       = history.history['loss']\n",
    "    validation_loss     = history.history['val_loss']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "    # Visualize loss history for training data.\n",
    "    actualLabel = str(rates)\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    # View loss on unseen data.\n",
    "    plt.plot(epoch_count, validation_loss, label=actualLabel)\n",
    "    plt.legend()\n",
    "\n",
    "def showAccuracy(history, rates):\n",
    "    # Get training and test loss histories\n",
    "    training_loss       = history.history['accuracy']\n",
    "    validation_loss     = history.history['val_accuracy']\n",
    "\n",
    "    # Create count of the number of epochs\n",
    "    epoch_count = range(1, len(training_loss) + 1)\n",
    "    plt.subplot(1, 2, 2)\n",
    "\n",
    "    actualLabel = str(rates)\n",
    "    # View loss on unseen data.\n",
    "    plt.plot(epoch_count, validation_loss, label=actualLabel)\n",
    "    plt.legend()\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    decayRates = [0, 0.001, 0.0005, 0.0001]\n",
    "    plt.subplots(nrows=1, ncols=2,  figsize=(14,7))\n",
    "\n",
    "    for i in range(0, len(decayRates)):\n",
    "        history = buildModel(decayRates[i])\n",
    "        showLoss(history, decayRates[i])\n",
    "        showAccuracy(history, decayRates[i])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(columns=['decay', 'acc', 'loss'])\n",
    "    for result in resultList:\n",
    "        df = df.append(result, ignore_index=True)\n",
    "    print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 21:42:00.202737: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-01 21:42:00.323887: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62857, saving model to best_model.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.62857 to 0.64286, saving model to best_model.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.64286\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.64286\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.64286\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.64286 to 0.65714, saving model to best_model.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.65714\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.65714 to 0.67143, saving model to best_model.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.67143\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.67143 to 0.68571, saving model to best_model.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.68571\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.68571 to 0.70000, saving model to best_model.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.70000\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.70000\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.70000\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.70000\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.70000\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.70000\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.70000\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.70000\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.70000\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.70000\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.70000\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.70000 to 0.71429, saving model to best_model.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.71429\n",
      "\n",
      "Epoch 00050: val_accuracy improved from 0.71429 to 0.72857, saving model to best_model.h5\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.72857\n",
      "\n",
      "Epoch 00061: val_accuracy improved from 0.72857 to 0.74286, saving model to best_model.h5\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.74286\n",
      "\n",
      "Epoch 00091: val_accuracy improved from 0.74286 to 0.75714, saving model to best_model.h5\n",
      "\n",
      "Epoch 00092: val_accuracy improved from 0.75714 to 0.78571, saving model to best_model.h5\n",
      "\n",
      "Epoch 00093: val_accuracy improved from 0.78571 to 0.80000, saving model to best_model.h5\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.80000\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.80000\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.80000\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.80000\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.80000\n",
      "\n",
      "Epoch 00099: val_accuracy improved from 0.80000 to 0.81429, saving model to best_model.h5\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.81429\n",
      "\n",
      "Epoch 00117: val_accuracy improved from 0.81429 to 0.82857, saving model to best_model.h5\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.82857\n",
      "\n",
      "Epoch 00232: val_accuracy improved from 0.82857 to 0.84286, saving model to best_model.h5\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00352: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00353: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00354: val_accuracy did not improve from 0.84286\n",
      "\n",
      "Epoch 00355: val_accuracy did not improve from 0.84286\n",
      "Epoch 00355: early stopping\n",
      "Train accuracy: 0.967, Test accuracy: 0.843\n",
      "Train loss: 0.133, Test loss: 0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-01 21:42:09.275229: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# Creating an overfit situation with the moons data set.\n",
    "from sklearn.datasets       import make_moons\n",
    "from keras.layers           import Dense\n",
    "from keras.models           import Sequential\n",
    "import matplotlib.pyplot    as plt\n",
    "\n",
    "# Generate 2d classification dataset.\n",
    "X, y    = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
    "\n",
    "# Split data into train and test.\n",
    "n_train = 30\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "\n",
    "# Define the model.\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# simple early stopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1,\n",
    "                     save_best_only=True)\n",
    "\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0,\n",
    "                    callbacks=[es, mc])\n",
    "\n",
    "# load the saved model\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "# Evaluate the model.\n",
    "train_loss, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
    "test_loss, test_acc   = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train accuracy: %.3f, Test accuracy: %.3f' % (train_acc, test_acc))\n",
    "print('Train loss: %.3f, Test loss: %.3f' % (train_loss, test_loss))\n",
    "\n",
    "# Plot loss learning curves.\n",
    "plt.subplot(211)\n",
    "plt.title('Cross-Entropy Loss', pad=-40)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy learning curves.\n",
    "plt.subplot(212)\n",
    "plt.title('Accuracy', pad=-40)\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}