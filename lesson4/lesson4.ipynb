{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "test_array = np.asarray([[8.3, 5.7], [8.9, 8.1]])\n",
    "print(np.argmax(test_array, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "test_array = np.asarray([[2.3, 1.7, 2.2], [1.9, 2.1, 2.4]])\n",
    "print(np.argmax(test_array, axis=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** Single model results:\n",
      "Single model 0   accuracy: 0.8114285714285714\n",
      "Single model 1   accuracy: 0.7885714285714286\n",
      "Single model 2   accuracy: 0.8171428571428572\n",
      "Single model 3   accuracy: 0.8171428571428572\n",
      "Single model 4   accuracy: 0.8114285714285714\n",
      "Single model 5   accuracy: 0.8057142857142857\n",
      "Single model 6   accuracy: 0.8142857142857143\n",
      "Single model 7   accuracy: 0.8028571428571428\n",
      "Single model 8   accuracy: 0.7914285714285715\n",
      "Single model 9   accuracy: 0.8028571428571428\n",
      "Single model 10   accuracy: 0.82\n",
      "Average model accuracy:      0.8075324675324675\n",
      "Accuracy standard deviation: 0.009917861346512602\n",
      "\n",
      "**** Ensemble model results: \n",
      "Ensemble model accuracy during trial 0: 0.82\n",
      "Ensemble model accuracy during trial 1: 0.8028571428571428\n",
      "Ensemble model accuracy during trial 2: 0.8114285714285714\n",
      "Ensemble model accuracy during trial 3: 0.8057142857142857\n",
      "Ensemble model accuracy during trial 4: 0.82\n",
      "Ensemble model accuracy during trial 5: 0.8228571428571428\n",
      "Ensemble model accuracy during trial 6: 0.7971428571428572\n",
      "Ensemble model accuracy during trial 7: 0.82\n",
      "Ensemble model accuracy during trial 8: 0.8171428571428572\n",
      "Ensemble model accuracy during trial 9: 0.82\n",
      "Ensemble model accuracy during trial 10: 0.8114285714285714\n",
      "Average model accuracy:      0.8135064935064935\n",
      "Accuracy standard deviation: 0.008089564416829826\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import argmax\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# fit model on dataset\n",
    "def fitMModel(trainX, trainy):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=200, verbose=0)\n",
    "    return model\n",
    "\n",
    "def getData():\n",
    "    # generate 2d classification dataset\n",
    "    X, y = make_blobs(n_samples=500, centers=3, n_features=2,\n",
    "                      cluster_std=2, random_state=2)\n",
    "\n",
    "    # split into train and test\n",
    "    trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.7)\n",
    "\n",
    "    # Converts array to matrix of categories.\n",
    "    # [0, 1, 2]\n",
    "\n",
    "    # Becomes:\n",
    "    # [[1, 0, 0],\n",
    "    #  [0, 1, 0],\n",
    "    #  [0, 0, 1]]\n",
    "    trainy = to_categorical(trainy)\n",
    "    return trainX, testX, trainy, testy\n",
    "\n",
    "def buildAndEvaluateIndividualModels():\n",
    "    trainX, testX, trainy, testy = getData()\n",
    "    NUM_MODELS  = 11\n",
    "    yhats       = []\n",
    "    scores      = []\n",
    "    models      = []\n",
    "    print(\"\\n**** Single model results:\")\n",
    "    for i in range(0, NUM_MODELS):\n",
    "        model                   = fitMModel(trainX, trainy)\n",
    "        models.append(model)\n",
    "        predictions             = model.predict(testX)\n",
    "        yhats.append(predictions)\n",
    "\n",
    "        # Converts multi-column prediction set back to single column\n",
    "        # so accuracy score can be calculated.\n",
    "        singleColumnPredictions = argmax(predictions, axis=1)\n",
    "        accuracy = accuracy_score(singleColumnPredictions, testy)\n",
    "        scores.append(accuracy)\n",
    "        print(\"Single model \" + str(i) + \"   accuracy: \" + str(accuracy))\n",
    "\n",
    "    print(\"Average model accuracy:      \" + str(np.mean(scores)))\n",
    "    print(\"Accuracy standard deviation: \" + str(np.std(scores)))\n",
    "    return models\n",
    "\n",
    "\n",
    "# Evaluate ensemble\n",
    "def buildAndEvaluateEnsemble(models):\n",
    "    scores = []\n",
    "    print(\"\\n**** Ensemble model results: \")\n",
    "    for trial in range(0, 11):\n",
    "        # Generate new test data.\n",
    "        _, testX, _, testy = getData()\n",
    "\n",
    "        yhats  = []\n",
    "        # Get predictions with pre-built models.\n",
    "        for model in models:\n",
    "            predictions = model.predict(testX)\n",
    "            yhats.append(predictions)\n",
    "\n",
    "        # Sum predictions for all models.\n",
    "        # [[0.2, 0.3, 0.5], [0.3, 0.3, 0.4]...], # Model 1 results\n",
    "        #  [0.3, 0.3, 0.4], [0.1, 0.1, 0.8]...], # Model 2 results\n",
    "        #  [0.2, 0.2, 0.6], [0.3, 0.3, 0.4]...], # Model 3 results\n",
    "        # Becomes\n",
    "        # [[0.7, 0.8, 1.5],[0.7, 0.7, 1.6]...] # Summed results\n",
    "        summed = np.sum(yhats, axis=0)\n",
    "\n",
    "        # Converts multi-column prediction set back to single column\n",
    "        # so accuracy score can be calculated. For example;\n",
    "        # [[0.7, 0.8, 1.5],[0.7, 0.7, 1.6]...]\n",
    "        # Becomes\n",
    "        # [2, 2,....]\n",
    "        singleColumnPredictions = argmax(summed, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(singleColumnPredictions, testy)\n",
    "        scores.append(accuracy)\n",
    "        print(\"Ensemble model accuracy during trial \" + str(trial) +\n",
    "              \": \" + str(accuracy))\n",
    "\n",
    "    print(\"Average model accuracy:      \" + str(np.mean(scores)))\n",
    "    print(\"Accuracy standard deviation: \" + str(np.std(scores)))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    models = buildAndEvaluateIndividualModels()\n",
    "    buildAndEvaluateEnsemble(models)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** Single model results:\n",
      "Single model 0   accuracy: 0.98\n",
      "Single model 1   accuracy: 0.96\n",
      "Single model 2   accuracy: 0.98\n",
      "WARNING:tensorflow:5 out of the last 1349 calls to <function Model.make_predict_function.<locals>.predict_function at 0x160843d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Single model 3   accuracy: 0.78\n",
      "WARNING:tensorflow:6 out of the last 1351 calls to <function Model.make_predict_function.<locals>.predict_function at 0x161c25dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Single model 4   accuracy: 0.98\n",
      "Single model 5   accuracy: 0.98\n",
      "Single model 6   accuracy: 0.98\n",
      "Single model 7   accuracy: 0.98\n",
      "Single model 8   accuracy: 0.94\n",
      "Single model 9   accuracy: 0.96\n",
      "Single model 10   accuracy: 0.98\n",
      "Average model accuracy:      0.9545454545454546\n",
      "Accuracy standard deviation: 0.05662695091780885\n",
      "\n",
      "**** Ensemble model results: \n",
      "Ensemble model accuracy during trial 0: 0.96\n",
      "Ensemble model accuracy during trial 1: 0.98\n",
      "Ensemble model accuracy during trial 2: 0.98\n",
      "Ensemble model accuracy during trial 3: 0.96\n",
      "Ensemble model accuracy during trial 4: 0.98\n",
      "Ensemble model accuracy during trial 5: 1.0\n",
      "Ensemble model accuracy during trial 6: 0.98\n",
      "Ensemble model accuracy during trial 7: 1.0\n",
      "Ensemble model accuracy during trial 8: 0.98\n",
      "Ensemble model accuracy during trial 9: 0.96\n",
      "Ensemble model accuracy during trial 10: 0.98\n",
      "Average model accuracy:      0.9781818181818184\n",
      "Accuracy standard deviation: 0.013360853142453711\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from numpy import argmax\n",
    "from sklearn.datasets import make_blobs\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# fit model on dataset\n",
    "def fitModel(trainX, trainy):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=200, verbose=0)\n",
    "    return model\n",
    "\n",
    "\n",
    "def getData():\n",
    "    PATH = \"../datasets/\"\n",
    "    df = pd.read_csv(PATH + 'iris_old.csv')\n",
    "    df.columns = ['Sepal L', 'Sepal W', 'Petal L', 'Petal W', 'Iris Type']\n",
    "\n",
    "    # Convert text to numeric category.\n",
    "    # 0 is setosa, 1 is versacolor and 2 is virginica\n",
    "    df['y'] = LabelEncoder().fit_transform(df['Iris Type'])\n",
    "\n",
    "    # Prepare the data.\n",
    "    X = df[['Sepal L', 'Sepal W', 'Petal L', 'Petal W']]\n",
    "    y = df['y']\n",
    "    ROW_DIM = 0\n",
    "    COL_DIM = 1\n",
    "\n",
    "    x_array = X.values\n",
    "    x_arrayReshaped = x_array.reshape(x_array.shape[ROW_DIM],\n",
    "                                      x_array.shape[COL_DIM])\n",
    "\n",
    "    y_array = y.values\n",
    "    y_arrayReshaped = y_array.reshape(y_array.shape[ROW_DIM], 1)\n",
    "\n",
    "    trainX, testX, trainy, testy = train_test_split(x_arrayReshaped,\n",
    "                                                    y_arrayReshaped,\n",
    "                                                    test_size=0.33)\n",
    "    trainy = to_categorical(trainy)\n",
    "    return trainX, testX, trainy, testy\n",
    "\n",
    "\n",
    "def buildAndEvaluateIndividualModels():\n",
    "    trainX, testX, trainy, testy = getData()\n",
    "    NUM_MODELS  = 11\n",
    "    yhats       = []\n",
    "    scores      = []\n",
    "    models      = []\n",
    "    print(\"\\n**** Single model results:\")\n",
    "    for i in range(0, NUM_MODELS):\n",
    "        model                   = fitModel(trainX, trainy)\n",
    "        models.append(model)\n",
    "        predictions             = model.predict(testX)\n",
    "        yhats.append(predictions)\n",
    "\n",
    "        # Converts multi-column prediction set back to single column\n",
    "        # so accuracy score can be calculated.\n",
    "        singleColumnPredictions = argmax(predictions, axis=1)\n",
    "        accuracy = accuracy_score(singleColumnPredictions, testy)\n",
    "        scores.append(accuracy)\n",
    "        print(\"Single model \" + str(i) + \"   accuracy: \" + str(accuracy))\n",
    "\n",
    "    print(\"Average model accuracy:      \" + str(np.mean(scores)))\n",
    "    print(\"Accuracy standard deviation: \" + str(np.std(scores)))\n",
    "    return models\n",
    "\n",
    "\n",
    "# Evaluate ensemble\n",
    "def buildAndEvaluateEnsemble(models):\n",
    "    scores = []\n",
    "    print(\"\\n**** Ensemble model results: \")\n",
    "    for trial in range(0, 11):\n",
    "        # Generate new test data.\n",
    "        _, testX, _, testy = getData()\n",
    "\n",
    "        yhats  = []\n",
    "        # Get predictions with pre-built models.\n",
    "        for model in models:\n",
    "            predictions = model.predict(testX)\n",
    "            yhats.append(predictions)\n",
    "\n",
    "        # Sum predictions for all models.\n",
    "        # [[0.2, 0.3, 0.5], [0.3, 0.3, 0.4]...], # Model 1 results\n",
    "        #  [0.3, 0.3, 0.4], [0.1, 0.1, 0.8]...], # Model 2 results\n",
    "        #  [0.2, 0.2, 0.6], [0.3, 0.3, 0.4]...], # Model 3 results\n",
    "        # Becomes\n",
    "        # [[0.7, 0.8, 1.5],[0.7, 0.7, 1.6]...] # Summed results\n",
    "        summed = np.sum(yhats, axis=0)\n",
    "\n",
    "        # Converts multi-column prediction set back to single column\n",
    "        # so accuracy score can be calculated. For example;\n",
    "        # [[0.7, 0.8, 1.5],[0.7, 0.7, 1.6]...]\n",
    "        # Becomes\n",
    "        # [2, 2,....]\n",
    "        singleColumnPredictions = argmax(summed, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(singleColumnPredictions, testy)\n",
    "        scores.append(accuracy)\n",
    "        print(\"Ensemble model accuracy during trial \" + str(trial) +\n",
    "              \": \" + str(accuracy))\n",
    "\n",
    "    print(\"Average model accuracy:      \" + str(np.mean(scores)))\n",
    "    print(\"Accuracy standard deviation: \" + str(np.std(scores)))\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    models = buildAndEvaluateIndividualModels()\n",
    "    buildAndEvaluateEnsemble(models)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved ./models/model_1.h5\n",
      ">Saved ./models/model_2.h5\n",
      ">Saved ./models/model_3.h5\n",
      ">Saved ./models/model_4.h5\n",
      ">Saved ./models/model_5.h5\n",
      ">loaded ./models/model_1.h5\n",
      ">loaded ./models/model_2.h5\n",
      ">loaded ./models/model_3.h5\n",
      ">loaded ./models/model_4.h5\n",
      ">loaded ./models/model_5.h5\n",
      "Loaded 5 models\n",
      "Model Accuracy: 0.737\n",
      "Model Accuracy: 0.751\n",
      "Model Accuracy: 0.761\n",
      "Model Accuracy: 0.761\n",
      "Model Accuracy: 0.752\n",
      "Stacked Test Accuracy: 0.817\n"
     ]
    }
   ],
   "source": [
    "from keras.models     import Sequential\n",
    "from keras.layers     import Dense\n",
    "from os               import makedirs\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "PATH = './models/'\n",
    "\n",
    "# fit model on dataset\n",
    "def fit_model(trainX, trainy):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=2, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=500, verbose=0)\n",
    "    return model\n",
    "\n",
    "def generateData():\n",
    "    # generate 2d classification dataset\n",
    "    X, y = make_blobs(n_samples=1100, centers=3,\n",
    "                      n_features=2,\n",
    "                      cluster_std=2, random_state=2)\n",
    "\n",
    "    # split into train and test\n",
    "    trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.93)\n",
    "    return trainX, testX, trainy, testy\n",
    "\n",
    "def generateModels(trainX, trainy):\n",
    "    # create directory for models\n",
    "    if(not path.exists(PATH)):\n",
    "        makedirs('./models')\n",
    "\n",
    "    # fit and save models\n",
    "    numModels = 5\n",
    "    for i in range(numModels):\n",
    "        # fit model\n",
    "        model = fit_model(trainX, trainy)\n",
    "        # save model\n",
    "        filename = PATH + 'model_' + str(i + 1) + '.h5'\n",
    "        model.save(filename)\n",
    "        print('>Saved %s' % filename)\n",
    "\n",
    "# load models from file\n",
    "def load_all_models(n_models):\n",
    "    all_models = list()\n",
    "    for i in range(n_models):\n",
    "        # define filename for this ensemble\n",
    "        filename = PATH + 'model_' + str(i + 1) + '.h5'\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "        # add to list of models\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models\n",
    "\n",
    "\n",
    "# create stacked model input dataset as outputs from the ensemble\n",
    "def getStackedData(models, inputX):\n",
    "    stackXdf = None\n",
    "    for model in models:\n",
    "        # make prediction\n",
    "        yhat = model.predict(inputX, verbose=0)\n",
    "        singleModelPredDf = pd.DataFrame(np.row_stack(yhat))\n",
    "\n",
    "        # Store predictions of all models for 1 sample in each df row.\n",
    "        # Here is 1st row for 5 models with predictions for 3 classes each.\n",
    "        # 5 models x 3 classes = 15 columns.\n",
    "        #          0             1         2   ...        12            13        14\n",
    "        # 0 0.993102  1.106366e-04  0.006788   ...  0.993102  1.106366e-04  0.006788\n",
    "        if stackXdf is None:\n",
    "            stackXdf = singleModelPredDf\n",
    "        else:\n",
    "            numClasses = len(singleModelPredDf.keys())\n",
    "            numStackXCols = len(stackXdf.keys())\n",
    "\n",
    "            # Add new classification columns.\n",
    "            for i in range(0, numClasses):\n",
    "                stackXdf[numStackXCols + i] = stackXdf[i]\n",
    "    return stackXdf\n",
    "\n",
    "# Make predictions with the stacked model\n",
    "def stacked_prediction(models, model, inputX):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = getStackedData(models, inputX)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(stackedX)\n",
    "    return yhat\n",
    "\n",
    "# fit a model based on the outputs from the ensemble models\n",
    "def fit_stacked_model(models, inputX, inputy):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = getStackedData(models, inputX)\n",
    "    # fit standalone model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(stackedX, inputy)\n",
    "    return model\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    trainX, testX, trainy, testy = generateData()\n",
    "\n",
    "    # one hot encode output variable\n",
    "    trainy = to_categorical(trainy)\n",
    "    generateModels(trainX, trainy)\n",
    "    trainX, testX, trainy, testy = generateData()\n",
    "\n",
    "    # load all models\n",
    "    numModels = 5\n",
    "    models    = load_all_models(numModels)\n",
    "    print('Loaded %d models' % len(models))\n",
    "\n",
    "    # evaluate standalone models on test dataset\n",
    "    # individual ANN models are built with one-hot encoded data.\n",
    "    for model in models:\n",
    "        oneHotEncodedY = to_categorical(testy)\n",
    "        _, acc = model.evaluate(testX, oneHotEncodedY, verbose=0)\n",
    "        print('Model Accuracy: %.3f' % acc)\n",
    "\n",
    "    # fit stacked model using the ensemble\n",
    "    # Stacked model build with LogisticRegression.\n",
    "    # y for LogisticRegression is not one-hot encoded.\n",
    "    model = fit_stacked_model(models, testX, testy)\n",
    "\n",
    "    # evaluate model on test set\n",
    "    yhat = stacked_prediction(models, model, testX)\n",
    "    acc  = accuracy_score(testy, yhat)\n",
    "    print('Stacked Test Accuracy: %.3f' % acc)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Saved ./models/model_1.h5\n",
      ">Saved ./models/model_2.h5\n",
      ">Saved ./models/model_3.h5\n",
      ">Saved ./models/model_4.h5\n",
      ">Saved ./models/model_5.h5\n",
      ">loaded ./models/model_1.h5\n",
      ">loaded ./models/model_2.h5\n",
      ">loaded ./models/model_3.h5\n",
      ">loaded ./models/model_4.h5\n",
      ">loaded ./models/model_5.h5\n",
      "Loaded 5 models\n",
      "Model Accuracy: 0.975\n",
      "Model Accuracy: 0.908\n",
      "Model Accuracy: 0.942\n",
      "Model Accuracy: 0.958\n",
      "Model Accuracy: 0.967\n",
      "Stacked Test Accuracy: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanleung/miniforge3/lib/python3.9/site-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from keras.models     import Sequential\n",
    "from keras.layers     import Dense\n",
    "from os               import makedirs\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "PATH = './models/'\n",
    "\n",
    "# fit model on dataset\n",
    "def fit_model(trainX, trainy):\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=4, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    # fit model\n",
    "    model.fit(trainX, trainy, epochs=500, verbose=0)\n",
    "    return model\n",
    "\n",
    "def generateData():\n",
    "    PATH = \"../datasets/\"\n",
    "    df = pd.read_csv(PATH + 'iris_old.csv')\n",
    "    df.columns = ['Sepal L', 'Sepal W', 'Petal L', 'Petal W', 'Iris Type']\n",
    "\n",
    "    # Convert text to numeric category.\n",
    "    # 0 is setosa, 1 is versacolor and 2 is virginica\n",
    "    df['y'] = LabelEncoder().fit_transform(df['Iris Type'])\n",
    "\n",
    "    # Prepare the data.\n",
    "    X = df[['Sepal L', 'Sepal W', 'Petal L', 'Petal W']]\n",
    "    y = df['y']\n",
    "    ROW_DIM = 0\n",
    "    COL_DIM = 1\n",
    "\n",
    "    x_array = X.values\n",
    "    x_arrayReshaped = x_array.reshape(x_array.shape[ROW_DIM],\n",
    "                                      x_array.shape[COL_DIM])\n",
    "\n",
    "    y_array = y.values\n",
    "    y_arrayReshaped = y_array.reshape(y_array.shape[ROW_DIM], 1)\n",
    "\n",
    "    trainX, testX, trainy, testy = train_test_split(x_arrayReshaped,\n",
    "                                                    y_arrayReshaped,\n",
    "                                                    test_size=0.80)\n",
    "    return trainX, testX, trainy, testy\n",
    "\n",
    "\n",
    "def generateModels(trainX, trainy):\n",
    "    # create directory for models\n",
    "    if(not path.exists(PATH)):\n",
    "        makedirs('./models')\n",
    "\n",
    "    # fit and save models\n",
    "    numModels = 5\n",
    "    for i in range(numModels):\n",
    "        # fit model\n",
    "        model = fit_model(trainX, trainy)\n",
    "        # save model\n",
    "        filename = PATH + 'model_' + str(i + 1) + '.h5'\n",
    "        model.save(filename)\n",
    "        print('>Saved %s' % filename)\n",
    "\n",
    "# load models from file\n",
    "def load_all_models(n_models):\n",
    "    all_models = list()\n",
    "    for i in range(n_models):\n",
    "        # define filename for this ensemble\n",
    "        filename = PATH + 'model_' + str(i + 1) + '.h5'\n",
    "        # load model from file\n",
    "        model = load_model(filename)\n",
    "        # add to list of models\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models\n",
    "\n",
    "\n",
    "# create stacked model input dataset as outputs from the ensemble\n",
    "def getStackedData(models, inputX):\n",
    "    stackXdf = None\n",
    "    for model in models:\n",
    "        # make prediction\n",
    "        yhat = model.predict(inputX, verbose=0)\n",
    "        singleModelPredDf = pd.DataFrame(np.row_stack(yhat))\n",
    "\n",
    "        # Store predictions of all models for 1 sample in each df row.\n",
    "        # Here is 1st row for 5 models with predictions for 3 classes each.\n",
    "        # 5 models x 3 classes = 15 columns.\n",
    "        #          0             1         2   ...        12            13        14\n",
    "        # 0 0.993102  1.106366e-04  0.006788   ...  0.993102  1.106366e-04  0.006788\n",
    "        if stackXdf is None:\n",
    "            stackXdf = singleModelPredDf\n",
    "        else:\n",
    "            numClasses = len(singleModelPredDf.keys())\n",
    "            numStackXCols = len(stackXdf.keys())\n",
    "\n",
    "            # Add new classification columns.\n",
    "            for i in range(0, numClasses):\n",
    "                stackXdf[numStackXCols + i] = stackXdf[i]\n",
    "    return stackXdf\n",
    "\n",
    "# Make predictions with the stacked model\n",
    "def stacked_prediction(models, model, inputX):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = getStackedData(models, inputX)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(stackedX)\n",
    "    return yhat\n",
    "\n",
    "# fit a model based on the outputs from the ensemble models\n",
    "def fit_stacked_model(models, inputX, inputy):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = getStackedData(models, inputX)\n",
    "    # fit standalone model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(stackedX, inputy)\n",
    "    return model\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    trainX, testX, trainy, testy = generateData()\n",
    "\n",
    "    # one hot encode output variable\n",
    "    trainy = to_categorical(trainy)\n",
    "    generateModels(trainX, trainy)\n",
    "    trainX, testX, trainy, testy = generateData()\n",
    "\n",
    "    # load all models\n",
    "    numModels = 5\n",
    "    models    = load_all_models(numModels)\n",
    "    print('Loaded %d models' % len(models))\n",
    "\n",
    "    # evaluate standalone models on test dataset\n",
    "    # individual ANN models are built with one-hot encoded data.\n",
    "    for model in models:\n",
    "        oneHotEncodedY = to_categorical(testy)\n",
    "        _, acc = model.evaluate(testX, oneHotEncodedY, verbose=0)\n",
    "        print('Model Accuracy: %.3f' % acc)\n",
    "\n",
    "    # fit stacked model using the ensemble\n",
    "    # Stacked model build with LogisticRegression.\n",
    "    # y for LogisticRegression is not one-hot encoded.\n",
    "    model = fit_stacked_model(models, testX, testy)\n",
    "\n",
    "    # evaluate model on test set\n",
    "    yhat = stacked_prediction(models, model, testX)\n",
    "    acc  = accuracy_score(testy, yhat)\n",
    "    print('Stacked Test Accuracy: %.3f' % acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}